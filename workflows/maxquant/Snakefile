"""
Incremental development:

1) run on local machine in dry-run (iteratively adding functionality)
2) execute using `qsub` (or interactive shell on CR2)
3) add queuing system `qsub`
"""
import os
configfile: 'config.yaml'  # access using config['key']


results_foldername = os.path.basename(config["RESULTSDIR"])

# move away from config into envvars
envvars:
    "SSHPASS"

# wildcard_mqpar = os.path.join(config['SCRIPTDIR'], 'mqpar_xmls', "mqpar_{file}.xml")
# mq_par_temp = os.path.join(config['SCRIPTDIR'], config['MQ_PAR_TEMP'])

with open(config['FILES'], encoding='utf-8') as f:
    FILES = set(line.strip().split('.raw')[0] for line in f)

# Order Files (set gives an unordered)
FILES = list(FILES)
FILES.sort()  # otherwise execution order is not deterministic due to set
# local, excluded files previously identified as to small
fname_excluded = f"{results_foldername}_excluded_files.txt"
try:
    with open(fname_excluded, encoding='utf-8') as f:
        FILES_EXCLUDED = set(line.strip().split('.raw')[0] for line in f)

    for _file_to_remove in FILES_EXCLUDED:
        FILES.remove(_file_to_remove)
except FileNotFoundError:
    print(f"No such file: {fname_excluded} - Creating one.")
    with open(fname_excluded, 'w'):
        pass
except ValueError:
    print(f"WARNING: Excluded files not in current set of files.")


# local rules are excuted in the process (job) running snakemake
# allows for ssh-multiplexing, see https://blog.scottlowe.org/2015/12/11/using-ssh-multiplexing/
localrules: target, mqpar, download_file, upload_file


# Thinnode resources sharing: 40 cores and 196 GB RAM (minus 2GB for snakemake)
# http://www.dewassoc.com/kbase/hard_drives/binary_v_decimal_measurement.htm
job_ram_mb = int(204_800 / 40 * config['THREATS_MQ'])

# #Target Rule:
rule target:
    input:
        # mockfile approach: https://stackoverflow.com/a/53751654/9684872
        # replace? https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#directories-as-outputs
        expand(os.path.join(config['RESULTSDIR'],
                            "{file}", "{file}.txt"), file=FILES)


rule download_file:
    output:
        raw = temp(os.path.join(config['DATADIR'], "{file}", "{file}.raw"))
    benchmark:
        os.path.join(config['RESULTSDIR'], "{file}", "benchmark_download.tsv")
    params:
        file = "{file}.raw",
        logdir = os.path.join(config['RESULTSDIR'], "{file}"),
        remote = config['REMOTE_IN'],
        datadir = os.path.join(config['DATADIR'], "{file}")
    resources:
        walltime = 300, nodes = 1, mem_mb = 2048
    threads:
        1
    shell:
        """
        sftp -B 258048 {params.remote} <<< 'get {params.file} {output.raw}' && (
        FILESIZE=$(stat -c%s {output.raw}) &&
        [ $FILESIZE -le 100000000 ] &&
        echo '{params.file}' >> {fname_excluded} &&
        echo "{params.file} is too small: $FILESIZE" &&
        echo "File is too small: $FILESIZE" > {params.logdir}/download_too_small.log &&
        rm -R {params.datadir} &&
        exit 1 ||  exit 0)
        """


rule mqpar:
    benchmark:
        os.path.join(config['RESULTSDIR'], "{file}", "benchmark_mqpar.tsv")
    params:
        raw = os.path.join(config['DATADIR'], "{file}", "{file}.raw"),
        mq_par_temp = os.path.join(config['SCRIPTDIR'], config['MQ_PAR_TEMP']),
        threads_mq = config['THREATS_MQ'],
        logdir = os.path.join(config['RESULTSDIR'], "{file}"),
    resources:
        walltime = 240, nodes = 1, mem_mb = 1024
    threads:
        1
    output:
        mq_par = os.path.join(config['SCRIPTDIR'],
                              'mqpar_xmls', "mqpar_{file}.xml")
    run:
        # snakemake create folders itself if missing -> download job into folder
        with open(file=params.mq_par_temp, encoding='utf-8') as infile, open(file=output.mq_par, mode='w', encoding='utf-8') as outfile:
            for line in infile:
                line = line.replace('PATH', params.raw)
                line = line.replace('NUM_THREADS', str(params.threads_mq))
                outfile.write(line)
            outfile.close()
            infile.close()


rule maxquant:
    input:
        raw = os.path.join(config['DATADIR'], "{file}", "{file}.raw"),
        mq_par = os.path.join(config['SCRIPTDIR'],
                              'mqpar_xmls', "mqpar_{file}.xml"),
        exe = config['MAXQUANTEXE']
    benchmark:
        os.path.join(config['RESULTSDIR'], "{file}", "benchmark_MQ.tsv")
    output:
        out = os.path.join(config['RESULTSDIR'],
                           "{file}", "{file}_mq_done.txt")
    resources:
        mem_mb = job_ram_mb, nodes = 1, walltime = 14400
    threads:
        config['THREATS_MQ']
    envmodules:
        "tools",
        "mono/5.20.1.19"
    params:
        datadir = os.path.join(config['DATADIR'], "{file}"),
        logdir = os.path.join(config['RESULTSDIR'], "{file}"),
        log_failed = f"{results_foldername}_failed.txt",
        log_completed = f"{results_foldername}_completed.txt",
        remote = config['REMOTE_OUT']
    shell:
        # https://snakemake.readthedocs.io/en/stable/project_info/faq.html#i-don-t-want-snakemake-to-detect-an-error-if-my-shell-command-exits-with-an-exitcode-1-what-can-i-do
        # write shell script?
        # https: // stackoverflow.com/a/27301889/9684872
        # changing in presence of here-documents (<< EOF EOF below)
        # https://snakemake.readthedocs.io/en/stable/project_info/faq.html#is-it-possible-to-pass-variable-values-to-the-workflow-via-the-command-line
        # { have to be escaped as {{
        """
        mono --version &&
        FILESIZE=$(stat -c%s {input.raw}) &&
        [ $FILESIZE -ge 100000000 ] &&
        mono {input.exe} {input.mq_par} &&
        echo "$(date +"%F %T"): Finished run with MaxQuant version {input.exe}" >> {output.out} &&
        echo '-mkdir mq_out/{wildcards.file}' >> sftp_commands &&
        echo '-put {params.datadir}/combined/txt/* mq_out/{wildcards.file}' >> sftp_commands &&
        cp {input.mq_par} {params.datadir}/combined/txt/mqpar.xml &&
        echo '{wildcards.file}' >> {params.log_completed} ||
        ( echo '{wildcards.file}' >> {params.log_failed} &&
        echo "Size of {input.raw}: $FILESIZE" &&
        rm -R {params.datadir} &&
        exit 1 )
        """

rule upload_file:
    input:
        mq_done = os.path.join(
            config['RESULTSDIR'], "{file}", "{file}_mq_done.txt")
    output:
        out = os.path.join(config['RESULTSDIR'],
                           "{file}", "{file}.txt")
    resources:
        mem_mb = job_ram_mb, nodes = 1, walltime = 900
    params:
        datadir = os.path.join(config['DATADIR'], "{file}"),
        remote = config['REMOTE_OUT']
    shell:
        """
        sftp -B 258048 {params.remote} <<< '-mkdir mq_out/{wildcards.file}\nput {params.datadir}/combined/txt/* mq_out/{wildcards.file}' &&
        rm -R {params.datadir} && echo 'Done uploading to mq_out/{wildcards.file} on {params.remote}' &&
        echo "$(date +"%F %T"): Finished upload to erda." >> {output.out} || echo 'Failed upload for {wildcards.file}'
        """
