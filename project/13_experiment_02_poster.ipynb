{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02\n",
    "\n",
    "\n",
    "The current approach for creating train, validation and test data sets is to split \n",
    "the data in long-format, i.e. one observation is an intensity value from one sample representing one peptide, into the desired splits. In this process missing values are not regarded.\n",
    "\n",
    "- [x] mask entries in larger dataset in long-format\n",
    "- [x] mask peptides based on their frequency in samples (probability of being observed)\n",
    "- [x] create *long-format* training data set without masked values for each model\n",
    "    - FNN based on embeddings of peptides and samples (long-format **without** missing values)\n",
    "    - Denoising AE (wide-format **with** missing values)\n",
    "    - VAE (wide-format **with** missing values)\n",
    "- [ ] restrict to only a training data split of consective data: Increase number of samples.\n",
    "    - focus on best reconstruction performance\n",
    "    - mean comparison\n",
    "\n",
    "### Collaborative Filtering model\n",
    "\n",
    "- Cannot accomodate iid assumption of statistical test in current setup for embedding vectors.\n",
    "  - if pretrained model should be applied to an new batch of replicates (with a certain condition) one would need to find a way to initialize the sample embeddings without fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "import seaborn\n",
    "import numpy.testing as npt  # fastcore.test functionality\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import vaep.io_images\n",
    "from vaep.pandas import interpolate\n",
    "from vaep.model import build_df_from_pred_batches\n",
    "\n",
    "from src.nb_imports import *\n",
    "from src import metadata\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 02\")\n",
    "\n",
    "figures = {}  # collection of ax or figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# None takes all\n",
    "N_SAMPLES: int = 1000\n",
    "n_features: int = 50\n",
    "ADD_TENSORBOARD: bool = False\n",
    "FN_PEPTIDE_INTENSITIES: Path = (\n",
    "    config.FOLDER_DATA / 'df_intensities_N07285_M01000')  # 90%\n",
    "epochs_max = 10\n",
    "batch_size = 32\n",
    "latent_dim = 2\n",
    "most_common: bool = False\n",
    "most_uncommon: bool = False\n",
    "out_folder: str = 'poster'\n",
    "# write to read only config ? namedtuple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, EPOCHS = batch_size, epochs_max\n",
    "folder = Path(out_folder) / f'feat_{n_features:04d}_epochs_{epochs_max:03d}'\n",
    "print(f\"{folder = }\")\n",
    "\n",
    "if most_common and most_uncommon:\n",
    "    raise ValueError(f\"Cannot be both True: {most_common = } and {most_uncommon = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_PEPTIDE_INTENSITIES = Path(FN_PEPTIDE_INTENSITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = AnalyzePeptides(fname=FN_PEPTIDE_INTENSITIES, nrows=None)\n",
    "analysis.df.columns.name = 'peptide'\n",
    "analysis.log_transform(np.log2)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date are not possible in the indices\n",
    "rename_indices_w_wrong_dates = {'20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_03': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_03',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_12': '20180330_QE10_nLC0_MR_QC_MNT_Hela_12',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_01': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_01',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_11': '20180330_QE10_nLC0_MR_QC_MNT_Hela_11',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_02': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_02'}\n",
    "analysis.df.rename(index=rename_indices_w_wrong_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N consecutive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_consecutive_dates(n_samples=N_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not analysis.df._is_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_long.isna().sum().sum(\n",
    ") == 0, \"There are still missing values in the long format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_wide.isna().sum().sum(\n",
    ") > 0, \"There are no missing values left in the wide format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling peptides by their frequency (important for later)\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_per_peptide = analysis.df.unstack().to_frame('intensity').reset_index(1, drop=True)\n",
    "freq_per_peptide = analysis.df_long['intensity']\n",
    "freq_per_peptide = freq_per_peptide.notna().groupby(level=1).sum()\n",
    "print(f\"{n_features = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting N\n",
    " - most common\n",
    " - most uncommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_per_pepitde = freq_per_peptide.sort_values(ascending=False)\n",
    "\n",
    "if most_common:\n",
    "    freq_per_pepitde = freq_per_pepitde.iloc[:n_features]\n",
    "elif most_uncommon:\n",
    "    freq_per_pepitde = freq_per_pepitde.iloc[-n_features:]\n",
    "else:\n",
    "    freq_per_pepitde = freq_per_pepitde.sample(n_features)\n",
    "    \n",
    "assert len(freq_per_pepitde.index) == n_features\n",
    "\n",
    "freq_per_pepitde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df = analysis.df[freq_per_pepitde.index]\n",
    "# ToDo: clean-up other attributes needs to be integrated\n",
    "del analysis._df_long  # , analysis._df_wide\n",
    "analysis.df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- biological stock differences in PCA plot. Show differences in models. Only see biological variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis.plot_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo add df_meta property\n",
    "analysis.df_meta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.io_images._savefig(fig, folder /\n",
    "                        f'pca_plot_raw_data_{analysis.fname_stub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation data\n",
    "\n",
    "- use mulitindex for obtaining validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# analysis._df_long = analysis.df_long.reset_index(\n",
    "# ).set_index(['Sample ID', 'peptide'])\n",
    "analysis.df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = analysis.df.unstack().to_frame('intensity').reset_index(1)\n",
    "analysis.df_train = analysis.df_long.reset_index(0).groupby(\n",
    "    by='Sample ID',\n",
    "    level=0\n",
    ").sample(frac=0.90,\n",
    "         weights=freq_per_peptide,\n",
    "         random_state=42)\n",
    "analysis.df_train = analysis.df_train.reset_index().set_index([\n",
    "    'Sample ID', 'peptide'])\n",
    "analysis.df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.indices_valid = analysis.df_long.index.difference(\n",
    "    analysis.df_train.index)\n",
    "analysis.df_valid = analysis.df_long.loc[analysis.indices_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(analysis.df_long) == len(analysis.df_train) + len(analysis.df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all samples are also in the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_train.index.levshape == (N_SAMPLES, n_features)\n",
    "\n",
    "try:\n",
    "    assert analysis.df_valid.index.levshape == (N_SAMPLES, n_features)\n",
    "except AssertionError:\n",
    "    print(f'Expected shape in validation: {(N_SAMPLES, n_features)}')\n",
    "    print(f'Shape in validation: {analysis.df_valid.index.levshape}')\n",
    "\n",
    "analysis.df_train = analysis.df_train.loc[analysis.df_valid.index.levels[0]]\n",
    "analysis.df_train = analysis.df_train.reset_index().set_index(\n",
    "    ['Sample ID', 'peptide'])  # update index categories (there is probably a better way)\n",
    "N_SAMPLES = analysis.df_valid.index.levshape[0]\n",
    "analysis.df_train.index.levshape, analysis.df_valid.index.levshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DL\n",
    "\n",
    "- [ ] move all above to separate data notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaep.models as models\n",
    "from vaep.models.cmd import get_args\n",
    "from vaep.models import ae\n",
    "\n",
    "args = get_args(batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                no_cuda=False)  # data transfer to GPU seems slow\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(f\"{args = }\", f\"{device = }\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai default device for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.torch_core\n",
    "print(f\"{torch.cuda.is_available() = }\")  # self-documenting python 3.8\n",
    "fastai.torch_core.defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison data\n",
    "\n",
    "- first impute first and last row (using n=3 replicate)\n",
    "- use pandas interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.median_train = analysis.df_train['intensity'].unstack().median()\n",
    "analysis.median_train.name = 'train_median'\n",
    "analysis.averag_train = analysis.df_train['intensity'].unstack().mean()\n",
    "analysis.averag_train.name = 'train_average'\n",
    "\n",
    "df_pred = analysis.df_valid.copy()\n",
    "\n",
    "df_pred = df_pred.join(analysis.median_train, on='peptide')\n",
    "df_pred = df_pred.join(analysis.averag_train, on='peptide')\n",
    "\n",
    "\n",
    "_ = interpolate(wide_df=analysis.df_train['intensity'].unstack())\n",
    "df_pred = df_pred.join(_)\n",
    "\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(df_pred.isna()):\n",
    "    print(\"Consecutive NaNs are not imputed using replicates.\")\n",
    "    display(df_pred.loc[df_pred.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboritive filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import CollabDataLoaders, MSELossFlat, Learner\n",
    "from fastai.collab import EmbeddingDotBias\n",
    "\n",
    "analysis.collab = Analysis()\n",
    "collab = analysis.collab\n",
    "collab.columns = 'peptide,Sample ID,intensity'.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data view for collaborative filtering\n",
    "\n",
    "- currently a bit hacky as the splitter does not support predefinded indices (create custum subclass providing splits to internal methods?)\n",
    "\n",
    "- Use the [`CollabDataLoaders`](https://docs.fast.ai/collab.html#CollabDataLoaders)  similar to the [`TabularDataLoaders`](https://docs.fast.ai/tabular.data.html#TabularDataLoaders).\n",
    "- Use the [`IndexSplitter`](https://docs.fast.ai/data.transforms.html#IndexSplitter) and provide splits to whatever is used in `CollabDataLoaders`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_train = analysis.df_train.reset_index()\n",
    "collab.df_valid = analysis.df_valid.reset_index()\n",
    "collab.df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (collab.df_train.intensity.isna().sum(),\n",
    "        collab.df_valid.intensity.isna().sum()) == (0, 0), \"Remove missing values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacky part uses training data `Datasets` from dataloaders to recreate a custom `DataLoaders` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_train = CollabDataLoaders.from_df(\n",
    "    collab.df_train, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=args.batch_size, device=device)\n",
    "collab.dl_valid = CollabDataLoaders.from_df(\n",
    "    collab.df_valid, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=args.batch_size,\n",
    "    shuffle=False, device=device)\n",
    "collab.dl_train.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "collab.dls = DataLoaders(collab.dl_train.train, collab.dl_valid.train)\n",
    "if args.cuda:\n",
    "    collab.dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collab.dls.classes['Sample ID']), len(collab.dls.classes['peptide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collab.dls.train), len(collab.dls.valid)  # mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to the hacky version, one could use a factory method, but there the sampling/Splitting methods would need to be implemented (not using [`RandomSplitter`](https://docs.fast.ai/data.transforms.html#RandomSplitter) somehow)\n",
    "\n",
    " - [`TabDataLoader`](https://docs.fast.ai/tabular.core.html#TabDataLoader)\n",
    " - uses [`TabularPandas`](https://docs.fast.ai/tabular.core.html#TabularPandas)\n",
    " \n",
    " > Current problem: No custom splitter can be provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.model_args = {}\n",
    "collab.model_args['n_samples'] = len(collab.dls.classes['Sample ID'])\n",
    "collab.model_args['n_peptides'] = len(collab.dls.classes['peptide'])\n",
    "collab.model_args['dim_latent_factors'] = latent_dim\n",
    "collab.model_args['y_range'] = (\n",
    "    int(analysis.df_train['intensity'].min()), int(analysis.df_train['intensity'].max())+1)\n",
    "\n",
    "print(\"Args:\")\n",
    "pprint(collab.model_args)\n",
    "\n",
    "\n",
    "# from vaep.models.collab import DotProductBias\n",
    "# model = DotProductBias(**collab.model_args)\n",
    "model = EmbeddingDotBias.from_classes(\n",
    "    n_factors=collab.model_args['dim_latent_factors'], classes=collab.dls.classes, y_range=collab.model_args['y_range'])\n",
    "learn = Learner(dls=collab.dls, model=model, loss_func=MSELossFlat())\n",
    "if args.cuda:\n",
    "    learn.cuda()\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(epochs_max, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.models import plot_loss\n",
    "from fastai import learner\n",
    "learner.Recorder.plot_loss = plot_loss\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.set_title('Collab loss: Reconstruction loss.')\n",
    "learn.recorder.plot_loss(skip_start=5, ax=ax)\n",
    "vaep.io_images._savefig(fig, name='collab_training',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dls.valid_ds.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.reset_index()\n",
    "pred, target = learn.get_preds()\n",
    "df_pred['intensity_pred_collab'] = pd.Series(\n",
    "    pred.flatten().numpy(), index=collab.dls.valid.items.index)\n",
    "\n",
    "npt.assert_almost_equal(\n",
    "    actual=collab.dls.valid.items.intensity.to_numpy(),\n",
    "    desired=target.numpy().flatten()\n",
    ")\n",
    "\n",
    "\n",
    "df_pred = analyzers.cast_object_to_category(df_pred)\n",
    "df_pred.set_index(['Sample ID', 'peptide'], inplace=True)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (abs(target.reshape(-1) - pred.reshape(-1))).sum() / len(target) - \\\n",
    "    (df_pred.intensity - df_pred.intensity_pred_collab).abs().sum() / \\\n",
    "    len(df_pred) < 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot biases and embedding weigths\n",
    "\n",
    "- visualize relative order of samples and peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "def get_bias(learner, indices, is_item=True) -> pd.Series:\n",
    "    ret = learner.model.bias(indices.values, is_item=is_item) # user=sample\n",
    "    return pd.Series(ret, index=indices)\n",
    "\n",
    "# def get_weigths\n",
    "\n",
    "CollabIDs = namedtuple(\"CollabIDs\", \"sample peptide\")\n",
    "\n",
    "collab.biases = CollabIDs(\n",
    "    sample=get_bias(learn, indices=analysis.df_train.index.levels[0], is_item=False), # item=peptide\n",
    "    peptide=get_bias(learn, indices=analysis.df_train.index.levels[1] )\n",
    ")\n",
    "collab.biases.sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax = collab.biases.sample.sort_values().plot(kind='line', rot=90, title='Sample biases', ax=ax)\n",
    "vaep.io_images._savefig(fig, name='collab_bias_samples',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "_ = collab.biases.peptide.sort_values().plot(kind='line', rot=90, title='Sample biases', ax=ax)\n",
    "vaep.io_images._savefig(fig, name='collab_bias_peptides',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(learner, indices, is_item=True) -> pd.Series:\n",
    "    ret = learner.model.weight(indices.values, is_item=is_item) # user=sample\n",
    "    return pd.DataFrame(ret, index=indices, columns=[f'latent dimension {i+1}' for i in range(ret.shape[-1])])\n",
    "\n",
    "collab.embeddings = CollabIDs(\n",
    "    sample=get_weight(learn, indices=analysis.df_train.index.levels[0], is_item=False), # item=peptide\n",
    "    peptide=get_weight(learn, indices=analysis.df_train.index.levels[1] )\n",
    ")\n",
    "collab.embeddings.sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "analyzers.plot_date_map(df=collab.embeddings.sample, fig=fig, ax=ax,\n",
    "                        dates=analysis.df_meta.date.loc[collab.embeddings.sample.index])\n",
    "vaep.io_images._savefig(fig, name='collab_latent_by_date',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "meta_col = 'ms_instrument'\n",
    "\n",
    "df_ = collab.embeddings.sample\n",
    "analyzers.seaborn_scatter(df=df_,\n",
    "                          fig=fig,\n",
    "                          ax=ax,\n",
    "                          meta=analysis.df_meta[meta_col].loc[df_.index],\n",
    "                          title='2D sample embedding weights by MS instrument')\n",
    "\n",
    "vaep.io_images._savefig(fig, name='collab_latent_by_ms_instrument',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder (DAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transforms\n",
    "\n",
    "- [x] Shift standard normalized data around\n",
    "    - Error metrics won't be directly comparable afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from vaep.models import ae\n",
    "\n",
    "from fastai.tabular.core import TabularPandas\n",
    "\n",
    "# from fastai.callback.core import Callback\n",
    "\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "from fastai.learner import Learner\n",
    "from fastai.losses import MSELossFlat\n",
    "\n",
    "\n",
    "# https://docs.fast.ai/tabular.core.html#FillStrategy\n",
    "# from fastai.tabular.core import FillMissing\n",
    "# from fastai.tabular.core import TabularPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert format\n",
    "# undo using `stack`\n",
    "analysis.df_train = analysis.df_train['intensity'].unstack()\n",
    "analysis.df_valid = analysis.df_valid['intensity'].unstack()\n",
    "analysis.df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and std. dev. from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = Normalize.from_stats(analysis.df_train.mean(), analysis.df_valid.std()) # copy interface?\n",
    "NORMALIZER = Normalize  # dae.NormalizeShiftedMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data\n",
    "\n",
    "procs passed to TabluarPandas are handled internally \n",
    "  1. not necessarily in order\n",
    "  2. with setup call (using current training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [NORMALIZER, FillMissing(add_col=True)]\n",
    "cont_names = list(analysis.df_train.columns)\n",
    "\n",
    "to = TabularPandas(analysis.df_train, procs=procs, cont_names=cont_names)\n",
    "print(\"Tabular object:\", type(to))\n",
    "\n",
    "to.items  # items reveals data in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better manuelly apply `Transforms` on `Tabluar` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = list(analysis.df_train.columns)\n",
    "to = TabularPandas(analysis.df_train, cont_names=cont_names, do_setup=False)\n",
    "\n",
    "tf_norm = NORMALIZER()\n",
    "_ = tf_norm.setups(to)  # returns to\n",
    "tf_fillna = FillMissing(add_col=True)\n",
    "_ = tf_fillna.setup(to)\n",
    "\n",
    "print(\"Tabular object:\", type(to))\n",
    "# _ = (procs[0]).encodes(to)\n",
    "to.items  # items reveals data in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check mean and standard deviation after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.items.iloc[:, :10].describe()  # not perferct anymore as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask is added as type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.items.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the suffix `_na` where `True` is indicating a missing value replaced by the `FillMissing` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.cont_names, to.cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(to.valid) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data\n",
    "\n",
    "- reuse training data with different mask for evaluation\n",
    "- target data is the validation data\n",
    "    - switch between training and evaluation mode for setting comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_valid = TabularPandas(\n",
    "    analysis.df_valid, cont_names=analysis.df_valid.columns.tolist())\n",
    "# assert analysis.df_valid.isna().equals(y_valid.items.isna())\n",
    "_df_valid = tf_norm.encodes(_df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_valid.items.iloc[:, :10].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "# build validation DataFrame with mask according to validation data\n",
    "# FillNA values in data as before, but do not add categorical columns (as this is done manuelly)\n",
    "_valid_df = to.conts  # same data for predictions\n",
    "_valid_df = _valid_df.join(analysis.df_valid.isna(), rsuffix='_na')  # mask\n",
    "_valid_df = _valid_df.join(_df_valid.items, rsuffix='_val')  # target\n",
    "_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [norm, FillMissing(add_col=False)]  # mask is provided explicitly\n",
    "procs = None\n",
    "\n",
    "cont_names = list(analysis.df_train.columns)\n",
    "cat_names = [f'{s}_na' for s in cont_names]\n",
    "y_names = [f'{s}_val' for s in cont_names]\n",
    "\n",
    "splits = None\n",
    "y_block = None\n",
    "to_valid = TabularPandas(_valid_df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                         y_names=y_names, splits=splits, y_block=y_block, do_setup=True)\n",
    "to_valid.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_valid = to_valid.targ.iloc[:, :100].describe()\n",
    "stats_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True = training data (\"fill_na\" transform sets mask to true in training data where values are replaced)\n",
    "to_valid.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(to_valid.cat_names) == list(\n",
    "    _valid_df.select_dtypes(include='bool').columns)  # 'object'\n",
    "assert to_valid.cats.equals(analysis.df_valid.isna().add_suffix('_na'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix and match dataloaders\n",
    "\n",
    "- train dataloader in both TabularPandas objects used\n",
    "- train dataloader in dataloaders used in both case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size\n",
    "dl_train = to.dataloaders(shuffle_train=True, shuffle=False,\n",
    "                          bs=args.batch_size).train  # , after_batch=after_batch)\n",
    "dl_valid = to_valid.dataloaders(\n",
    "    shuffle_train=False, shuffle=False, bs=args.batch_size).train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_train, dl_valid)\n",
    "b = dls.train.one_batch()\n",
    "[x.shape for x in b]  # cat, cont, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_train, dl_valid)\n",
    "b = dls.valid.one_batch()\n",
    "[x.shape for x in b]  # cat, cont, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "- standard PyTorch Model from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = analysis.df_train.shape[-1]\n",
    "model = ae.Autoencoder(n_features=M, n_neurons=int(\n",
    "    M/2), last_decoder_activation=None, dim_latent=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "- controll training loop\n",
    "    - set what is data\n",
    "    - what should be used for evaluation (differs for training and evaluation mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.ModelAdapter, ae.ModelAdapterFlatPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner: Fastai Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls=dls, model=model,\n",
    "                loss_func=MSELossFlat(), cbs=ae.ModelAdapterFlatPred())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_lr = learn.lr_find()\n",
    "suggested_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(epochs_max, lr_max=suggested_lr.valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.set_title('DAE loss: Reconstruction loss')\n",
    "learn.recorder.plot_loss(skip_start=5, ax=ax)\n",
    "vaep.io_images._savefig(fig, name='dae_training',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L(zip(learn.recorder.iters, learn.recorder.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder True: Only 500 predictions returned\n",
    "pred, target = learn.get_preds(act=noop, concat_dim=0, reorder=False)\n",
    "len(pred), len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE on transformed data is not too interesting for comparision between models if these use different standardizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func(pred, target)  # MSE in transformed space not too interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target is in expected order\n",
    "Y = dls.valid.targ\n",
    "\n",
    "npt.assert_almost_equal(\n",
    "    actual=target.numpy(),\n",
    "    desired=Y.stack().to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from fastai.tabular.core import TabularPandas\n",
    "\n",
    "df_pred['intensity_pred_dae'] = ae.transform_preds(\n",
    "    pred=pred, index=analysis.df_valid.stack().index, normalizer=tf_norm)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plot of latent space\n",
    "\n",
    "- 2 dimensional latent space: just plot\n",
    "- more than 2 dimensional: PCA, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = []\n",
    "for b in dls.valid:\n",
    "    model_input = b[1]\n",
    "    latent_space.append(model.encoder(model_input).detach().numpy())\n",
    "\n",
    "df_dae_latent = build_df_from_pred_batches(latent_space,\n",
    "                                           index=_df_valid.items.index,\n",
    "                                           columns=[f'latent dimension {i+1}' for i in range(latent_dim)])\n",
    "df_dae_latent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "analyzers.plot_date_map(df=df_dae_latent, fig=fig, ax=ax,\n",
    "                        dates=analysis.df_meta.date.loc[df_dae_latent.index])\n",
    "vaep.io_images._savefig(fig, name='dae_latent_by_date',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "meta_col = 'ms_instrument'\n",
    "\n",
    "analyzers.seaborn_scatter(df=df_dae_latent,\n",
    "                          fig=fig,\n",
    "                          ax=ax,\n",
    "                          meta=analysis.df_meta[meta_col].loc[df_dae_latent.index],\n",
    "                          title='by MS instrument')\n",
    "\n",
    "vaep.io_images._savefig(\n",
    "    fig, name=f'dae_latent_by_{meta_col}', folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn MinMaxScaler\n",
    "\n",
    "- [docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.transform import MinMaxScaler\n",
    "\n",
    "args_vae = {}\n",
    "args_vae['SCALER'] = MinMaxScaler\n",
    "# select initial data: transformed vs not log transformed\n",
    "scaler = args_vae['SCALER']().fit(analysis.df_train)\n",
    "scaler.transform(analysis.df_valid.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders\n",
    "\n",
    "- follow instructions for using plain PyTorch Datasets, see [tutorial](https://docs.fast.ai/tutorial.siamese.html#Preparing-the-data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(analysis.df_train.columns == analysis.df_valid.columns)\n",
    "if not all(analysis.df.columns == analysis.df_train.columns):\n",
    "    print(\"analysis.df columns are not the same as analysis.df_train\")\n",
    "    # ToDo: DataLoading has to be cleaned up\n",
    "    # analysis.df = analysis.df_train.fillna(analysis.df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.io.datasets import PeptideDatasetInMemory\n",
    "\n",
    "FILL_NA = 0.0\n",
    "\n",
    "train_ds = PeptideDatasetInMemory(data=scaler.transform(\n",
    "    analysis.df_train).to_numpy(dtype=None), fill_na=FILL_NA)\n",
    "valid_ds = PeptideDatasetInMemory(data=scaler.transform(analysis.df_train.fillna(analysis.df_valid)).to_numpy(dtype=None),\n",
    "                                  mask=analysis.df_valid.notna().to_numpy(), fill_na=FILL_NA)\n",
    "\n",
    "assert (train_ds.peptides == valid_ds.peptides).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, n_inp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid\n",
    "\n",
    "M = analysis.df_train.shape[-1]\n",
    "model = ae.VAE(n_features=M, n_neurons=int(\n",
    "    M/2), last_encoder_activation=None, last_decoder_activation=Sigmoid, dim_latent=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls=dls,\n",
    "                model=model,\n",
    "                loss_func=ae.loss_fct_vae,\n",
    "                cbs=ae.ModelAdapterVAE())\n",
    "\n",
    "learn.show_training_loop()\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_lr = learn.lr_find()\n",
    "suggested_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(epochs_max, lr_max=suggested_lr.valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.set_title('VAE loss: Reconstruction loss and Kullback-Leiber-Divergence for latent space')\n",
    "learn.recorder.plot_loss(skip_start=5, ax=ax)\n",
    "vaep.io_images._savefig(fig, name='vae_training',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder True: Only 500 predictions returned\n",
    "pred, target = learn.get_preds(act=noop, concat_dim=0, reorder=False)\n",
    "len(pred), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred = pd.Series(pred[0], index=analysis.df_valid.stack().index).unstack()\n",
    "_pred = scaler.inverse_transform(_pred).stack()\n",
    "\n",
    "df_pred['intensity_pred_vae'] = _pred\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add plot of latent space\n",
    "\n",
    "- 2 dimensional latent space: just plot\n",
    "- more than 2 dimensional: PCA, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = []\n",
    "for b in dls.valid:\n",
    "    model_input = b[0]\n",
    "    b_mu, b_std = model.get_mu_and_logvar(model_input, detach=True)\n",
    "    latent_space.append(b_mu)\n",
    "\n",
    "\n",
    "df_vae_latent = build_df_from_pred_batches(latent_space,\n",
    "                                           index=_df_valid.items.index,\n",
    "                                           columns=[f'latent dimension {i+1}' for i in range(latent_dim)])\n",
    "df_vae_latent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "analyzers.plot_date_map(df=df_vae_latent, fig=fig, ax=ax,\n",
    "                        dates=analysis.df_meta.date.loc[df_vae_latent.index])\n",
    "vaep.io_images._savefig(fig, name='vae_latent_by_date',\n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "meta_col = 'ms_instrument'\n",
    "\n",
    "analyzers.seaborn_scatter(df=df_vae_latent,\n",
    "                          fig=fig,\n",
    "                          ax=ax,\n",
    "                          meta=analysis.df_meta[meta_col].loc[df_vae_latent.index],\n",
    "                          title='by MS instrument')\n",
    "\n",
    "vaep.io_images._savefig(\n",
    "    fig, name=f'vae_latent_by_{meta_col}', folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the 3 models\n",
    "\n",
    "- replicates: replace NAs with neighbouring (\"close\") values\n",
    "- train average, median: Replace NA with average or median from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklm\n",
    "pred_columns = df_pred.columns[1:]\n",
    "scoring = [('MSE', sklm.mean_squared_error),\n",
    "           ('MAE', sklm.mean_absolute_error)]\n",
    "\n",
    "y_true = df_pred['intensity']\n",
    "\n",
    "metrics = {}\n",
    "for col in pred_columns:\n",
    "    _y_pred = df_pred[col].dropna()\n",
    "    if len(df_pred[col]) > len(_y_pred):\n",
    "        logger.info(\n",
    "            f\"Drop indices for {col}: {[(idx[0], idx[1]) for idx in df_pred[col].index.difference(_y_pred.index)]}\")\n",
    "\n",
    "    metrics[col] = dict(\n",
    "        [(k, f(y_true=y_true.loc[_y_pred.index], y_pred=_y_pred))\n",
    "         for k, f in scoring]\n",
    "    )\n",
    "\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics.to_csv(folder / f'exp_02_metrics.csv',\n",
    "               float_format='{:.3f}'.format)\n",
    "metrics.sort_values(by=[k for k, f in scoring], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final prediction values of validation data for later comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(folder /\n",
    "               f\"{config.FOLDER_DATA}_valid_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot for imputed and denoised data\n",
    "\n",
    "two setups:\n",
    " - impute missing values\n",
    " - additinally change observed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
