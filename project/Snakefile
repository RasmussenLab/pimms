"""
Document how all the notebooks for a single experiment are connected.
"""

configfile: "config/proteinGroups_split.yaml"
configfile: "config/proteinGroups_train.yaml"

folder_experiment = config['folder_experiment']


print(f"{folder_experiment = }")

rule all:
    input: 
        expand(f"{folder_experiment}/{{nb}}",
            nb='14_experiment_03_latent_space_analysis.ipynb')

# # rule template

# nb = '.ipynb'
# rule name:
#     input:
#         nb=nb,
#     output:
#         nb=f"{nb_outfolder}/{nb}",
#     shell:
#         "papermill {input.nb} {output.nb}"


# separate workflow by level -> provide custom configs
nb = '14_experiment_03_data.ipynb'
rule create_splits:
    input:
        nb=nb
    output:
        data=f"{folder_experiment}/data/train_X.pkl",
        nb=f"{folder_experiment}/{nb}",
    params:
        folder_experiment=folder_experiment,
        sample_completeness=config["sample_completeness"],
        min_rt_time=config["min_rt_time"]

    shell:
        "papermill {input.nb} {output.nb}"
        " -f config/split_proteinGroups.yaml"
        " -r folder_experiment {params.folder_experiment}"
        " && jupyter nbconvert --to html {output.nb}"

nb = '14_experiment_03_latent_space_analysis.ipynb'
rule train_models:
    input:
        nb=nb,
        train_split=f"{folder_experiment}/data/train_X.pkl",
    output:
        nb=f"{folder_experiment}/{nb}",
    params:
        folder_experiment=f"{folder_experiment}",
    shell:
        "papermill {input.nb} {output.nb}"
        " -f config/train_proteinGroups.yaml" # pass on config file
        " -r folder_experiment {params.folder_experiment}"
        " && jupyter nbconvert --to html {output.nb}"
