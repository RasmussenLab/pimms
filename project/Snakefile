"""
Document how all the notebooks for a single experiment are connected.
"""

configfile: "config/train_proteinGroups.yaml"

folder_experiment = config['folder_experiment']

print(f"{folder_experiment = }")

rule all:
    input: 
        expand(f"{folder_experiment}/{{nb}}",
            nb='14_experiment_03_latent_space_analysis.ipynb')

# # rule template

# nb = '.ipynb'
# rule name:
#     input:
#         nb=nb,
#     output:
#         nb=f"{nb_outfolder}/{nb}",
#     shell:
#         "papermill {input.nb} {output.nb}"


# separate workflow by level -> provide custom configs
nb = '14_experiment_03_data.ipynb'
rule create_splits:
    input:
        nb=nb,
        intensities=config['intensities'],
        metadata=config['metadata'],
    output:
        data=f"{folder_experiment}/data/train_X.pkl",
        nb=f"{folder_experiment}/{nb}",
    params:
        folder_experiment=folder_experiment,
        sample_completeness=config["sample_completeness"],
        min_rt_time=config["min_rt_time"]

    shell:
        "papermill {input.nb} {output.nb} -p FN_INTENSITIES {input.intensities}"
        " -p fn_rawfile_metadata {input.metadata}"
        " -r folder_experiment {params.folder_experiment}"
        " -p sample_completeness {params.sample_completeness}"
        " -p min_RT_max {params.min_rt_time}"
        " && jupyter nbconvert --to html {output.nb}"

nb = '14_experiment_03_latent_space_analysis.ipynb'
rule train_models:
    input:
        nb=nb,
        train_split=f"{folder_experiment}/data/train_X.pkl",
    output:
        nb=f"{folder_experiment}/{nb}",
    params:
        folder_experiment=f"{folder_experiment}",
    shell:
        "papermill {input.nb} {output.nb}"
        " -f config/train_proteinGroups.yaml" # pass on config file
        " -r folder_experiment {params.folder_experiment}"
        " && jupyter nbconvert --to html {output.nb}"
