{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02\n",
    "\n",
    "- [ ] mask entries in larger dataset in long-format\n",
    "- [ ] mask peptides based on their frequency in samples (probability of being observed)\n",
    "- [ ] create training data set without masked values for each model\n",
    "    - Denoising AE\n",
    "    - FNN based on embeddings (Collaborative Filtering)\n",
    "    - VAE\n",
    "- [ ] restrict to only a training data split of consective data: Increase number of samples.\n",
    "    - focus on best reconstruction performance\n",
    "    - mean comparison\n",
    "\n",
    "### Collaborative Filtering model\n",
    "- Cannot accomodate iid assumption of statistical test in current setup for embedding vectors.\n",
    "    - if pretrained model should be applied to an new batch of replicates (with a certain condition)\n",
    "      one would need to find a way to initialize the sample embeddings without fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from src.nb_imports import *\n",
    "\n",
    "\n",
    "import vaep.io_images\n",
    "import seaborn\n",
    "\n",
    "import numpy.testing as npt # fastcore.test functionality\n",
    "\n",
    "from pathlib import Path\n",
    "from src import metadata\n",
    "\n",
    "\n",
    "import logging\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 02\")\n",
    "\n",
    "figures = {}  # collection of ax or figures\n",
    "\n",
    "ADD_TENSORBOARD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None takes all\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only some sample have many missings\n",
    "\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / \\\n",
    "    'df_intensities_N_07813_M01000'  # all\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / \\\n",
    "    'df_intensities_N_07637_M01000'  # 60%\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / \\\n",
    "    'df_intensities_N_07285_M01000'  # 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = AnalyzePeptides(fname=FN_PEPTIDE_INTENSITIES, nrows=None)\n",
    "analysis.df.columns.name = 'peptide'\n",
    "analysis.log_transform(np.log2)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date are not possible in the indices\n",
    "rename_indices_w_wrong_dates = {'20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_03': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_03',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_12': '20180330_QE10_nLC0_MR_QC_MNT_Hela_12',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_01': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_01',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_11': '20180330_QE10_nLC0_MR_QC_MNT_Hela_11',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_02': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_02'}\n",
    "analysis.df.rename(index=rename_indices_w_wrong_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N consecutive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort index\n",
    "analysis.df.sort_index(inplace=True)\n",
    "analysis.df_all = analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N_SAMPLES = min(len(analysis.df), N_SAMPLES) if N_SAMPLES else len(analysis.df)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def get_consecutive_data_indices(df, n_samples=N_SAMPLES):\n",
    "    index = df.sort_index().index\n",
    "    start_sample = len(index) - n_samples\n",
    "    start_sample = random.randint(0, start_sample)\n",
    "    return df.loc[index[start_sample:start_sample+n_samples]]\n",
    "\n",
    "\n",
    "_attr_name = f'df_{N_SAMPLES}'\n",
    "setattr(analysis, _attr_name, get_consecutive_data_indices(analysis.df_all))\n",
    "print(\"Training data stored under:\", _attr_name)\n",
    "analysis.df = getattr(analysis, _attr_name)\n",
    "analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not analysis.df._is_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- biological stock differences in PCA plot. Show differences in models. Only see biological variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_meta = metadata.get_metadata_from_filenames(analysis.df.index)\n",
    "analysis.df_meta = pd.DataFrame.from_dict(\n",
    "    d_meta, orient='index')\n",
    "analysis.df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to find date parsing errors, used for renaming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_dates = pd.to_datetime(analysis.df_meta.date, errors='coerce').isna()\n",
    "# display(analysis.df_meta.loc[invalid_dates])\n",
    "# {i : i for i in analysis.df_meta.loc[invalid_dates].index} # to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See rare instrument types (potential labeling errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MIN_INSTRUMENT = 10\n",
    "ms_instruments = analysis.df_meta.ms_instrument.value_counts()\n",
    "ms_instruments = ms_instruments[ms_instruments > N_MIN_INSTRUMENT].index\n",
    "mask = ~analysis.df_meta.ms_instrument.isin(ms_instruments)\n",
    "analysis.df_meta.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import itertools\n",
    "from sklearn.impute import SimpleImputer\n",
    "X = SimpleImputer().fit_transform(analysis.df)\n",
    "X = vaep.pandas._add_indices(X, analysis.df)\n",
    "assert X.isna().sum().sum() == 0\n",
    "\n",
    "pca = analyzers.run_pca(X)\n",
    "cols = list(pca.columns)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(\n",
    "    15, 20), constrained_layout=True)\n",
    "\n",
    "Dim = namedtuple('DimensionsData', 'N M')\n",
    "analysis.dim = Dim(*analysis.df.shape)\n",
    "\n",
    "fig.suptitle(\n",
    "    f'First two Principal Components of {analysis.dim.M} most abundant peptides \\n for {analysis.dim.N} samples', fontsize=30)\n",
    "\n",
    "\n",
    "# by instrument\n",
    "ax = axes[0]\n",
    "pca['ms_instrument'] = analysis.df_meta['ms_instrument'].astype('category')\n",
    "# for name, group in pca.groupby('ms_instrument'):\n",
    "#     ax.scatter(x=group[cols[0]], y=group[cols[1]], label=name)\n",
    "seaborn.scatterplot(x=pca[cols[0]], y=pca[cols[1]],\n",
    "                    hue=pca['ms_instrument'], ax=ax, palette='deep')\n",
    "ax.set_title('by category', fontsize=18)\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.11, 0.5))\n",
    "\n",
    "# by dates\n",
    "ax = axes[1]\n",
    "ax.set_title('by date', fontsize=18)\n",
    "path_collection = analyzers.scatter_plot_w_dates(\n",
    "    ax, pca, dates=analysis.df_meta.date, errors='raise')\n",
    "path_collection = analyzers.add_date_colorbar(path_collection, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.io_images._savefig(fig, config.FIGUREFOLDER /\n",
    "                        f'pca_plot_raw_data_{analysis.fname_stub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots need to become interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_format(self, colname_values='intensity', inplace=False):\n",
    "    df = self.df\n",
    "    df_long = df.unstack().dropna().to_frame(colname_values)\n",
    "    df_long = df_long.reset_index('Sample ID')\n",
    "    if inplace:\n",
    "        self.df_long = df_long\n",
    "        return\n",
    "    return df_long\n",
    "\n",
    "\n",
    "get_long_format(analysis, inplace=True)\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_long.isna().sum().sum(\n",
    ") == 0, \"There are still missing values in the long format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wide_format(self, columns='Sample ID', name_values='intensity', inplace=False):\n",
    "    df_wide = self.df_long.pivot(columns=columns, values=name_values)\n",
    "    df_wide = df_wide.T\n",
    "    if inplace:\n",
    "        self.df_wide = df_wide\n",
    "        return\n",
    "    return df_wide\n",
    "\n",
    "\n",
    "get_wide_format(analysis, inplace=True)\n",
    "analysis.df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_wide.isna().sum().sum(\n",
    ") > 0, \"There are no missing values left in the wide format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling peptides by their frequency (important for later)\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_per_peptide = analysis.df.unstack().to_frame('intensity').reset_index(1, drop=True)\n",
    "freq_per_peptide = analysis.df_long['intensity']\n",
    "freq_per_peptide = freq_per_peptide.notna().groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = analysis.df.unstack().to_frame('intensity').reset_index(1)\n",
    "analysis.df_train = analysis.df_long.groupby(\n",
    "    by='Sample ID').sample(frac=0.95, weights=freq_per_peptide, random_state=42)\n",
    "analysis.df_train = analysis.df_train.reset_index().set_index([\n",
    "    'Sample ID', 'peptide'])\n",
    "analysis.df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex \n",
    "\n",
    "- use mulitindex for obtaining validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long = analysis.df_long.reset_index(\n",
    ").set_index(['Sample ID', 'peptide'])\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.indices_valid = analysis.df_long.index.difference(\n",
    "    analysis.df_train.index)\n",
    "analysis.df_valid = analysis.df_long.loc[analysis.indices_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(analysis.df_long) == len(analysis.df_train) + len(analysis.df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaep.model as vaep_model\n",
    "from vaep.cmd import get_args\n",
    "\n",
    "BATCH_SIZE, EPOCHS = 128, 30\n",
    "args = get_args(batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                no_cuda=False)  # data transfer to GPU seems slow\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(args, device, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai default device for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.torch_core\n",
    "# # device = torch.device('cpu')\n",
    "# # fastai.torch_core.defaults.device = torch.device('cpu')\n",
    "# device = fastai.torch_core.defaults.device\n",
    "# device\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai.torch_core.defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboritive filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import CollabDataLoaders, MSELossFlat, Learner\n",
    "\n",
    "analysis.collab = Analysis()\n",
    "collab = analysis.collab\n",
    "collab.columns = 'peptide,Sample ID,intensity'.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data view for collaborative filtering\n",
    "\n",
    "- currently a bit hacky as the splitter does not support predefinded indices (create custum subclass providing splits to internal methods?)\n",
    "\n",
    "- Use the [`CollabDataLoaders`](https://docs.fast.ai/collab.html#CollabDataLoaders)  similar to the [`TabularDataLoaders`](https://docs.fast.ai/tabular.data.html#TabularDataLoaders).\n",
    "- Use the [`IndexSplitter`](https://docs.fast.ai/data.transforms.html#IndexSplitter) and provide splits to whatever is used in `CollabDataLoaders`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_train = analysis.df_train.reset_index()\n",
    "collab.df_valid = analysis.df_valid.reset_index()\n",
    "collab.df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (collab.df_train.intensity.isna().sum(),\n",
    "        collab.df_valid.intensity.isna().sum()) == (0, 0), \"Remove missing values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacky part uses training data `Datasets` from dataloaders to recreate a custom `DataLoaders` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_train = CollabDataLoaders.from_df(\n",
    "    collab.df_train, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=args.batch_size, device=device)\n",
    "collab.dl_valid = CollabDataLoaders.from_df(\n",
    "    collab.df_valid, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=args.batch_size,\n",
    "    shuffle=False, device=device)\n",
    "collab.dl_train.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "collab.dls = DataLoaders(collab.dl_train.train, collab.dl_valid.train)\n",
    "if args.cuda:\n",
    "    collab.dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collab.dls.classes['Sample ID']), len(collab.dls.classes['peptide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collab.dls.train), len(collab.dls.valid)  # mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to the hacky version, one could use a factory method, but there the sampling/Splitting methods would need to be implemented (not using [`RandomSplitter`](https://docs.fast.ai/data.transforms.html#RandomSplitter) somehow)\n",
    "\n",
    " - [`TabDataLoader`](https://docs.fast.ai/tabular.core.html#TabDataLoader)\n",
    " - uses [`TabularPandas`](https://docs.fast.ai/tabular.core.html#TabularPandas)\n",
    " \n",
    " > Current problem: No custom splitter can be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_idx = [analysis.df_long.index.get_loc(key=key) for key in analysis.indices_valid]\n",
    "# splitter = IndexSplitter([valid_idx])\n",
    "# splitter(collab.df.index)\n",
    "\n",
    "# # replace in CollabDataloaders for getting splits\n",
    "# # or directly in TabularCollab\n",
    "# CollabDataLoaders??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop NAs before?\n",
    "#\n",
    "# from fastai.tabular.all import *\n",
    "# from fastai.tabular.data import TabularDataLoaders\n",
    "# collab.dls = TabularDataLoaders.from_df(\n",
    "#     df=analysis.df_long.reset_index(),\n",
    "#     procs=[Categorify],\n",
    "#     valid_idx=valid_idx,\n",
    "#     cat_names=['Sample ID', 'peptide'],\n",
    "#     y_names=['intensity'],\n",
    "#     with_cont=False,\n",
    "#     y_block=TransformBlock(),\n",
    "#     bs=64)\n",
    "# collab.dls.show_batch()\n",
    "# # Problem: this return a second empty df - > would need to adapt model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief check that the values match roughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.testing import assert_almost_equal\n",
    "# UPTODECIMAL = 5\n",
    "# assert_almost_equal(\n",
    "#     collab.dls.valid_ds['intensity'].values,\n",
    "#     analysis.df_long.iloc[valid_idx]['intensity'],\n",
    "#     decimal=UPTODECIMAL\n",
    "# )\n",
    "# print(f\"Values match up to the {UPTODECIMAL} decimal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.model_args = {}\n",
    "collab.model_args['n_samples'] = len(collab.dls.classes['Sample ID'])\n",
    "collab.model_args['n_peptides'] = len(collab.dls.classes['peptide'])\n",
    "collab.model_args['dim_latent_factors'] = 20\n",
    "collab.model_args['y_range'] = (\n",
    "    int(analysis.df_train['intensity'].min()), int(analysis.df_train['intensity'].max())+1)\n",
    "\n",
    "print(\"Args:\")\n",
    "pprint(collab.model_args)\n",
    "\n",
    "\n",
    "model = vaep_model.DotProductBias(**collab.model_args)\n",
    "learn = Learner(dls=collab.dls, model=model, loss_func=MSELossFlat())\n",
    "if args.cuda:\n",
    "    learn.cuda()\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dls.valid_ds.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# dtype = pd.CategoricalDtype(collab.dls.classes['peptide'], ordered=False)\n",
    "# pd.Categorical.from_codes(codes=collab.dls.valid_ds.items['Sample ID'], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show False does not return results..\n",
    "res = learn.show_results(show=True)  # something similar with return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = collab.df_valid.copy()\n",
    "pred, target = learn.get_preds()\n",
    "df_pred['intensity_pred_collab'] = pd.Series(\n",
    "    pred.flatten().numpy(), index=collab.dls.valid.items.index)\n",
    "\n",
    "npt.assert_almost_equal(\n",
    "    actual=collab.dls.valid.items.intensity.to_numpy(),\n",
    "    desired=target.numpy().flatten()\n",
    ")\n",
    "\n",
    "\n",
    "def cast_object_to_category(df):\n",
    "    \"\"\"Object to category dtype.\"\"\"\n",
    "    _columns = df.select_dtypes(include='object').columns\n",
    "    return df.astype({col: 'category' for col in _columns})\n",
    "\n",
    "\n",
    "df_pred = cast_object_to_category(df_pred)\n",
    "df_pred.set_index(['Sample ID', 'peptide'], inplace=True)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adapt to get prediction Dataframe\n",
    "# encodings, pred, target = learn.get_preds(\n",
    "#     with_input=True)  # per default validation data\n",
    "# pred_df = pd.DataFrame([{'Sample ID': collab.dls.classes['Sample ID'][obs[0]], 'peptide': collab.dls.classes['peptide']\n",
    "#                          [obs[1]], 'intensity_pred_collab': pred_intensity.item(), 'intensity': orig_intensity.item() } for obs, pred_intensity, orig_intensity in zip(encodings, pred, target)])\n",
    "# # pred_df = pred_df.pivot(index='Sample ID', columns='peptide')\n",
    "# pred_df.sort_values(by=['Sample ID', 'peptide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(target - pred)).sum() / len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder (DAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transforms\n",
    "\n",
    "- [x] Shift standard normalized data around\n",
    "    - Error metrics won't be directly comparable afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import store_attr\n",
    "from fastcore.imports import noop\n",
    "from fastai.data.transforms import Normalize, broadcast_vec\n",
    "\n",
    "\n",
    "class NormalizeShiftedMean(Normalize):\n",
    "    \"Normalize/denorm batch of `TensorImage` with shifted mean and scaled variance.\"\n",
    "\n",
    "    def __init__(self, mean=None, std=None, axes=(0, 2, 3),\n",
    "                 shift_mu=0.5, scale_var=2): store_attr()\n",
    "\n",
    "    def setups(self, to: Tabular):\n",
    "        store_attr(but='to', means=dict(getattr(to, 'train', to).conts.mean()),\n",
    "                   stds=dict(getattr(to, 'train', to).conts.std(ddof=0)+1e-7))\n",
    "        self.shift_mu = 0.5\n",
    "        self.scale_var = 2\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to: Tabular):\n",
    "        to.conts = (to.conts-self.means) / self.stds\n",
    "        to.conts = to.conts / self.scale_var + self.shift_mu\n",
    "        return to\n",
    "\n",
    "    def decodes(self, to: Tabular):\n",
    "        to.conts = (to.conts - self.shift_mu) * self.scale_var\n",
    "        to.conts = (to.conts*self.stds) + self.means\n",
    "        return to\n",
    "\n",
    "    _docs = dict(encodes=\"Normalize batch with shifted mean and scaled variance\",\n",
    "                 decodes=\"Normalize batch with shifted mean and scaled variance\")\n",
    "\n",
    "\n",
    "# test with Tabular data somehow\n",
    "test_data_view = analysis.df.iloc[:100, :10]\n",
    "\n",
    "# norm_shifted = Normalize.from_stats(mean=test_data_view.mean(), std=test_data_view.std())\n",
    "# norm_shifted = NormalizeShiftedMean.from_stats(mean=test_data_view.mean(), std=test_data_view.std())\n",
    "\n",
    "procs = [NormalizeShiftedMean, FillMissing(add_col=True)]\n",
    "cont_names = list(set(test_data_view))\n",
    "to = TabularPandas(test_data_view, procs=procs, cat_names=None,\n",
    "                   cont_names=cont_names, y_names=None, splits=None, y_block=None, do_setup=True)\n",
    "to.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAi uses singledispatch internally to modify \"Normalization\" dependent on the type annotations!\n",
    "\n",
    "  - see `Transform` [docs](https://fastcore.fast.ai/transform.html#Transform) (`Transform` itself is part of fastcore library)\n",
    " \n",
    "  - see the `Transform`'s meta class [`__call__` function](https://github.com/fastai/fastcore/blob/ae8148c85a0c57cc7fd6aa29fa13bdbfbe59be22/fastcore/transform.py#L33-L39) for the \"singledispatch\"/\"typedispatch\" functionality shown below \n",
    "  - `Normalize` typedispatch added for each application, [here `Tabular`](https://github.com/fastai/fastai/blob/99d38fec7207db9b4209568bebc85ded7e3d3f1b/fastai/tabular/core.py#L269-L283)\n",
    "  - checkout [`TabularProc`](https://docs.fast.ai/tabular.core.html#TabularProc) and [`InPlaceTransform`](https://fastcore.fast.ai/transform.html#InplaceTransform)\n",
    "\n",
    "> Check what happens if one removes `to:Tabular`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This would replace the Normalization for Tabular objects\n",
    "# @Normalize\n",
    "# def setups(self, to:Tabular):\n",
    "#     store_attr(but='to', means=dict(getattr(to, 'train', to).conts.mean()),\n",
    "#                stds=dict(getattr(to, 'train', to).conts.std(ddof=0)+1e-7))\n",
    "#     self.shift_mu = 0.5\n",
    "#     self.scale_var = 2\n",
    "#     return self(to)\n",
    "\n",
    "# @Normalize\n",
    "# def encodes(self, to:Tabular):\n",
    "#     to.conts = (to.conts-self.means) / self.stds\n",
    "#     to.conts =  to.conts / self.scale_var + self.shift_mu\n",
    "#     return to\n",
    "\n",
    "# @Normalize\n",
    "# def decodes(self, to:Tabular):\n",
    "#     to.conts = (to.conts - self.shift_mu) * self.scale_var\n",
    "#     to.conts = (to.conts*self.stds ) + self.means\n",
    "#     return to\n",
    "\n",
    "# # test with Tabular data somehow\n",
    "# test_data_view = analysis.df.iloc[:100, :10]\n",
    "\n",
    "# # norm_shifted = Normalize.from_stats(mean=test_data_view.mean(), std=test_data_view.std())\n",
    "# # norm_shifted = NormalizeShiftedMean.from_stats(mean=test_data_view.mean(), std=test_data_view.std())\n",
    "\n",
    "# procs = [Normalize, FillMissing(add_col=True)]\n",
    "# cont_names = list(set(test_data_view))\n",
    "# to = TabularPandas(test_data_view, procs=procs, cat_names=None,\n",
    "#                    cont_names=cont_names, y_names=None, splits=None, y_block=None, do_setup=True)\n",
    "# to.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.core import Callback\n",
    "\n",
    "from fastai.data.core import DataLoaders\n",
    "# from fastai.data.transforms import Normalize\n",
    "\n",
    "# from fastai.learner import *\n",
    "from fastai.learner import Learner\n",
    "from fastai.losses import MSELossFlat\n",
    "\n",
    "\n",
    "# https://docs.fast.ai/tabular.core.html#FillStrategy\n",
    "# from fastai.tabular.core import FillMissing\n",
    "# from fastai.tabular.core import TabularPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert format\n",
    "analysis.df_train = analysis.df_train['intensity'].unstack() #undo using `stack`\n",
    "analysis.df_valid = analysis.df_valid['intensity'].unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and std. dev. from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = Normalize.from_stats(analysis.df_train.mean(), analysis.df_valid.std()) # copy interface?\n",
    "NORMALIZER = Normalize # NormalizeShiftedMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data\n",
    "\n",
    "procs passed to TabluarPandas are handled internally \n",
    "  1. not necessarily in order\n",
    "  2. with setup call (using current training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [NORMALIZER, FillMissing(add_col=True)]\n",
    "cont_names = list(analysis.df_train.columns)\n",
    "\n",
    "to = TabularPandas(analysis.df_train, procs=procs, cont_names=cont_names)\n",
    "print(\"Tabular object:\", type(to))\n",
    "\n",
    "to.items # items reveals data in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better manuelly apply `Transforms` on `Tabluar` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = list(analysis.df_train.columns)\n",
    "to = TabularPandas(analysis.df_train, cont_names=cont_names, do_setup=False)\n",
    "\n",
    "\n",
    "tf_norm = NORMALIZER()\n",
    "_ = tf_norm.setups(to) # returns to\n",
    "tf_fillna = FillMissing(add_col=True)\n",
    "_ = tf_fillna.setup(to)\n",
    "\n",
    "print(\"Tabular object:\", type(to))\n",
    "# _ = (procs[0]).encodes(to)\n",
    "to.items # items reveals data in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check mean and standard deviation after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.items.iloc[:, :10].describe()  # not perferct anymore as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask is added as type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.items.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the suffix `_na` where `True` is indicating a missing value replaced by the `FillMissing` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.cont_names, to.cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(to.valid) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data\n",
    "\n",
    "- reuse training data with different mask for evaluation\n",
    "- target data is the validation data\n",
    "    - switch between training and evaluation mode for setting comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_valid = TabularPandas(analysis.df_valid,cont_names=analysis.df_valid.columns.tolist())\n",
    "# assert analysis.df_valid.isna().equals(y_valid.items.isna())\n",
    "_df_valid = tf_norm.encodes(_df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_valid.items.iloc[:,:10].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "# build validation DataFrame with mask according to validation data\n",
    "# FillNA values in data as before, but do not add categorical columns (as this is done manuelly)\n",
    "_valid_df = to.conts  # same data for predictions\n",
    "_valid_df = _valid_df.join(analysis.df_valid.isna(), rsuffix='_na')  # mask\n",
    "_valid_df = _valid_df.join(_df_valid.items, rsuffix='_val')  # target\n",
    "_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.core import TabularPandas\n",
    "procs = None #[norm, FillMissing(add_col=False)]  # mask is provided explicitly\n",
    "\n",
    "cont_names = list(analysis.df_train.columns)\n",
    "cat_names = [f'{s}_na' for s in cont_names]\n",
    "y_names = [f'{s}_val' for s in cont_names]\n",
    "\n",
    "splits = None\n",
    "y_block = None\n",
    "to_valid = TabularPandas(_valid_df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                         y_names=y_names, splits=splits, y_block=y_block, do_setup=True)\n",
    "to_valid.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_valid = to_valid.targ.iloc[:, :100].describe()\n",
    "stats_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_valid.cats # True = training data (\"fill_na\" transform sets mask to true in training data where values are replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(to_valid.cat_names) == list(\n",
    "    _valid_df.select_dtypes(include='bool').columns)\n",
    "assert to_valid.cats.equals(analysis.df_valid.isna().add_suffix('_na'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader\n",
    "\n",
    "- [ ] can they plukked in efficiently as suggested by fastai paper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vaep.transform import ShiftedStandardScaler\n",
    "\n",
    "# args_ae = {}\n",
    "# args_ae['SCALER'] = StandardScaler\n",
    "# args_ae['SCALER'] = ShiftedStandardScaler\n",
    "\n",
    "# # select initial data: transformed vs not log transformed\n",
    "# scaler = args_ae['SCALER'](scale_var=2).fit(analysis.df_train)\n",
    "# # five examples from validation dataset\n",
    "# scaler.transform(analysis.df_train).describe(percentiles=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# from vaep.io.datasets import PeptideDatasetInMemoryMasked\n",
    "\n",
    "# # ToDo: replace with helper class (see below)\n",
    "# tf_norm = None  # replace with Normalizer\n",
    "\n",
    "# dataset_train = PeptideDatasetInMemoryMasked(\n",
    "#     data=scaler.transform(analysis.df_train.values))\n",
    "# dataset_valid = PeptideDatasetInMemoryMasked(\n",
    "#     data=scaler.transform(analysis.df_valid.values))\n",
    "# dl_train = DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True)\n",
    "# dl_valid = DataLoader(dataset_valid, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix and match dataloaders\n",
    "\n",
    "- train dataloader in both TabularPandas objects used\n",
    "- train dataloader in dataloaders used in both case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size\n",
    "dl_train = to.dataloaders(shuffle_train=True, shuffle=False,\n",
    "                          bs=args.batch_size).train  # , after_batch=after_batch)\n",
    "dl_valid = to_valid.dataloaders(\n",
    "    shuffle_train=False, shuffle=False, bs=args.batch_size).train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_train, dl_valid)\n",
    "b = dls.train.one_batch()\n",
    "[x.shape for x in b]  # cat, cont, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_train, dl_valid)\n",
    "b = dls.valid.one_batch()\n",
    "[x.shape for x in b]  # cat, cont, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "- standard PyTorch Model from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = analysis.df_train.shape[-1]\n",
    "model = vaep_model.Autoencoder(n_features=M, n_neurons=int(\n",
    "    M/2), last_decoder_activation=None, dim_latent=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "- controll training loop\n",
    "    - set what is data\n",
    "    - what should be used for evaluation (differs for training and evaluation mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAdapter(Callback):\n",
    "    \"\"\"Models forward only expects on input matrix. \n",
    "    Apply mask from dataloader to both pred and targets.\"\"\"\n",
    "\n",
    "    def __init__(self, p=0.1):\n",
    "        self.do = torch.nn.Dropout(p=p)  # for denoising AE\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"\"\"Remove cont. values from batch (mask)\"\"\"\n",
    "        # assert self.yb\n",
    "        mask, data = self.xb  # x_cat, x_cont\n",
    "        self.learn._mask = mask != 1\n",
    "        if self.training:\n",
    "            self.learn.yb = (data[self.learn._mask],)\n",
    "        # dropout data using median\n",
    "        self.learn.xb = (self.do(data),)\n",
    "        #         # could be function handeled by switch set at beginning of evaluation/training?\n",
    "        #         if self.training:\n",
    "        #             self.learn.yb = (data[self.learn._mask],)\n",
    "        #         else:\n",
    "        #             # self.y is not available at \"before_batch\" - > why?\n",
    "        #             self.learn.yb = (self.y[mask],)\n",
    "\n",
    "    def after_pred(self):\n",
    "        M = self._mask.shape[-1]\n",
    "\n",
    "        if not self.training:\n",
    "            if len(self.yb):\n",
    "                self.learn.yb = (self.y[self.learn._mask],)\n",
    "                self.val_targets.append(self.learn.yb[0])\n",
    "                \n",
    "\n",
    "        #         self.learn.pred = self.pred.view(-1, M)[self._mask] #is this flat?\n",
    "        self.learn.pred = self.pred[self._mask] #is this flat?\n",
    "        if not self.training:\n",
    "            self.val_preds.append(self.learn.pred)\n",
    "        \n",
    "    def before_validate(self):\n",
    "        \"containers for current predictions\"\n",
    "        self.learn.val_preds,self.learn.val_targets = [],[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner: Fastai Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls=dls, model=model,\n",
    "                loss_func=MSELossFlat(), cbs=ModelAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_lr = learn.lr_find()\n",
    "suggested_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = learn.dls.one_batch()\n",
    "learn.one_batch(0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30, lr_max=suggested_lr.lr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.val_preds, learn.val_targets #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L(zip(learn.recorder.iters, learn.recorder.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = learn.get_preds(act=noop, concat_dim=0, reorder=False) # reorder True: Only 500 predictions returned\n",
    "len(pred), len(target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE on transformed data is not too interesting for comparision between models if these use different standardizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func(pred, target) # MSE in transformed space not too interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target is in expected order\n",
    "Y = dls.valid.targ\n",
    "\n",
    "npt.assert_almost_equal(\n",
    "    actual=target.numpy(),\n",
    "    desired=Y.stack().to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_preds(pred:torch.Tensor, index:pd.Index):\n",
    "    pred = pd.Series(pred, index).unstack()\n",
    "    pred = TabularPandas(pred, cont_names=list(pred.columns))\n",
    "    _ = tf_norm.decode(pred)\n",
    "    pred = pred.items.stack()\n",
    "    return pred\n",
    "\n",
    "df_pred['intensity_pred_dae'] = transform_preds(pred=pred, index=analysis.df_valid.stack().index)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms - FastAi MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "# X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn MinMaxScaler\n",
    "\n",
    "- [docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.transform import MinMaxScaler\n",
    "\n",
    "args_vae = {}\n",
    "args_vae['SCALER'] = MinMaxScaler\n",
    "# select initial data: transformed vs not log transformed\n",
    "scaler = args_vae['SCALER']().fit(analysis.df_train)\n",
    "scaler.transform(analysis.df_valid.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklm\n",
    "pred_columns = df_pred.columns[df_pred.columns.str.contains('pred')]\n",
    "scoring =     [('MSE',sklm.mean_squared_error),\n",
    "    ('MAE',sklm.mean_absolute_error)]\n",
    "\n",
    "y_true = df_pred['intensity']\n",
    "\n",
    "metrics = {}\n",
    "for col in pred_columns:\n",
    "    metrics[col] = dict(\n",
    "        [(k, f(y_true=y_true, y_pred=df_pred[col])) for k, f in scoring]\n",
    "    )\n",
    "    \n",
    "#     sklm.mean_absolute_error\n",
    "\n",
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final prediction values of validation data for later comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(config.FOLDER_DATA / f\"{config.FOLDER_DATA}_valid_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
