{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02\n",
    "\n",
    "- [ ] mask entries in larger dataset in long-format\n",
    "- [ ] mask peptides based on their frequency in samples (probability of being observed)\n",
    "- [ ] create training data set without masked values for each model\n",
    "    - Denoising AE\n",
    "    - FNN based on embeddings (Collaborative Filtering)\n",
    "    - VAE\n",
    "- [ ] restrict to only a training data split of consective data: Increase number of samples.\n",
    "    - focus on best reconstruction performance\n",
    "    - mean comparison\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nb_imports import *\n",
    "\n",
    "from pathlib import Path\n",
    "from src import metadata\n",
    "\n",
    "import logging\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 02\")\n",
    "\n",
    "figures = {}  # collection of ax or figures\n",
    "\n",
    "ADD_TENSORBOARD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only some sample have many missings\n",
    "FN_PEPTIDE_INTENSITIES = Path('data') / 'df_intensities_N_07813_M01000'  # all\n",
    "FN_PEPTIDE_INTENSITIES = Path('data') / 'df_intensities_N_07637_M01000'  # 60%\n",
    "FN_PEPTIDE_INTENSITIES = Path('data') / 'df_intensities_N_07285_M01000'  # 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = AnalyzePeptides(fname=FN_PEPTIDE_INTENSITIES, nrows=None)\n",
    "analysis.df.columns.name = 'peptide'\n",
    "analysis.log_transform(np.log2)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date are not possible in the indices\n",
    "rename_indices_w_wrong_dates = {'20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_03': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_03',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_12': '20180330_QE10_nLC0_MR_QC_MNT_Hela_12',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_01': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_01',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_11': '20180330_QE10_nLC0_MR_QC_MNT_Hela_11',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_02': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_02'}\n",
    "analysis.df.rename(index=rename_indices_w_wrong_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- biological stock differences in PCA plot. Show differences in models. Only see biological variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_meta = metadata.get_metadata_from_filenames(analysis.df.index)\n",
    "analysis.df_meta = pd.DataFrame.from_dict(\n",
    "    d_meta, orient='index')\n",
    "analysis.df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to find date parsing errors, used for renaming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_dates = pd.to_datetime(analysis.df_meta.date, errors='coerce').isna()\n",
    "# display(analysis.df_meta.loc[invalid_dates])\n",
    "# {i : i for i in analysis.df_meta.loc[invalid_dates].index} # to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See rare instrument types (potential labeling errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MIN_INSTRUMENT = 10\n",
    "ms_instruments = analysis.df_meta.ms_instrument.value_counts()\n",
    "ms_instruments = ms_instruments[ms_instruments > N_MIN_INSTRUMENT].index\n",
    "mask = ~analysis.df_meta.ms_instrument.isin(ms_instruments)\n",
    "analysis.df_meta.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.impute import SimpleImputer\n",
    "X = SimpleImputer().fit_transform(analysis.df)\n",
    "X = vaep.pandas._add_indices(X, analysis.df)\n",
    "assert X.isna().sum().sum() == 0\n",
    "\n",
    "pca = analyzers.run_pca(X)\n",
    "cols = list(pca.columns)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(\n",
    "    15, 20), constrained_layout=True)\n",
    "fig.suptitle('First two Principal Components of entire dataset', fontsize=30)\n",
    "\n",
    "\n",
    "# by instrument\n",
    "ax = axes[0]\n",
    "pca['ms_instrument'] = analysis.df_meta['ms_instrument'].astype('category')\n",
    "for name, group in pca.groupby('ms_instrument'):\n",
    "    ax.scatter(x=group[cols[0]], y=group[cols[1]], label=name)\n",
    "ax.set_title('by category', fontsize=18)\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.11, 0.5))\n",
    "\n",
    "# by dates\n",
    "ax = axes[1]\n",
    "ax.set_title('by date', fontsize=18)\n",
    "path_collection = analyzers.scatter_plot_w_dates(\n",
    "    ax, pca, dates=analysis.df_meta.date, errors='raise')\n",
    "path_collection = analyzers.add_date_colorbar(path_collection, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_format(self, colname_values='intensity', inplace=False):\n",
    "    df = self.df\n",
    "    df_long = df.unstack().dropna().to_frame(colname_values)\n",
    "    df_long = df_long.reset_index('Sample ID')\n",
    "    if inplace:\n",
    "        self.df_long = df_long\n",
    "        return\n",
    "    return df_long\n",
    "\n",
    "\n",
    "get_long_format(analysis, inplace=True)\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_long.isna().sum().sum() == 0, \"There are still missing values in the long format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wide_format(self, columns='Sample ID', name_values='intensity', inplace=False):\n",
    "    df_wide = self.df_long.pivot(columns=columns, values=name_values)\n",
    "    df_wide = df_wide.T\n",
    "    if inplace:\n",
    "        self.df_wide = df_wide\n",
    "        return\n",
    "    return df_wide\n",
    "\n",
    "\n",
    "get_wide_format(analysis, inplace=True)\n",
    "analysis.df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_wide.isna().sum().sum() > 0, \"There are no missing values left in the wide format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling peptides by their frequency (important for later)\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_per_peptide = analysis.df.unstack().to_frame('intensity').reset_index(1, drop=True)\n",
    "freq_per_peptide = analysis.df_long['intensity']\n",
    "freq_per_peptide = freq_per_peptide.notna().groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = analysis.df.unstack().to_frame('intensity').reset_index(1)\n",
    "analysis.df_train = analysis.df_long.groupby(\n",
    "    by='Sample ID').sample(frac=0.95, weights=freq_per_peptide)\n",
    "analysis.df_train = analysis.df_train.reset_index().set_index([\n",
    "    'Sample ID', 'peptide'])\n",
    "analysis.df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiindex \n",
    "\n",
    "- use mulitindex for obtaining validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long = analysis.df_long.reset_index(\n",
    ").set_index(['Sample ID', 'peptide'])\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.indices_valid = analysis.df_long.index.difference(\n",
    "    analysis.df_train.index)\n",
    "analysis.df_valid = analysis.df_long.loc[analysis.indices_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(analysis.df_long) == len(analysis.df_train) + len(analysis.df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaep.model as vaep_model\n",
    "from vaep.cmd import get_args\n",
    "\n",
    "BATCH_SIZE, EPOCHS = 8, 30\n",
    "args = get_args(batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                no_cuda=True)  # data transfer to GPU seems slow\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(args, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboritive filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import CollabDataLoaders, MSELossFlat, Learner\n",
    "# from types import SimpleNamespace\n",
    "\n",
    "analysis.collab = Analysis()\n",
    "collab = analysis.collab\n",
    "collab.columns = 'peptide,Sample ID,intensity'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_train = analysis.df_train.reset_index()\n",
    "collab.df_valid = analysis.df_valid.reset_index()\n",
    "collab.df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (collab.df_train.intensity.isna().sum(),\n",
    "        collab.df_valid.intensity.isna().sum()) == (0, 0), \"Remove missing values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_train = CollabDataLoaders.from_df(\n",
    "    collab.df_train, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=64)\n",
    "collab.dl_valid = CollabDataLoaders.from_df(\n",
    "    collab.df_valid, valid_pct=0.0, user_name='Sample ID', item_name='peptide', rating_name='intensity', bs=64, \n",
    "    shuffle=False)\n",
    "collab.dl_train.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(collab.dl_train.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dl_valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "collab.dls = DataLoaders(collab.dl_train.train, collab.dl_valid.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collab.dls.classes['Sample ID']), len(collab.dls.classes['peptide'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to the hacky version, one could use a factory method, but there the sampling/Splitting methods would need to be implemented (not using [`RandomSplitter`](https://docs.fast.ai/data.transforms.html#RandomSplitter) somehow)\n",
    "\n",
    " - [`TabDataLoader`](https://docs.fast.ai/tabular.core.html#TabDataLoader)\n",
    " - uses [`TabularPandas`](https://docs.fast.ai/tabular.core.html#TabularPandas)\n",
    " \n",
    " > Current problem: No custom splitter can be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop NAs before?\n",
    "# valid_idx = [analysis.df_long.index.get_loc(key=key) for key in analysis.indices_valid]\n",
    "# from fastai.tabular.all import *\n",
    "# from fastai.tabular.data import TabularDataLoaders\n",
    "# collab.dls = TabularDataLoaders.from_df(\n",
    "#     df=analysis.df_long.reset_index(), \n",
    "#     procs=[Categorify],\n",
    "#     valid_idx=valid_idx,\n",
    "#     cat_names=['Sample ID', 'peptide'],\n",
    "#     y_names=['intensity'],\n",
    "#     with_cont=False,\n",
    "#     y_block=TransformBlock(),\n",
    "#     bs=64)\n",
    "# collab.dls.show_batch()\n",
    "# # Problem: this return a second empty df - > would need to adapt model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief check that the values match roughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.testing import assert_almost_equal\n",
    "# UPTODECIMAL = 5\n",
    "# assert_almost_equal(\n",
    "#     collab.dls.valid_ds['intensity'].values, \n",
    "#     analysis.df_long.iloc[valid_idx]['intensity'],\n",
    "#     decimal=UPTODECIMAL\n",
    "# )\n",
    "# print(f\"Values match up to the {UPTODECIMAL} decimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import fastai.torch_core\n",
    "# device = torch.device('cpu')\n",
    "# fastai.torch_core.defaults.device = torch.device('cpu')\n",
    "device = fastai.torch_core.defaults.device\n",
    "\n",
    "collab.model_args = {}\n",
    "collab.model_args['n_samples'] = len(collab.dls.classes['Sample ID'])\n",
    "collab.model_args['n_peptides'] = len(collab.dls.classes['peptide'])\n",
    "collab.model_args['dim_latent_factors'] = 20\n",
    "collab.model_args['y_range'] = (\n",
    "    int(analysis.df_train['intensity'].min()), int(analysis.df_train['intensity'].max())+1)\n",
    "\n",
    "print(\"Args:\")\n",
    "pprint(collab.model_args)\n",
    "\n",
    "model = vaep_model.DotProductBias(**collab.model_args).to(device)\n",
    "learn = Learner(dls=collab.dls, model=model, loss_func=MSELossFlat())\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(target - preds)).sum() / len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab.dls.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show False does not return results..\n",
    "res = learn.show_results(show=True)  # something similar with return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adapt to get prediction Ddataframe\n",
    "# encodings, pred, target = learn.get_preds(\n",
    "#     with_input=True)  # per default validation data\n",
    "# pred_df = pd.DataFrame([{'Sample ID': dls.classes['Sample ID'][obs[0]], 'peptide': dls.classes['peptide']\n",
    "#                          [obs[1]], 'intensity': pred_intensity.item()} for obs, pred_intensity in zip(encodings, pred)])\n",
    "# pred_df = pred_df.pivot(index='Sample ID', columns='peptide')\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder (DAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
