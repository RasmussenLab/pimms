{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import config\n",
    "from src.analyzers import *\n",
    "from vaep.transform import StandardScaler, get_df_fitted_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = logging.getLogger()  # returns root-logger\n",
    "logger.setLevel(logging.CRITICAL)  # silence for everything else\n",
    "logger.handlers = []\n",
    "\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "- 1000 features (most abundant peptides)\n",
    "- later a subset of samples is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_TO_LOAD = None\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N_07813_M01000'\n",
    "analysis = AnalyzePeptides(\n",
    "    fname=FN_PEPTIDE_INTENSITIES, nrows=N_SAMPLES_TO_LOAD)\n",
    "analysis.df = analysis.df.sort_index()  # sort by date\n",
    "assert analysis.df.index.is_unique, \"Non-unique training samples\"\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select consecutives samples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "logger.info(f\"Selected {N_SAMPLES}\")\n",
    "analysis.N_SAMPLES = N_SAMPLES\n",
    "\n",
    "\n",
    "def get_consecutive_data_indices(index, n_samples=N_SAMPLES):\n",
    "    start_sample = len(index) - n_samples\n",
    "    start_sample = random.randint(0, start_sample)\n",
    "    return index[start_sample:start_sample+n_samples]\n",
    "\n",
    "\n",
    "indices_selected = get_consecutive_data_indices(analysis.df.index)\n",
    "analysis.samples = indices_selected\n",
    "analysis.df = analysis.df.loc[indices_selected]\n",
    "\n",
    "FRACTION = 0.9\n",
    "\n",
    "class Indices(SimpleNamespace):\n",
    "    pass\n",
    "\n",
    "indices = Indices()\n",
    "indices.train, indices.valid = indices_selected[:int(\n",
    "    FRACTION*N_SAMPLES)], indices_selected[int(FRACTION*N_SAMPLES):]\n",
    "analysis.indices = indices\n",
    "\n",
    "analysis.df_train = analysis.df.loc[indices.train]\n",
    "analysis.df_valid = analysis.df.loc[indices.valid]\n",
    "\n",
    "analysis.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meta data from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import metadata\n",
    "\n",
    "data_meta = metadata.get_metadata_from_filenames(indices_selected)\n",
    "analysis.df_meta = pd.DataFrame.from_dict(\n",
    "    data_meta, orient='index')\n",
    "# analysis.df_meta['date'] = pd.to_datetime(analysis.df_meta['date'])\n",
    "analysis.df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- possibility to group data in time along `(machine, lc)` pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.loc[indices.train].describe(datetime_is_numeric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This becomes part of analysis\n",
    "def compare_meta_data_for_splits(meta, indices):\n",
    "\n",
    "    _indices = vars(indices)\n",
    "    logger.info('Found vars: {}'.format(', '.join(str(x)\n",
    "                                                  for x in _indices.keys())))\n",
    "\n",
    "    for key_split, split in _indices.items():\n",
    "        print(f\"{key_split:8} - split description:\")\n",
    "        display(\n",
    "            meta.loc[split].describe(datetime_is_numeric=True)\n",
    "        )\n",
    "\n",
    "    _meta_features = list(meta.columns)\n",
    "\n",
    "    for _column in _meta_features:\n",
    "        display(\n",
    "            _=pd.DataFrame({\n",
    "                key_split: meta.loc[split, _column].value_counts(normalize=True) for key_split, split in _indices.items()\n",
    "            }).sort_index().plot(kind='line', rot=90, figsize=(10, 5), title=f\"{_column} value Counts for different splits\")\n",
    "        )\n",
    "\n",
    "\n",
    "compare_meta_data_for_splits(analysis.df_meta.iloc[:, :2], indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis state so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# import importlib; importlib.reload(vaep.model)\n",
    "from vaep.model import train\n",
    "from vaep.model import VAE\n",
    "from vaep.model import loss_function\n",
    "from vaep.cmd import get_args\n",
    "from vaep.tf_board import TensorboardModelNamer\n",
    "\n",
    "from vaep.io.datasets import PeptideDatasetInMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(no_cuda=True) # data transfer to GPU seems slow\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "args.epochs = 30\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_limit = np.log10(analysis.df).min().min()  # all zeros become nan.\n",
    "\"Detection limit: {:6.3f}, corresponding to intensity value of {:,d}\".format(\n",
    "    detection_limit,\n",
    "    int(10 ** detection_limit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = analysis.df.shape\n",
    "\"N samples: {:10,d} - N Peptides: {:10,d}\".format(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis.indices.valid), analysis.indices.valid[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-log transformed data (Single run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale samples according to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select initial data: transformed vs not log transformed\n",
    "scaler = StandardScaler().fit(analysis.df_train)\n",
    "# five examples from validation dataset\n",
    "scaler.transform(analysis.df_valid.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(df_train, df_valid, scaler):\n",
    "    data_train = PeptideDatasetInMemory(\n",
    "        data=scaler.transform(df_train))\n",
    "    data_valid = PeptideDatasetInMemory(data=scaler.transform(df_valid))\n",
    "\n",
    "    dl_train = torch.utils.data.DataLoader(\n",
    "        dataset=data_train,\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    dl_valid = torch.utils.data.DataLoader(\n",
    "        dataset=data_valid,\n",
    "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    return dl_train, dl_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = max(30, int(n_features/6))\n",
    "logger.info(f'Latent layer neurons: {n_neurons}')\n",
    "\n",
    "tensorboard_model_namer = TensorboardModelNamer(prefix_folder='experiment_01')\n",
    "writer = tensorboard_model_namer.get_writer(1, [n_neurons], 'scaler')\n",
    "logger.info(f\"Logging to: {writer.get_logdir()}\")\n",
    "\n",
    "\n",
    "dl_train, dl_valid = get_dataloaders(\n",
    "    df_train=analysis.df_train,\n",
    "    df_valid=analysis.df_valid,\n",
    "    scaler=scaler)\n",
    "\n",
    "logger.info(\n",
    "    \"N train: {:5,d} \\nN valid: {:5,d}\".format(\n",
    "        len(dl_train.dataset), len(dl_valid.dataset))\n",
    ")\n",
    "\n",
    "data, mask = next(iter(dl_train))\n",
    "\n",
    "writer.add_image(\n",
    "    f'{len(data)} batch of sampled data (as heatmap)', data, dataformats='HW')\n",
    "writer.add_image(\n",
    "    f'{len(mask)} mask for this batch of samples', mask, dataformats='HW')\n",
    "\n",
    "\n",
    "model = VAE(n_features=n_features, n_neurons=n_neurons)\n",
    "\n",
    "logger.info(model)\n",
    "model = model.to(device, non_blocking=True)\n",
    "\n",
    "# ToDo: compiler warning: error or tracer error?\n",
    "writer.add_graph(model, input_to_model=data.to(device))  # try to add after training?\n",
    "# writer.flush()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from vaep.model import eval\n",
    "\n",
    "def run_experiment(model, dls, writer, args):\n",
    "    metrics = defaultdict(dict)\n",
    "    dl_train, dl_valid = dls\n",
    "    msg_eval_epoch = \"Validation Set - Epoch: {:3d} - loss: {:7.3f} - mse: {:5.3f} - KLD: {:5.3f}\"\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        metrics[('train', 'loss')][epoch] = float(train(epoch, model=model, train_loader=dl_train,\n",
    "                                                        optimizer=optimizer, device=device, writer=writer))\n",
    "        # ToDo: Pull out writer from eval function\n",
    "        _epoch_metric_valid = eval(\n",
    "            model=model, data_loader=dl_valid, device=device)\n",
    "        n_batches = len(dl_valid)\n",
    "        writer.add_scalar('avg validation loss',\n",
    "                          _epoch_metric_valid['loss'] / n_batches,\n",
    "                          epoch)\n",
    "        metrics[('valid', 'loss')][epoch] = _epoch_metric_valid['loss']\n",
    "        metrics[('valid', 'mse')][epoch] = _epoch_metric_valid['mse']\n",
    "        metrics[('valid', 'kld')][epoch] = _epoch_metric_valid['kld']\n",
    "        if not epoch % 10:\n",
    "            logger.info(msg_eval_epoch.format(\n",
    "                epoch, *_epoch_metric_valid.values()))\n",
    "    writer.flush()\n",
    "    writer.close()  # closes all internal writers of SummaryWriter\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "metrics = run_experiment(model=model, dls=(\n",
    "    dl_train, dl_valid), writer=writer, args=args)  # decide about format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "_ = metrics.plot(\n",
    "    figsize=(18, 6), xlim=(1, args.epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [(_split, _metric)\n",
    "            for _split in ['train', 'valid']\n",
    "            for _metric in ['loss']\n",
    "            ]\n",
    "_ = metrics[selected].plot(\n",
    "    figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformed data (Single run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_train_log10 = np.log10(analysis.df_train)\n",
    "analysis.df_valid_log10 = np.log10(analysis.df_valid)\n",
    "scaler_log = StandardScaler().fit(X=analysis.df_train_log10)\n",
    "# five examples from validation dataset\n",
    "scaler_log.transform(analysis.df_valid_log10.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_neurons = max(30, int(n_features/6))\n",
    "logger.info(f'Latent layer neurons: {n_neurons}')\n",
    "\n",
    "writer = tensorboard_model_namer.get_writer(1, [n_neurons], 'scaler_log')\n",
    "logger.info(f\"Logging to: {writer.get_logdir()}\")\n",
    "\n",
    "\n",
    "dl_train, dl_valid = get_dataloaders(df_train=analysis.df_train_log10, df_valid=analysis.df_valid_log10, scaler=scaler_log)\n",
    "\n",
    "logger.info(\n",
    "    \"N train: {:5,d} \\nN valid: {:5,d}\".format(\n",
    "        len(dl_train.dataset), len(dl_valid.dataset))\n",
    ")\n",
    "\n",
    "data, mask = next(iter(dl_train))\n",
    "\n",
    "writer.add_image(\n",
    "    f'{len(data)} batch of sampled data (as heatmap)', data, dataformats='HW')\n",
    "writer.add_image(\n",
    "    f'{len(mask)} mask for this batch of samples', mask, dataformats='HW')\n",
    "\n",
    "\n",
    "model = VAE(n_features=n_features, n_neurons=n_neurons)\n",
    "\n",
    "logger.info(model)\n",
    "# model = model.to(device, non_blocking=True)\n",
    "\n",
    "# ToDo: compiler warning: error or tracer error?\n",
    "writer.add_graph(model, input_to_model=data)  # try to add after training?\n",
    "writer.flush()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_log = run_experiment(model=model, dls=(\n",
    "    dl_train, dl_valid), writer=writer, args=args)  # decide about format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfromance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics_log)\n",
    "metrics.plot(\n",
    "    figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [(_split, _metric)\n",
    "            for _split in ['train', 'valid']\n",
    "            for _metric in ['loss']\n",
    "            ]\n",
    "_ = metrics[selected].plot(\n",
    "    figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "- can be run from notebook\n",
    "- or in a separate process to inspect currently running training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first time, it timesout, second time it starts, see https://github.com/tensorflow/tensorboard/issues/2481#issuecomment-516819768\n",
    "# %tensorboard --logdir {tensorboard_model_namer.folder} --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Run to see updates: \\n\\n\\ttensorboard --logdir {tensorboard_model_namer.folder.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter comparison\n",
    "\n",
    "- [x] order data by date: consecutive samples from training to validation\n",
    "- [ ] check stratification based on machine and column length between splits\n",
    "    - validation and training data have same proportion of machine types\n",
    "- [ ] complete meta data reading based on filenames\n",
    "- [ ] compare performance regarding data normalization\n",
    "    - in original intensity space (non-log-transformed)\n",
    "- [ ] compare performance regarding several hyperparameters of VAE (layers, activation, etc)\n",
    "    - plot different losses in one plot as validation data set is the same\n",
    "- [ ] increase number of samples in training set and create result plot\n",
    "- [ ] increase the number of peptides (features)\n",
    "- [ ] mask some values in the validation set missing (Quality Assessment)\n",
    "- [ ] write main function which trains an entire model (including data transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug\n",
    "- [ ] Check reporting of loss again: average sample loss or average peptide loss?\n",
    "- [ ] take a close look at VAE tutorial of PyTorch (data normalization, etc)\n",
    "- [ ] reduce the features size to fewer samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE\n",
    "- original inputs between 0 and 1 as decoder outputs are transformed originally using the sigmoid fct\n",
    "- original model use `tanh` activations\n",
    "- think about the definition of `MSE` in a mini-batch. Should be peptide wise?\n",
    "    - VAMB does sum over a sample and then takes the mean of the sum (alternative?)\n",
    "    - multi-output regression?\n",
    "- learning requires active masking: Mask inputs which should be learned to be recovered. Feed original, \n",
    "  not masked image as target to loss.\n",
    "\n",
    "- [ ] Run MNIST example with MSE loss. Does it still work?\n",
    "- [ ] Normalize inputs to zero and one, use MNIST VAE. Does it work?\n",
    "- [ ] Regress M peptide intensities on 1 other peptide intensity. Does it work? (Reference performance)\n",
    "- [ ] Build a normal AE without probabilistic bottleneck. Does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactoring\n",
    "\n",
    "- [ ] get epoch out of train, eval etc\n",
    "\n",
    "\n",
    "Ideas\n",
    "  - combine 1000 most abundant peptides as guidance for different sets of low abundant peptides\n",
    "  - show the difference between original and reconstruction using a cm in an Image? batch-wise?\n",
    "\n",
    "- Current optimum for comparision is zero\n",
    "\n",
    "> The comparison where relatively low abundant, but not super low-abundant peptides will be masked, could skew the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer # new writer\n",
    "# dls = get_dls(data_in_memory, scaler)\n",
    "# model = VAE()\n",
    "# writer =  # new writer for each setup\n",
    "# metrics = run_experiment(model, dls, writer)\n",
    "# overview['experiment_name'] = metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
