{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src import config\n",
    "from src.analyzers import *\n",
    "from vaep.transform import StandardScaler, get_df_fitted_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = logging.getLogger()  # returns root-logger\n",
    "logger.setLevel(logging.CRITICAL)  # silence for everything else\n",
    "logger.handlers = []\n",
    "\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "- 1000 features (most abundant peptides)\n",
    "- later a subset of samples is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_TO_LOAD = None\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N_07813_M01000'\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N_00090_M01000'\n",
    "\n",
    "analysis = AnalyzePeptides(\n",
    "    fname=FN_PEPTIDE_INTENSITIES, nrows=N_SAMPLES_TO_LOAD)\n",
    "analysis.df = analysis.df.sort_index()  # sort by date\n",
    "assert analysis.df.index.is_unique, \"Non-unique training samples\"\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select consecutives samples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from vaep.utils import sample_iterable\n",
    "\n",
    "N_SAMPLES = min(len(analysis.df), 1000)\n",
    "logger.info(f\"Selected {N_SAMPLES}\")\n",
    "analysis.N_SAMPLES = N_SAMPLES\n",
    "\n",
    "M = 10\n",
    "\n",
    "columns_selected = sorted(sample_iterable(list(analysis.df.columns), n=M))\n",
    "analysis.df = analysis.df.loc[:, columns_selected]\n",
    "\n",
    "\n",
    "def get_consecutive_data_indices(index, n_samples=N_SAMPLES):\n",
    "    start_sample = len(index) - n_samples\n",
    "    start_sample = random.randint(0, start_sample)\n",
    "    return index[start_sample:start_sample+n_samples]\n",
    "\n",
    "\n",
    "indices_selected = get_consecutive_data_indices(analysis.df.index)\n",
    "analysis.samples = indices_selected\n",
    "analysis.df = analysis.df.loc[indices_selected]\n",
    "\n",
    "from numpy import log2\n",
    "LOG_TRANSFORM = log2 # None\n",
    "if LOG_TRANSFORM:\n",
    "    analysis.df = LOG_TRANSFORM(analysis.df)\n",
    "\n",
    "FRACTION = 0.8\n",
    "\n",
    "class Indices(SimpleNamespace):\n",
    "    pass\n",
    "\n",
    "\n",
    "indices = Indices()\n",
    "indices.train, indices.valid = indices_selected[:int(\n",
    "    FRACTION*N_SAMPLES)], indices_selected[int(FRACTION*N_SAMPLES):]\n",
    "analysis.indices = indices\n",
    "\n",
    "analysis.df_train = analysis.df.loc[indices.train]\n",
    "analysis.df_valid = analysis.df.loc[indices.valid]\n",
    "\n",
    "# analysis.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = analysis.df.shape\n",
    "msg = \"Total:\\nN samples: {:10,d} - N Peptides: {:10,d}\\n\".format(n_samples, n_features)\n",
    "n_train, n_valid = len(analysis.df_train), len(analysis.df_valid)\n",
    "msg += \"N train set: {:8,d} - N valid set: {:9,d}\".format(n_train, n_valid)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_limit = analysis.df.min().min() if LOG_TRANSFORM else np.log10(analysis.df).min().min() # all zeros become nan.\n",
    "\"Detection limit: {:6.3f}, corresponding to intensity value of {:,d}\".format(\n",
    "    detection_limit,\n",
    "    int(10 ** detection_limit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meta data from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import metadata\n",
    "\n",
    "data_meta = metadata.get_metadata_from_filenames(indices_selected)\n",
    "analysis.df_meta = pd.DataFrame.from_dict(\n",
    "    data_meta, orient='index')\n",
    "# analysis.df_meta['date'] = pd.to_datetime(analysis.df_meta['date'])\n",
    "analysis.df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- possibility to group data in time along `(machine, lc)` pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.loc[indices.train].describe(datetime_is_numeric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This becomes part of analysis\n",
    "def compare_meta_data_for_splits(meta, indices):\n",
    "\n",
    "    _indices = vars(indices)\n",
    "    logger.info('Found vars: {}'.format(', '.join(str(x)\n",
    "                                                  for x in _indices.keys())))\n",
    "\n",
    "    for key_split, split in _indices.items():\n",
    "        print(f\"{key_split:8} - split description:\")\n",
    "        display(\n",
    "            meta.loc[split].describe(datetime_is_numeric=True)\n",
    "        )\n",
    "\n",
    "    _meta_features = list(meta.columns)\n",
    "\n",
    "    for _column in _meta_features:\n",
    "        display(\n",
    "            _=pd.DataFrame({\n",
    "                key_split: meta.loc[split, _column].value_counts(normalize=True) for key_split, split in _indices.items()\n",
    "            }).sort_index().plot(kind='line', rot=90, figsize=(10, 5), title=f\"{_column} value Counts for different splits\")\n",
    "        )\n",
    "\n",
    "\n",
    "compare_meta_data_for_splits(analysis.df_meta.iloc[:, :2], indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis state so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_lower_triangle(analysis.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline supervised RF models\n",
    "\n",
    "- M RandomForest baseline models, each predicting one feature based on the M-1 other features\n",
    "- get an idea of a possible baseline performance\n",
    "    - could be used together with imputation of inputs\n",
    "    - with some effort this could be scaled to predict only missing peptides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "metrics = {}\n",
    "\n",
    "\n",
    "peptides = list(analysis.df_train.columns)\n",
    "metrics = {}\n",
    "pred_valid = {}\n",
    "\n",
    "for i in range(M):\n",
    "    train_columns = list(range(M))\n",
    "    test_column = i\n",
    "    train_columns.remove(i)\n",
    "    train_columns = [peptides[i] for i in train_columns]\n",
    "    test_column = peptides[test_column]\n",
    "    logger.debug(\n",
    "        f\"Train columns: {', '.join(train_columns)}\\nTest column: {test_column}\")\n",
    "    _df_train, _y_train = analysis.df_train[train_columns], analysis.df_train[test_column]\n",
    "    _df_valid, _y_valid = analysis.df_valid[train_columns], analysis.df_valid[test_column]\n",
    "    rf_reg = RandomForestRegressor()\n",
    "    rf_reg.fit(X=_df_train, y=_y_train)\n",
    "    # metrics\n",
    "    _metrics = {}\n",
    "    _metrics[('MSE', 'train')] = mean_squared_error(\n",
    "        y_true=_y_train, y_pred=rf_reg.predict(_df_train))\n",
    "    y_pred_valid = rf_reg.predict(_df_valid)\n",
    "    _metrics[('MSE', 'valid')] = mean_squared_error(\n",
    "        y_true=_y_valid, y_pred=y_pred_valid)\n",
    "    metrics[test_column] = _metrics\n",
    "    # predictions\n",
    "    pred_valid[test_column] = y_pred_valid\n",
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_valid, index=analysis.df_valid.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfits to training data as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.cmd import get_args\n",
    "\n",
    "BATCH_SIZE, EPOCHS = 8, 30\n",
    "args = get_args(batch_size=BATCH_SIZE, epochs=EPOCHS, no_cuda=True)  # data transfer to GPU seems slow\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(args, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple AE\n",
    "- should also heavily overfit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(analysis.df_train)\n",
    "# # five examples from validation dataset\n",
    "scaler.transform(analysis.df_valid.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from vaep.io.datasets import PeptideDatasetInMemoryNoMissings\n",
    "\n",
    "tf_norm = None # replace with Normalizer\n",
    "\n",
    "dataset_train = PeptideDatasetInMemoryNoMissings(data=scaler.transform(analysis.df_train), transform=tf_norm)\n",
    "dataset_valid = PeptideDatasetInMemoryNoMissings(data=scaler.transform(analysis.df_valid), transform=tf_norm)\n",
    "dl_train = DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True)\n",
    "dl_valid = DataLoader(dataset_valid, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaep.model as vaep_model\n",
    "\n",
    "model = vaep_model.Autoencoder(n_features=M, n_neurons=int(M/2), last_activation=None, dim_latent=3).double()\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "# Train standard autoencoder (AE)\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "# do = nn.Dropout()  # for denoising AE\n",
    "for epoch in range(args.epochs):\n",
    "    # ===================train==========================\n",
    "    for data in dl_train:\n",
    "        model.train()\n",
    "        data = data.to(device)\n",
    "        # noise = do(torch.ones(data.shape)).to(device) # for denoising AE\n",
    "        # data_corrupted = (data * noise).to(device)    # for denoising AE\n",
    "        # ===================forward=====================\n",
    "        output = model(data) \n",
    "        loss = criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    # ===================validate========================\n",
    "    for data in dl_valid:\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        valid_losses.append(loss.item())\n",
    "    \n",
    "    # ===================log=============================\n",
    "    print(f'epoch [{epoch + 1:03d}/{args.epochs}], '\n",
    "          f'train-loss: {np.mean(train_losses[-len(dl_train):]):.4f},'\n",
    "          f'valid-loss: {np.mean(valid_losses[-len(dl_valid):]):.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_losses = vaep_model.process_train_loss({'MSE train': train_losses})\n",
    "\n",
    "# Plotting is boilerplate code:\n",
    "_ = df_train_losses.plot(kind='scatter', x='steps', y='MSE train smoothed', figsize=(15,8),  title='Exponential smoothed training loss', ylim=(0,None))\n",
    "df_train_losses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "model.eval()\n",
    "for data in dl_valid:\n",
    "    data = data.to(device)\n",
    "    output = model(data)\n",
    "    pred.append(output.detach().numpy())\n",
    "vaep_model.build_df_from_pred_batches(pred, scaler, index=analysis.df_valid.index, columns=analysis.df_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analysis.df_valid) # true values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With noise: Denoising AE\n",
    "\n",
    "- noise is added during training: some values are set to zero (which is the center for standard normalized intensities)\n",
    "- noise model could be adapted to reflect the observed noise in the training data - > extrapolation to near future should hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vaep_model.Autoencoder(n_features=M, n_neurons=int(M/2), last_activation=None, dim_latent=3).double()\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "# Train denoising autoencoder (AE)\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "do = torch.nn.Dropout()  # for denoising AE\n",
    "for epoch in range(args.epochs):\n",
    "    # ===================train==========================\n",
    "    for data in dl_train:\n",
    "        model.train()\n",
    "        data = data.to(device)\n",
    "        noise = do(torch.ones(data.shape)).to(device) # for denoising AE\n",
    "        data_corrupted = (data * noise).to(device)    # for denoising AE\n",
    "        # ===================forward=====================\n",
    "        output = model(data) \n",
    "        loss = criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    # ===================validate========================\n",
    "    for data in dl_valid:\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        valid_losses.append(loss.item())\n",
    "    \n",
    "    # ===================log=============================\n",
    "    print(f'epoch [{epoch + 1:03d}/{args.epochs}], '\n",
    "          f'train-loss: {np.mean(train_losses[-len(dl_train):]):.4f},'\n",
    "          f'valid-loss: {np.mean(valid_losses[-len(dl_valid):]):.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_losses = vaep_model.process_train_loss({'MSE train': train_losses})\n",
    "\n",
    "# Plotting is boilerplate code:\n",
    "_ = df_train_losses.plot(kind='scatter', x='steps', y='MSE train smoothed', figsize=(15,8),  title='Exponential smoothed training loss', ylim=(0,None))\n",
    "df_train_losses.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering setup\n",
    "\n",
    "- each sample has an embedding\n",
    "- each peptide has an embedding\n",
    "- scalar product of embeddings should yield predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform: Non-log transformed data (Single run)\n",
    "\n",
    "Scale samples according to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# select initial data: transformed vs not log transformed\n",
    "scaler = MinMaxScaler().fit(analysis.df_train)\n",
    "# five examples from validation dataset\n",
    "scaler.transform(analysis.df_valid.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.io.datasets import PeptideDatasetInMemoryNoMissings\n",
    "from vaep.io.dataloaders import get_dataloaders\n",
    "\n",
    "dl_train, dl_valid = get_dataloaders(\n",
    "    df_train=analysis.df_train,\n",
    "    df_valid=analysis.df_valid,\n",
    "    scaler=scaler,\n",
    "    DataSetClass=PeptideDatasetInMemoryNoMissings,\n",
    "    batch_size=args.batch_size)\n",
    "\n",
    "logger.info(\n",
    "    \"N train: {:5,d} \\nN valid: {:5,d}\".format(\n",
    "        len(dl_train.dataset), len(dl_valid.dataset))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.model import VAE\n",
    "\n",
    "n_neurons = 5\n",
    "logger.info(f'Latent layer neurons: {n_neurons}')\n",
    "\n",
    "model = vaep_model.VAE(n_features=n_features, n_neurons=n_neurons, dim_vae_latent=2)\n",
    "model = model.to(device)\n",
    "\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                       lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard_model_namer = TensorboardModelNamer(prefix_folder='experiment_01')\n",
    "# writer = tensorboard_model_namer.get_writer(1, [n_neurons], 'scaler')\n",
    "# logger.info(f\"Logging to: {writer.get_logdir()}\")\n",
    "\n",
    "# # data, mask = next(iter(dl_train))\n",
    "# # writer.add_image(\n",
    "# #     f'{len(mask)} mask for this batch of samples', mask, dataformats='HW')\n",
    "\n",
    "# data = next(iter(dl_train))\n",
    "# writer.add_image(\n",
    "#     f'{len(data)} batch of sampled data (as heatmap)', data, dataformats='HW')\n",
    "\n",
    "\n",
    "# # ToDo: compiler warning: error or tracer error?\n",
    "# writer.add_graph(model, input_to_model=data.to(device))  # try to add after training?\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def run_experiment(model, dls, writer, args):\n",
    "    metrics = defaultdict(dict)\n",
    "    metrics_per_batch = defaultdict(list)\n",
    "    dl_train, dl_valid = dls\n",
    "    msg_eval_epoch = \"Validation Set - Epoch: {:3d} - loss: {:7.3f} - mse: {:5.3f} - KLD: {:5.3f}\"\n",
    "\n",
    "    \n",
    "    def _append_batch_metrics(batch_metrics_epoch, d_metrics=metrics_per_batch, dataset_name='train'):\n",
    "        \"\"\"Append single batch metrics to global dictionary.\"\"\"\n",
    "        for d in batch_metrics_epoch.values():\n",
    "            for key, value in d.items():\n",
    "                d_metrics[(dataset_name, key)].append(d[key])\n",
    "        return None  # Signal in-place operation\n",
    "    \n",
    "    def _agg_metric_per_epoch(batch_metrics_epoch, epoch, d_metrics=metrics, dataset_name='train'):\n",
    "        keys = next(iter(batch_metrics_epoch.values())).keys()\n",
    "        for key in keys:\n",
    "            d_metrics[(dataset_name, key)][epoch] = np.mean([d[key]\n",
    "                                             for d in batch_metrics_epoch.values()])\n",
    "        return None # Signal in-place operation\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        _epoch_metrics = vaep_model.train(model=model, train_loader=dl_train,\n",
    "                                                                 optimizer=optimizer, device=device)\n",
    "        n_batches = len(dl_train)\n",
    "        \n",
    "        _append_batch_metrics(_epoch_metrics)\n",
    "        \n",
    "        _agg_metric_per_epoch(_epoch_metrics, epoch)\n",
    "#         metrics[('train', 'loss')][epoch] = np.mean([d['loss']\n",
    "#                                              for d in _epoch_metrics.values()])\n",
    "#         metrics[('train', 'mse')][epoch] = np.mean([d['MSE']\n",
    "#                                              for d in _epoch_metrics.values()])\n",
    "#         metrics[('train', 'KLD')][epoch] = np.mean([d['KLD']\n",
    "#                                              for d in _epoch_metrics.values()])\n",
    "        # if epoch % 25 == 0:\n",
    "        #     logger.info('====> Epoch: {epoch:3} Average loss: {avg_loss:10.4f}'.format(\n",
    "        #         epoch=epoch, avg_loss=avg_loss))\n",
    "        # if writer is not None:\n",
    "        #     writer.add_scalar('avg training loss',\n",
    "        #                       avg_loss,\n",
    "        #                       epoch)\n",
    "\n",
    "        _epoch_metrics_valid = vaep_model.evaluate(\n",
    "            model=model, data_loader=dl_valid, device=device)\n",
    "        n_batches = len(dl_valid)\n",
    "        _append_batch_metrics(_epoch_metrics_valid, dataset_name='valid')\n",
    "        _agg_metric_per_epoch(_epoch_metrics_valid, epoch, dataset_name='valid')\n",
    "        \n",
    "        if writer:\n",
    "            writer.add_scalar('avg validation loss',\n",
    "                          _epoch_metric_valid['loss'] / n_batchnes,\n",
    "                          epoch)\n",
    "\n",
    "            \n",
    "#         metrics[('valid', 'loss')][epoch] = np.mean([d['loss']\n",
    "#                                              for d in _epoch_metrics_valid.values()])\n",
    "#         metrics[('valid', 'mse')][epoch] = np.mean([d['MSE']\n",
    "#                                              for d in _epoch_metrics_valid.values()])\n",
    "#         metrics[('valid', 'KLD')][epoch] = np.mean([d['KLD']\n",
    "#                                              for d in _epoch_metrics_valid.values()])\n",
    "#         if not epoch % 10:\n",
    "#             logger.info(msg_eval_epoch.format(\n",
    "#                 epoch, *_epoch_metric_valid.values()))\n",
    "#     writer.flush()\n",
    "#     writer.close()  # closes all internal writers of SummaryWriter\n",
    "    return dict(metrics), dict(metrics_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, metrics_per_batch = run_experiment(model=model, dls=(\n",
    "    dl_train, dl_valid), writer=None, args=args)  # decide about format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_losses = vaep_model.process_train_loss({'training loss': metrics_per_batch[('train', 'loss')]})\n",
    "\n",
    "# Plotting is boilerplate code:\n",
    "_ = df_train_losses.plot(kind='scatter', x='steps', y='training loss smoothed', figsize=(15,8),  title='Exponential smoothed training loss', ylim=(0,None))\n",
    "df_train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "batch_metrics_last_epoch = vaep_model.train(model=model, train_loader=dl_train,\n",
    "                      optimizer=optimizer, device=device)\n",
    "pd.DataFrame.from_dict(batch_metrics_last_epoch, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently: No improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "_ = metrics.plot(\n",
    "    figsize=(18, 6), xlim=(1, args.epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [(_split, _metric)\n",
    "            for _split in ['train', 'valid']\n",
    "            for _metric in ['loss']\n",
    "            ]\n",
    "_ = metrics[selected].plot(\n",
    "    figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_epoch_metric_valid, pred = vaep_model.evaluate(model=model, data_loader=dl_valid, device=device, return_pred=True)\n",
    "# raw predictions\n",
    "pd.DataFrame(np.vstack(pred), index=analysis.df_valid.index, columns=analysis.df_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate label in dataloader\n",
    "vaep_model.build_df_from_pred_batches(pred, scaler, index=analysis.df_valid.index, columns=analysis.df_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "- can be run from notebook\n",
    "- or in a separate process to inspect currently running training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     f\"Run to see updates: \\n\\n\\ttensorboard --logdir {tensorboard_model_namer.folder.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter comparison\n",
    "\n",
    "- [x] order data by date: consecutive samples from training to validation\n",
    "- [x] check stratification based on machine and column length between splits\n",
    "    - Do validation and training data have same proportion of machine types? -> generally no, would need to be added\n",
    "       - not (all) machines are running continously or are continously checked\n",
    "- [x] complete meta data reading based on filenames\n",
    "- [x] compare performance regarding data normalization\n",
    "    - in original intensity space (non-log-transformed) - > \n",
    "- [ ] compare performance regarding several hyperparameters of VAE (layers, activation, etc)\n",
    "    - plot different losses in one plot as validation data set is the same\n",
    "- [ ] increase number of samples in training set and create result plot\n",
    "- [ ] increase the number of peptides (features)\n",
    "- [ ] mask some values in the validation set missing (Quality Assessment)\n",
    "- [ ] write main function which trains an entire model (including data transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug\n",
    "- [ ] Check reporting of loss again: average sample loss or average peptide loss?\n",
    "- [ ] take a close look at VAE tutorial of PyTorch (data normalization, etc)\n",
    "- [ ] reduce the features size to fewer samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE\n",
    "- original inputs between 0 and 1 as decoder outputs are transformed originally using the sigmoid fct\n",
    "- original model use `tanh` activations\n",
    "- think about the definition of `MSE` in a mini-batch. Should be peptide wise?\n",
    "    - VAMB does sum over a sample and then takes the mean of the sum (alternative?)\n",
    "    - multi-output regression?\n",
    "- learning requires active masking: Mask inputs which should be learned to be recovered. Feed original, \n",
    "  not masked image as target to loss.\n",
    "\n",
    "- [ ] Run MNIST example with MSE loss. Does it still work?\n",
    "- [ ] Normalize inputs to zero and one, use MNIST VAE. Does it work?\n",
    "- [ ] Regress M peptide intensities on 1 other peptide intensity. Does it work? (Reference performance)\n",
    "- [ ] Build a normal AE without probabilistic bottleneck. Does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactoring\n",
    "\n",
    "- [ ] get epoch out of train, eval etc\n",
    "\n",
    "\n",
    "Ideas\n",
    "  - combine 1000 most abundant peptides as guidance for different sets of low abundant peptides\n",
    "  - show the difference between original and reconstruction using a cm in an Image? batch-wise?\n",
    "\n",
    "- Current optimum for comparision is zero\n",
    "\n",
    "> The comparison where relatively low abundant, but not super low-abundant peptides will be masked, could skew the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer # new writer\n",
    "# dls = get_dls(data_in_memory, scaler)\n",
    "# model = VAE()\n",
    "# writer =  # new writer for each setup\n",
    "# metrics = run_experiment(model, dls, writer)\n",
    "# overview['experiment_name'] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect batches of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_valid = analysis.df_valid.index\n",
    "index_train = analysis.df_train.index\n",
    "columns_ = analysis.df_train.columns\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training batch example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "iter_dl_train = iter(dl_train)\n",
    "batch = next(iter_dl_train)\n",
    "batch_mask = None\n",
    "try:\n",
    "    batch, batch_mask = batch\n",
    "    batch_masked = batch * batch_mask\n",
    "except ValueError:\n",
    "    batch = batch\n",
    "batch_recon, mu, logvar = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_metrics = vaep_model.loss_function(batch_recon, batch, mu, logvar)\n",
    "_batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_mask:\n",
    "    _mse = ((batch * batch_mask) - (batch_recon * batch_mask)).pow(2).sum()  # avg per peptide loss -> should be close to zero (ref: std=1)\n",
    "else:\n",
    "    _mse = (batch - batch_recon).pow(2).sum()\n",
    "_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss = nn.MSELoss(reduction='sum')\n",
    "if batch_mask:\n",
    "    _mse = loss(input=batch_recon*batch_mask, target=batch * batch_mask)\n",
    "else:\n",
    "    _mse = loss(input=batch_recon, target=batch)\n",
    "_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "if batch_mask:\n",
    "    batch_sse = F.mse_loss(input=batch_recon*batch_mask,\n",
    "                       target=batch * batch_mask, reduction='sum')\n",
    "else:\n",
    "    batch_sse = F.mse_loss(input=batch_recon,\n",
    "                       target=batch, reduction='sum')\n",
    "batch_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Validation batch example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data loader is not shuffled\n",
    "N_valid = len(dl_valid.dataset)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "iter_dl_valid = iter(dl_valid)\n",
    "\n",
    "batch = next(iter_dl_valid)\n",
    "batch_mask = None\n",
    "try:\n",
    "    batch, batch_mask = batch\n",
    "    batch_masked = batch * batch_mask\n",
    "except ValueError:\n",
    "    batch = batch\n",
    "\n",
    "batch_recon, mu, logvar = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_metrics = vaep_model.loss_function(batch_recon, batch, mu, logvar)\n",
    "_batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_mask:\n",
    "    _mse = ((batch * batch_mask) - (batch_recon * batch_mask)).pow(2).sum()  # avg per peptide loss -> should be close to zero (ref: std=1)\n",
    "else:\n",
    "    _mse = (batch - batch_recon).pow(2).sum()\n",
    "_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss = nn.MSELoss(reduction='sum')\n",
    "if batch_mask:\n",
    "    _mse = loss(input=batch_recon*batch_mask, target=batch * batch_mask)\n",
    "else:\n",
    "    _mse = loss(input=batch_recon, target=batch)\n",
    "_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "if batch_mask:\n",
    "    batch_sse = F.mse_loss(input=batch_recon*batch_mask,\n",
    "                       target=batch * batch_mask, reduction='sum')\n",
    "else:\n",
    "    batch_sse = F.mse_loss(input=batch_recon,\n",
    "                       target=batch, reduction='sum')\n",
    "batch_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Validation data\n",
    "\n",
    "- VAMB training epoch normalizes by number of batches, [see](https://github.com/RasmussenLab/vamb/blob/734b741b85296377937de54166b7db274bc7ba9c/vamb/encode.py#L284-L335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data loader is not shuffled\n",
    "iter_dl_valid = iter(dl_valid)\n",
    "\n",
    "batch = next(iter_dl_valid)\n",
    "batch_mask = None\n",
    "try:\n",
    "    batch, batch_mask = batch\n",
    "    batch_masked = batch * batch_mask\n",
    "except ValueError:\n",
    "    batch = batch\n",
    "\n",
    "M = batch.shape[-1]\n",
    "batch_recon, _, _ = model(batch)\n",
    "\n",
    "data = batch.detach().numpy()\n",
    "if batch_mask: mask = batch_mask.detach().numpy()\n",
    "pred = batch_recon.detach().numpy()\n",
    "\n",
    "for batch in iter_dl_valid:\n",
    "    try:\n",
    "        # ToDo: Test if this works\n",
    "        if not type(batch) == torch.Tensor:\n",
    "            batch, batch_mask = batch\n",
    "            batch_masked = batch * batch_mask\n",
    "    except ValueError:\n",
    "        batch = batch\n",
    "    batch_recon, _, _ = model(batch)\n",
    "    data = np.append(data, batch.view([-1, M]), axis=0)\n",
    "    \n",
    "    if batch_mask: mask = np.append(mask, batch_mask, axis=0)\n",
    "    pred = np.append(pred, batch_recon.detach().numpy().reshape(-1, M), axis=0)\n",
    "\n",
    "expected_shape = analysis.df_valid.shape\n",
    "assert data.shape == expected_shape\n",
    "assert pred.shape == expected_shape\n",
    "if batch_mask: assert mask.shape == expected_shape\n",
    "\n",
    "data = pd.DataFrame(data, index=index_valid,\n",
    "                    columns=columns_).replace(0.0, np.nan)\n",
    "pred = pd.DataFrame(pred, index=index_valid, columns=columns_)\n",
    "mask = pd.DataFrame(mask, index=index_valid, columns=columns_) if batch_mask else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    scaler.inverse_transform(pred),\n",
    "    index=index_valid,\n",
    "    columns=columns_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.iloc[-1]  # mse loss get's most weight in combined loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.iloc[-1].loc[('valid', 'recon_loss')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average prediction error per peptides:\n",
    "\n",
    "-  std. dev is one, so a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that losses reported match loss calculated form predictions\n",
    "((pred - data)**2).sum().sum() / data.notna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred - data).iloc[:10, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((pred - data).iloc[:10, :5])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred - data).notna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = data.shape\n",
    "data.isna().sum().sum() / (N*M)  # only few missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
