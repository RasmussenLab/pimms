{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up data into single datasets\n",
    "\n",
    "- create datasets per (set of) instruments for a specific experiments\n",
    "- drop some samples based on quality criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vaep.io import thermo_raw_files\n",
    "from vaep.analyzers import analyzers\n",
    "\n",
    "from config import erda_dumps\n",
    "from config import defaults\n",
    "\n",
    "import vaep\n",
    "import vaep.io.filenames\n",
    "from vaep.logging import setup_nb_logger\n",
    "\n",
    "logger = setup_nb_logger()\n",
    "\n",
    "FOLDER_DATA = defaults.FOLDER_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.plotting.make_large_descriptors()\n",
    "FIGSIZE=(15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DUMP: str = erda_dumps.FN_PROTEIN_GROUPS\n",
    "# DUMP: str = erda_dumps.FN_PEPTIDES\n",
    "# DUMP: str = erda_dumps.FN_EVIDENCE\n",
    "FOLDER_DATASETS: str = f'single_datasets/{DUMP.stem}'\n",
    "FILE_EXT = 'pkl'\n",
    "SAMPLE_ID = 'Sample ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure output folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATASETS = defaults.FOLDER_DATA / FOLDER_DATASETS\n",
    "FOLDER_DATASETS.mkdir(exist_ok=True, parents=True)\n",
    "logger.info(f\"Folder for datasets to be created: {FOLDER_DATASETS.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load dumps\n",
    "- load file to machine mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(DUMP)\n",
    "data = data.squeeze() # In case it is a DataFrame, not a series (-> leads to MultiIndex)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Number of rows (row = sample, feature, intensity): {len(data):,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_non_sample = list(data.index.names)\n",
    "idx_non_sample.remove(SAMPLE_ID)\n",
    "idx_non_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = data.index.droplevel(SAMPLE_ID).nunique() # very slow alternative, but 100% correct\n",
    "M = vaep.io.filenames.read_M_features(DUMP.stem)\n",
    "logger.info(f\"Number of unqiue features: {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.groupby(SAMPLE_ID).count().squeeze()\n",
    "counts.to_json(FOLDER_DATASETS / 'support_all.json', indent=4)\n",
    "ax = (counts\n",
    "      .sort_values()  # will raise an error with a DataFrame\n",
    "      .reset_index(drop=True)\n",
    "      .plot(rot=45,\n",
    "            figsize=FIGSIZE,\n",
    "            grid=True,\n",
    "            xlabel='Count of samples ordered by number of features', \n",
    "            title=f'Support of {len(counts):,d} samples features over {M} features ({\", \".join(idx_non_sample)})',\n",
    "            ))\n",
    "vaep.plotting.add_prop_as_second_yaxis(ax, M)\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.plotting.savefig(fig, name='support_all',\n",
    "                      folder=FOLDER_DATASETS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for odd samples\n",
    "\n",
    "- fractionated samples\n",
    "- GPF - Gas phase fractionation # Faims? DIA? \n",
    "- DIA\n",
    "- CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see 02_data_exploration_peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data\n",
    "\n",
    "- based on ThermoRawFileParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_ids = data.index.levels[0] # assume first index position is Sample ID?\n",
    "sample_ids = data.index.get_level_values(SAMPLE_ID).unique() # more explict\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('data/files_selected_metadata.csv', index_col=SAMPLE_ID)\n",
    "date_col = 'Content Creation Date'\n",
    "df_meta[date_col] = pd.to_datetime(df_meta[date_col])\n",
    "df_meta = df_meta.loc[sample_ids]\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_instrument = df_meta.groupby(thermo_raw_files.cols_instrument)[date_col].agg(\n",
    "    ['count', 'min', 'max']).sort_values(by=thermo_raw_files.cols_instrument[:2] + ['count'], ascending=False)\n",
    "counts_instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MIN_INSTRUMENT = 300\n",
    "selected_instruments = counts_instrument.query(f\"count >= {N_MIN_INSTRUMENT}\")\n",
    "fname = FOLDER_DATASETS / 'dataset_info'\n",
    "selected_instruments.to_json(f\"{fname}.json\", indent=4)\n",
    "selected_instruments.to_latex(f\"{fname}.tex\")\n",
    "selected_instruments.to_excel(f\"{fname}.xlsx\")\n",
    "logger.info(f\"Save Information to: {fname} (as json, tex)\")\n",
    "selected_instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump single experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = selected_instruments.index.names\n",
    "\n",
    "file_formats = {'pkl': 'to_pickle',\n",
    "                'pickle': 'to_pickle',\n",
    "                'csv': 'to_csv'}\n",
    "\n",
    "\n",
    "for values in selected_instruments.index:\n",
    "    mask = df_meta[cols] == values\n",
    "    logger.info(f\"Samples: {mask.all(axis=1).sum()}\")\n",
    "    sample_ids = df_meta.loc[mask.all(axis=1)].index\n",
    "    dataset = data.loc[sample_ids]\n",
    "    fname_dataset = vaep.io.get_fname_from_keys(values,\n",
    "                                                folder=FOLDER_DATASETS,\n",
    "                                                file_ext=f\".{FILE_EXT}\")\n",
    "\n",
    "    logger.info(f'Dump dataset with N = {len(dataset)} to {fname_dataset}')\n",
    "    _to_file_format = getattr(dataset, file_formats[FILE_EXT])\n",
    "    _to_file_format(fname_dataset)\n",
    "\n",
    "    fname_support = vaep.io.get_fname_from_keys(values,\n",
    "                                            folder='.',\n",
    "                                                file_ext=\"\")\n",
    "    fname_support = fname_support.stem + '_support'\n",
    "    logger.info(f\"Dump support to: {fname_support}\")\n",
    "    counts = dataset.groupby(SAMPLE_ID).count().squeeze()\n",
    "    counts.to_json(FOLDER_DATASETS / f\"{fname_support}.json\", indent=4)\n",
    "   \n",
    "    M = dataset.index.droplevel(SAMPLE_ID).nunique() # very slow alternative, but 100% correct\n",
    "\n",
    "    # plot:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = (counts\n",
    "          .sort_values()  # will raise an error with a DataFrame\n",
    "          .reset_index(drop=True)\n",
    "          .plot(rot=45,\n",
    "                ax=ax,\n",
    "                figsize=FIGSIZE,\n",
    "                grid=True,\n",
    "                xlabel='Count of samples ordered by number of features',\n",
    "                title=f'Support of {len(counts):,d} samples features over {M} features ({\", \".join(idx_non_sample)})',\n",
    "                ))\n",
    "    vaep.plotting.add_prop_as_second_yaxis(ax, M)\n",
    "    fig.tight_layout()\n",
    "    vaep.plotting.savefig(fig, name=fname_support,\n",
    "                          folder=FOLDER_DATASETS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last example dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3c193f136b3677f7a0d8b8f2344336d9d9fbcf8449c7b9fd96c2b5d44d3d77c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
