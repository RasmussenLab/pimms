{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fbb5ed-e86e-44a5-ba62-eabcd7b48565",
   "metadata": {},
   "source": [
    "# Compare predictions between model and RSN\n",
    "\n",
    "- see differences in imputation for diverging cases\n",
    "- dumps top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa9d4c-622f-46c3-847a-7f7474082ee4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import njab\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "import vaep\n",
    "import vaep.analyzers\n",
    "import vaep.imputation\n",
    "import vaep.io.datasplits\n",
    "\n",
    "logger = vaep.logging.setup_nb_logger()\n",
    "logging.getLogger('fontTools').setLevel(logging.WARNING)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [4, 2.5]  # [16.0, 7.0] , [4, 3]\n",
    "vaep.plotting.make_large_descriptors(7)\n",
    "\n",
    "# catch passed parameters\n",
    "args = None\n",
    "args = dict(globals()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3192d11-2db7-440c-a80d-7a2e10799895",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfd1e5-719d-4905-a441-4a2a8ac5b14c",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "folder_experiment = 'runs/appl_ald_data/plasma/proteinGroups'\n",
    "fn_clinical_data = \"data/ALD_study/processed/ald_metadata_cli.csv\"\n",
    "make_plots = True  # create histograms and swarmplots of diverging results\n",
    "model_key = 'VAE'\n",
    "sample_id_col = 'Sample ID'\n",
    "target = 'kleiner'\n",
    "cutoff_target: int = 2  # => for binarization target >= cutoff_target\n",
    "out_folder = 'diff_analysis'\n",
    "file_format = 'csv'\n",
    "baseline = 'RSN'  # default is RSN, but could be any other trained model\n",
    "template_pred = 'pred_real_na_{}.csv'  # fixed, do not change\n",
    "ref_method_score = None  # filepath to reference method score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c6c2a-146c-48bd-9d7b-1fe4eec8a6ae",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "params = vaep.nb.get_params(args, globals=globals())\n",
    "args = vaep.nb.Config()\n",
    "args.folder_experiment = Path(params[\"folder_experiment\"])\n",
    "args = vaep.nb.add_default_paths(args,\n",
    "                                 out_root=(args.folder_experiment\n",
    "                                           / params[\"out_folder\"]\n",
    "                                           / params[\"target\"]))\n",
    "args.folder_scores = (args.folder_experiment\n",
    "                      / params[\"out_folder\"]\n",
    "                      / params[\"target\"]\n",
    "                      / 'scores'\n",
    "                      )\n",
    "args.update_from_dict(params)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036fc07",
   "metadata": {},
   "source": [
    "Write outputs to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c833157-e36e-476b-a3bd-d604b962ef04",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "files_out = dict()\n",
    "\n",
    "fname = args.out_folder / 'diff_analysis_compare_DA.xlsx'\n",
    "writer = pd.ExcelWriter(fname)\n",
    "files_out[fname.name] = fname.as_posix()\n",
    "logger.info(\"Writing to excel file: %s\", fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d61673",
   "metadata": {},
   "source": [
    "## Load scores\n",
    "List dump of scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd112b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "score_dumps = [fname for fname in Path(\n",
    "    args.folder_scores).iterdir() if fname.suffix == '.pkl']\n",
    "score_dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18113565",
   "metadata": {},
   "source": [
    "Load scores from dumps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240a9b0",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "scores = pd.concat([pd.read_pickle(fname) for fname in score_dumps], axis=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb0f0b",
   "metadata": {},
   "source": [
    "If reference dump is provided, add it to the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dae12",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if args.ref_method_score:\n",
    "    scores_reference = (pd\n",
    "                        .read_pickle(args.ref_method_score)\n",
    "                        .rename({'None': 'None (100%)'},\n",
    "                                axis=1))\n",
    "    scores = scores.join(scores_reference)\n",
    "    logger.info(f'Added reference method scores from {args.ref_method_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79746f59",
   "metadata": {},
   "source": [
    "### Load frequencies of observed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecc391",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fname = args.folder_experiment / 'freq_features_observed.csv'\n",
    "freq_feat = pd.read_csv(fname, index_col=0)\n",
    "freq_feat.columns = pd.MultiIndex.from_tuples([('data', 'frequency'),])\n",
    "freq_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641099cd",
   "metadata": {},
   "source": [
    "### Assemble qvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a41e86",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "qvalues = scores.loc[pd.IndexSlice[:, args.target],\n",
    "                     pd.IndexSlice[:, 'qvalue']\n",
    "                     ].join(freq_feat\n",
    "                            ).set_index(\n",
    "    ('data', 'frequency'), append=True)\n",
    "qvalues.index.names = qvalues.index.names[:-1] + ['frequency']\n",
    "fname = args.out_folder / 'qvalues_target.pkl'\n",
    "files_out[fname.name] = fname.as_posix()\n",
    "qvalues.to_pickle(fname)\n",
    "qvalues.to_excel(writer, sheet_name='qvalues_all')\n",
    "qvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024e94d",
   "metadata": {},
   "source": [
    "### Assemble pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2488e4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pvalues = scores.loc[pd.IndexSlice[:, args.target],\n",
    "                     pd.IndexSlice[:, 'p-unc']\n",
    "                     ].join(freq_feat\n",
    "                            ).set_index(\n",
    "    ('data', 'frequency'), append=True)\n",
    "pvalues.index.names = pvalues.index.names[:-1] + ['frequency']\n",
    "fname = args.out_folder / 'pvalues_target.pkl'\n",
    "files_out[fname.name] = fname.as_posix()\n",
    "pvalues.to_pickle(fname)\n",
    "pvalues.to_excel(writer, sheet_name='pvalues_all')\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b02e5a",
   "metadata": {},
   "source": [
    "### Assemble rejected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12c234",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "da_target = scores.loc[pd.IndexSlice[:, args.target],\n",
    "                       pd.IndexSlice[:, 'rejected']\n",
    "                       ].join(freq_feat\n",
    "                              ).set_index(\n",
    "    ('data', 'frequency'), append=True)\n",
    "da_target.index.names = da_target.index.names[:-1] + ['frequency']\n",
    "fname = args.out_folder / 'equality_rejected_target.pkl'\n",
    "files_out[fname.name] = fname.as_posix()\n",
    "da_target.to_pickle(fname)\n",
    "count_rejected = njab.pandas.combine_value_counts(da_target.droplevel(-1, axis=1))\n",
    "count_rejected.to_excel(writer, sheet_name='count_rejected')\n",
    "count_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2a9c8",
   "metadata": {},
   "source": [
    "### Tabulate rejected decisions by method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0a7b4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! This uses implicitly that RSN is not available for some protein groups\n",
    "# ! Make an explicit list of the 313 protein groups available in original data\n",
    "mask_common = da_target.notna().all(axis=1)\n",
    "count_rejected_common = njab.pandas.combine_value_counts(da_target.loc[mask_common].droplevel(-1, axis=1))\n",
    "count_rejected_common.to_excel(writer, sheet_name='count_rejected_common')\n",
    "count_rejected_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8e3e5",
   "metadata": {},
   "source": [
    "### Tabulate rejected decisions by method for newly included features (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a13cb",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "count_rejected_new = njab.pandas.combine_value_counts(da_target.loc[~mask_common].droplevel(-1, axis=1))\n",
    "count_rejected_new.to_excel(writer, sheet_name='count_rejected_new')\n",
    "count_rejected_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57d9f0",
   "metadata": {},
   "source": [
    "### Tabulate rejected decisions by method for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e8772",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "da_target.to_excel(writer, sheet_name='equality_rejected_all')\n",
    "logger.info(\"Written to sheet 'equality_rejected_all' in excel file.\")\n",
    "da_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed7b09",
   "metadata": {},
   "source": [
    "Tabulate number of equal decison by method (`True`) to the ones with varying \n",
    "decision depending on the method (`False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa40ea2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "da_target_same = (da_target.sum(axis=1) == 0) | da_target.all(axis=1)\n",
    "da_target_same.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc6744",
   "metadata": {},
   "source": [
    "List frequency of features with varying decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c37698",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "feat_idx_w_diff = da_target_same[~da_target_same].index\n",
    "feat_idx_w_diff.to_frame()[['frequency']].reset_index(-1, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c770b",
   "metadata": {},
   "source": [
    "take only those with different decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57dfa9",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "(qvalues\n",
    " .loc[feat_idx_w_diff]\n",
    " .sort_values(('None', 'qvalue'))\n",
    " .to_excel(writer, sheet_name='qvalues_diff')\n",
    " )\n",
    "\n",
    "(qvalues\n",
    " .loc[feat_idx_w_diff]\n",
    " .loc[mask_common]  # mask automatically aligned\n",
    " .sort_values(('None', 'qvalue'))\n",
    " .to_excel(writer, sheet_name='qvalues_diff_common')\n",
    " )\n",
    "\n",
    "try:\n",
    "    (qvalues\n",
    "     .loc[feat_idx_w_diff]\n",
    "     .loc[~mask_common]\n",
    "     .sort_values(('None', 'qvalue'))\n",
    "     .to_excel(writer, sheet_name='qvalues_diff_new')\n",
    "     )\n",
    "except IndexError:\n",
    "    print(\"No new features or no new ones (with diverging decisions.)\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d4bcf",
   "metadata": {},
   "source": [
    "## Plots for inspecting imputations (for diverging decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10092826",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if not args.make_plots:\n",
    "    logger.warning(\"Not plots requested.\")\n",
    "    import sys\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81224abe",
   "metadata": {},
   "source": [
    "## Load target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d3301",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(args.fn_clinical_data,\n",
    "                     index_col=0,\n",
    "                     usecols=[args.sample_id_col, args.target])\n",
    "target = target.dropna()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160ab0c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "target_to_group = target.copy()\n",
    "target = target >= args.cutoff_target\n",
    "target = target.replace({False: f'{args.target} < {args.cutoff_target}',\n",
    "                        True: f'{args.target} >= {args.cutoff_target}'}\n",
    "                        ).astype('category')\n",
    "pd.crosstab(target.squeeze(), target_to_group.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5f980-5f3a-4a75-8479-a65c595e5220",
   "metadata": {},
   "source": [
    "## Measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083535b-9a06-479e-9909-935d49311b00",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = vaep.io.datasplits.DataSplits.from_folder(\n",
    "    args.data,\n",
    "    file_format=args.file_format)\n",
    "data = pd.concat([data.train_X, data.val_y, data.test_y]).unstack()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5b40",
   "metadata": {},
   "source": [
    "plot all of the new pgs which are at least once significant which are not already dumped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d183d5",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "feat_new_abundant = da_target.loc[~mask_common].any(axis=1)\n",
    "feat_new_abundant = feat_new_abundant.loc[feat_new_abundant].index.get_level_values(0)\n",
    "feat_new_abundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a677c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "feat_sel = feat_idx_w_diff.get_level_values(0)\n",
    "feat_sel = feat_sel.union(feat_new_abundant)\n",
    "len(feat_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c0f53",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = data.loc[:, feat_sel]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9762ec2a",
   "metadata": {},
   "source": [
    "- RSN prediction are based on all samples mean and std (N=455) as in original study\n",
    "- VAE also trained on all samples (self supervised)\n",
    "One could also reduce the selected data to only the samples with a valid target marker,\n",
    "but this was not done in the original study which considered several different target markers.\n",
    "\n",
    "RSN : shifted per sample, not per feature!\n",
    "\n",
    "Load all prediction files and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd936e9-eb56-4fb7-8010-d68092b925ad",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# exclude 'None' as this is without imputation (-> data)\n",
    "model_keys = [k for k in qvalues.columns.get_level_values(0) if k != 'None']\n",
    "pred_paths = [\n",
    "    args.out_preds / args.template_pred.format(method)\n",
    "    for method in model_keys]\n",
    "pred_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ecc0ed-c550-4a40-802b-25962d7edf7e",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "load_single_csv_pred_file = vaep.analyzers.compare_predictions.load_single_csv_pred_file\n",
    "pred_real_na = dict()\n",
    "for method in model_keys:\n",
    "    fname = args.out_preds / args.template_pred.format(method)\n",
    "    print(f\"missing values pred. by {method}: {fname}\")\n",
    "    pred_real_na[method] = load_single_csv_pred_file(fname)\n",
    "pred_real_na = pd.DataFrame(pred_real_na)\n",
    "pred_real_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e753f",
   "metadata": {},
   "source": [
    "Once imputation, reduce to target samples only (samples with target score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422a7a8",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# select samples with target information\n",
    "data = data.loc[target.index]\n",
    "pred_real_na = pred_real_na.loc[target.index]\n",
    "\n",
    "# assert len(data) == len(pred_real_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3294f6a-65f3-4793-ad0c-4dd8ff11be47",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "idx = feat_sel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17d5eb-a132-4616-b505-4a68efa0e9e5",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "feat_observed = data[idx].dropna()\n",
    "feat_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043395a7-fa33-490e-9d9c-f8071274f0b5",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# axes = axes.ravel()\n",
    "# args.out_folder.parent / 'intensity_plots'\n",
    "# each feature -> one plot?\n",
    "# plot all which are at least for one method significant?\n",
    "folder = args.out_folder / 'intensities_for_diff_in_DA_decision'\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f693",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "min_y_int, max_y_int = vaep.plotting.data.get_min_max_iterable(\n",
    "    [data.stack(), pred_real_na.stack()])\n",
    "min_max = min_y_int, max_y_int\n",
    "\n",
    "target_name = target.columns[0]\n",
    "\n",
    "min_max, target_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db8a0e",
   "metadata": {},
   "source": [
    "## Compare with target annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819b0e0",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# labels somehow?\n",
    "# target.replace({True: f' >={args.cutoff_target}', False: f'<{args.cutoff_target}'})\n",
    "\n",
    "for i, idx in enumerate(feat_sel):\n",
    "    print(f\"Swarmplot {i:3<}: {idx}:\")\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # dummy plots, just to get the Path objects\n",
    "    tmp_dot = ax.scatter([1, 2], [3, 4], marker='X')\n",
    "    new_mk, = tmp_dot.get_paths()\n",
    "    tmp_dot.remove()\n",
    "\n",
    "    feat_observed = data[idx].dropna()\n",
    "\n",
    "    def get_centered_label(method, n, q):\n",
    "        model_str = f'{method}'\n",
    "        stats_str = f'(N={n:,d}, q={q:.3f})'\n",
    "        if len(model_str) > len(stats_str):\n",
    "            stats_str = f\"{stats_str:<{len(model_str)}}\"\n",
    "        else:\n",
    "            model_str = f\"{model_str:<{len(stats_str)}}\"\n",
    "        return f'{model_str}\\n{stats_str}'\n",
    "\n",
    "    key = get_centered_label(method='observed',\n",
    "                             n=len(feat_observed),\n",
    "                             q=float(qvalues.loc[idx, ('None', 'qvalue')])\n",
    "                             )\n",
    "    to_plot = {key: feat_observed}\n",
    "    for method in model_keys:\n",
    "        try:\n",
    "            pred = pred_real_na.loc[pd.IndexSlice[:,\n",
    "                                                  idx], method].dropna().droplevel(-1)\n",
    "            if len(pred) == 0:\n",
    "                # in case no values was imputed -> qvalue is as based on measured\n",
    "                key = get_centered_label(method=method,\n",
    "                                         n=len(pred),\n",
    "                                         q=float(qvalues.loc[idx, ('None', 'qvalue')]\n",
    "                                                 ))\n",
    "            elif qvalues.loc[idx, (method, 'qvalue')].notna().all():\n",
    "                key = get_centered_label(method=method,\n",
    "                                         n=len(pred),\n",
    "                                         q=float(qvalues.loc[idx, (method, 'qvalue')]\n",
    "                                                 ))\n",
    "            elif qvalues.loc[idx, (method, 'qvalue')].isna().all():\n",
    "                logger.info(f\"NA qvalues for {idx}: {method}\")\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(\"Unknown case.\")\n",
    "            to_plot[key] = pred\n",
    "        except KeyError:\n",
    "            print(f\"No missing values for {idx}: {method}\")\n",
    "            continue\n",
    "\n",
    "    to_plot = pd.DataFrame.from_dict(to_plot)\n",
    "    to_plot.columns.name = 'group'\n",
    "    groups_order = to_plot.columns.to_list()\n",
    "    to_plot = to_plot.stack().to_frame('intensity').reset_index(-1)\n",
    "    to_plot = to_plot.join(target.astype('category'), how='inner')\n",
    "    to_plot = to_plot.astype({'group': 'category'})\n",
    "\n",
    "    ax = seaborn.swarmplot(data=to_plot,\n",
    "                           x='group',\n",
    "                           y='intensity',\n",
    "                           order=groups_order,\n",
    "                           dodge=True,\n",
    "                           hue=args.target,\n",
    "                           size=2,\n",
    "                           ax=ax)\n",
    "    first_pg = idx.split(\";\")[0]\n",
    "    ax.set_title(\n",
    "        f'Imputation for protein group {first_pg} with target {target_name} (N= {len(data):,d} samples)')\n",
    "\n",
    "    _ = ax.set_ylim(min_y_int, max_y_int)\n",
    "    _ = ax.locator_params(axis='y', integer=True)\n",
    "    _ = ax.set_xlabel('')\n",
    "    _xticks = ax.get_xticks()\n",
    "    ax.xaxis.set_major_locator(\n",
    "        matplotlib.ticker.FixedLocator(_xticks)\n",
    "    )\n",
    "    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45,\n",
    "                           horizontalalignment='right')\n",
    "\n",
    "    N_hues = len(pd.unique(to_plot[args.target]))\n",
    "\n",
    "    _ = ax.collections[0].set_paths([new_mk])\n",
    "    _ = ax.collections[1].set_paths([new_mk])\n",
    "\n",
    "    label_target_0, label_target_1 = ax.collections[-2].get_label(), ax.collections[-1].get_label()\n",
    "    _ = ax.collections[-2].set_label(f'imputed, {label_target_0}')\n",
    "    _ = ax.collections[-1].set_label(f'imputed, {label_target_1}')\n",
    "    _obs_label0 = ax.scatter([], [], color='C0', marker='X', label=f'observed, {label_target_0}')\n",
    "    _obs_label1 = ax.scatter([], [], color='C1', marker='X', label=f'observed, {label_target_1}')\n",
    "    _ = ax.legend(\n",
    "        handles=[_obs_label0, _obs_label1, *ax.collections[-4:-2]],\n",
    "        fontsize=5, title_fontsize=5, markerscale=0.4,)\n",
    "    fname = (folder /\n",
    "             f'{first_pg}_swarmplot.pdf')\n",
    "    files_out[fname.name] = fname.as_posix()\n",
    "    vaep.savefig(\n",
    "        fig,\n",
    "        name=fname)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899bcf9",
   "metadata": {},
   "source": [
    "Saved files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b042a1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "files_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
