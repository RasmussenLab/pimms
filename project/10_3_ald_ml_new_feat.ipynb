{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f8edbd",
   "metadata": {},
   "source": [
    "# Compare outcomes from differential analysis based on different imputation methods\n",
    "\n",
    "- load scores based on `10_1_ald_diff_analysis.ipynb`\n",
    "- compare performance for set of features included in original Study\n",
    "  to the set of features included in Niu. et. al 2022\n",
    "  (by lowering the threshold for feature completeness))\n",
    "- RSN should be set as baseline if Niu et. al 2022 data is used\n",
    "\n",
    "This notebook could be adapted to compare\n",
    "1. different set of features which were classified \"significant\" (is there signal)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c6764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import njab.sklearn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from njab.plotting.metrics import plot_split_auc, plot_split_prc\n",
    "from njab.sklearn.types import Splits\n",
    "\n",
    "import vaep\n",
    "import vaep.analyzers\n",
    "import vaep.io.datasplits\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (2.5, 2.5)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.markersize'] = 2\n",
    "fontsize = 5\n",
    "figsize = (2.5, 2.5)\n",
    "vaep.plotting.make_large_descriptors(fontsize)\n",
    "\n",
    "\n",
    "logger = vaep.logging.setup_nb_logger()\n",
    "logging.getLogger('fontTools').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch passed parameters\n",
    "args = None\n",
    "args = dict(globals()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c9ae8",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cd83d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "folder_data: str = ''  # specify data directory if needed\n",
    "fn_clinical_data = \"data/ALD_study/processed/ald_metadata_cli.csv\"\n",
    "folder_experiment = \"runs/appl_ald_data/plasma/proteinGroups\"\n",
    "model_key = 'VAE'\n",
    "target = 'kleiner'\n",
    "sample_id_col = 'Sample ID'\n",
    "cutoff_target: int = 2  # => for binarization target >= cutoff_target\n",
    "file_format = \"csv\"\n",
    "out_folder = 'diff_analysis'\n",
    "fn_qc_samples = ''  # 'data/ALD_study/processed/qc_plasma_proteinGroups.pkl'\n",
    "\n",
    "baseline = 'RSN'  # default is RSN, as this was used in the original ALD Niu. et. al 2022\n",
    "template_pred = 'pred_real_na_{}.csv'  # fixed, do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13538b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = vaep.nb.get_params(args, globals=globals())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vaep.nb.Config()\n",
    "args.folder_experiment = Path(params[\"folder_experiment\"])\n",
    "args = vaep.nb.add_default_paths(args,\n",
    "                                 out_root=(args.folder_experiment\n",
    "                                           / params[\"out_folder\"]\n",
    "                                           / params[\"target\"]\n",
    "                                           / f\"{params['baseline']}_vs_{params['model_key']}\"))\n",
    "args.update_from_dict(params)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_out = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb7cc9",
   "metadata": {},
   "source": [
    "## Load target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(args.fn_clinical_data,\n",
    "                     index_col=0,\n",
    "                     usecols=[args.sample_id_col, args.target])\n",
    "target = target.dropna()\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bbf2a2",
   "metadata": {},
   "source": [
    "### Measured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vaep.io.datasplits.DataSplits.from_folder(\n",
    "    args.data, file_format=args.file_format)\n",
    "data = pd.concat([data.train_X, data.val_y, data.test_y])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b446e",
   "metadata": {},
   "source": [
    "Get overlap between independent features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ad218",
   "metadata": {},
   "source": [
    "### Load ALD data or create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COMPLETENESS = 0.6\n",
    "MIN_N_PROTEIN_GROUPS: int = 200\n",
    "FRAC_PROTEIN_GROUPS: int = 0.622\n",
    "CV_QC_SAMPLE: float = 0.4\n",
    "\n",
    "ald_study, cutoffs = vaep.analyzers.diff_analysis.select_raw_data(data.unstack(\n",
    "), data_completeness=DATA_COMPLETENESS, frac_protein_groups=FRAC_PROTEIN_GROUPS)\n",
    "\n",
    "if args.fn_qc_samples:\n",
    "    qc_samples = pd.read_pickle(args.fn_qc_samples)\n",
    "    qc_samples = qc_samples[ald_study.columns]\n",
    "    qc_cv_feat = qc_samples.std() / qc_samples.mean()\n",
    "    qc_cv_feat = qc_cv_feat.rename(qc_samples.columns.name)\n",
    "    fig, ax = plt.subplots(figsize=(4, 7))\n",
    "    ax = qc_cv_feat.plot.box(ax=ax)\n",
    "    ax.set_ylabel('Coefficient of Variation')\n",
    "    print((qc_cv_feat < CV_QC_SAMPLE).value_counts())\n",
    "    ald_study = ald_study[vaep.analyzers.diff_analysis.select_feat(qc_samples)]\n",
    "\n",
    "column_name_first_prot_to_pg = {\n",
    "    pg.split(';')[0]: pg for pg in data.unstack().columns}\n",
    "\n",
    "ald_study = ald_study.rename(columns=column_name_first_prot_to_pg)\n",
    "ald_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_has_target = data.index.levels[0].intersection(target.index)\n",
    "assert not mask_has_target.empty, f\"No data for target: {data.index.levels[0]} and {target.index}\"\n",
    "print(\n",
    "    f\"Samples available both in proteomics data and for target: {len(mask_has_target)}\")\n",
    "target, data, ald_study = target.loc[mask_has_target], data.loc[mask_has_target], ald_study.loc[mask_has_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc05bf5",
   "metadata": {},
   "source": [
    "### Load semi-supervised model imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f072d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = args.out_preds / args.template_pred.format(args.model_key)\n",
    "print(f\"missing values pred. by {args.model_key}: {fname}\")\n",
    "load_single_csv_pred_file = vaep.analyzers.compare_predictions.load_single_csv_pred_file\n",
    "pred_real_na = load_single_csv_pred_file(fname).loc[mask_has_target]\n",
    "pred_real_na.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = args.out_preds / args.template_pred.format(args.baseline)\n",
    "pred_real_na_baseline = load_single_csv_pred_file(fname)  # .loc[mask_has_target]\n",
    "pred_real_na_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa21c8b",
   "metadata": {},
   "source": [
    "# Model predictions\n",
    "General approach:\n",
    "  - use one train, test split of the data\n",
    "  - select best 10 features from training data `X_train`, `y_train` before binarization of target\n",
    "  - dichotomize (binarize) data into to groups (zero and 1)\n",
    "  - evaluate model on the test data `X_test`, `y_test`\n",
    "\n",
    "Repeat general approach for\n",
    " 1. all original ald data: all features justed in original ALD study\n",
    " 2. all model data: all features available my using the self supervised deep learning model\n",
    "3. newly available feat only: the subset of features available from the\n",
    "self supervised deep learning model which were newly retained using the\n",
    "new approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([data, pred_real_na]).unstack()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be just observed, drop columns with missing values\n",
    "ald_study = pd.concat(\n",
    "    [ald_study.stack(),\n",
    "     pred_real_na_baseline.loc[\n",
    "        # only select columns in selected in ald_study\n",
    "        pd.IndexSlice[:, ald_study.columns]\n",
    "    ]\n",
    "    ]\n",
    ").unstack()\n",
    "ald_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = X.columns.difference(ald_study.columns)\n",
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e67247-a2a1-4a2f-b838-0bdc9f40cfa9",
   "metadata": {},
   "source": [
    "Binarize targets, but also keep groups for stratification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1f404-427a-4e78-b98d-cb26bb1d1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_group = target.copy()\n",
    "target = target >= args.cutoff_target\n",
    "pd.crosstab(target.squeeze(), target_to_group.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab754f",
   "metadata": {},
   "source": [
    "## Best number of parameters by CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e410d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_feat_ald = njab.sklearn.find_n_best_features(X=ald_study, y=target, name=args.target,\n",
    "                                                groups=target_to_group)\n",
    "cv_feat_ald = cv_feat_ald.groupby('n_features').agg(['mean', 'std'])\n",
    "cv_feat_ald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_feat_all = njab.sklearn.find_n_best_features(X=X, y=target, name=args.target,\n",
    "                                                groups=target_to_group)\n",
    "cv_feat_all = cv_feat_all.groupby('n_features').agg(['mean', 'std'])\n",
    "cv_feat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_feat_new = njab.sklearn.find_n_best_features(X=X.loc[:, new_features],\n",
    "                                                y=target, name=args.target,\n",
    "                                                groups=target_to_group)\n",
    "cv_feat_new = cv_feat_new.groupby('n_features').agg(['mean', 'std'])\n",
    "cv_feat_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72655713",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat_best = pd.DataFrame(\n",
    "    {'ald': cv_feat_ald.loc[:, pd.IndexSlice[:, 'mean']].idxmax(),\n",
    "     'all': cv_feat_all.loc[:, pd.IndexSlice[:, 'mean']].idxmax(),\n",
    "     'new': cv_feat_new.loc[:, pd.IndexSlice[:, 'mean']].idxmax()\n",
    "     }\n",
    ").droplevel(-1)\n",
    "n_feat_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdc8bf",
   "metadata": {},
   "source": [
    "## Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X,\n",
    "    target,\n",
    "    test_size=.2,\n",
    "    stratify=target_to_group,\n",
    "    random_state=42)\n",
    "idx_train = X_train.index\n",
    "idx_test = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "njab.pandas.combine_value_counts(\n",
    "    pd.concat([y_train, y_test],\n",
    "              axis=1,\n",
    "              ignore_index=True,\n",
    "              )\n",
    "    .rename(columns={0: 'train', 1: 'test'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71879005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b528b8e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- `run_model` returns dataclasses with the further needed results\n",
    "- add mrmr selection of data (select best number of features to use instead of fixing it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9de8b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "splits = Splits(X_train=X.loc[idx_train],\n",
    "                X_test=X.loc[idx_test],\n",
    "                y_train=y_train,\n",
    "                y_test=y_test)\n",
    "results_model_full = njab.sklearn.run_model(\n",
    "    splits,\n",
    "    n_feat_to_select=n_feat_best.loc['test_roc_auc', 'all'])\n",
    "results_model_full.name = f'{args.model_key} all'\n",
    "fname = args.out_folder / f'results_{results_model_full.name}.pkl'\n",
    "files_out[fname.name] = fname\n",
    "vaep.io.to_pickle(results_model_full, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18688a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all(results_model_full.test.roc.tpr\n",
    "#     ==\n",
    "#     vaep.sklearn.Results.from_pickle(fname).test.roc.tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e72950",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = Splits(X_train=X.loc[idx_train, new_features],\n",
    "                X_test=X.loc[idx_test, new_features],\n",
    "                y_train=y_train,\n",
    "                y_test=y_test)\n",
    "results_model_new = njab.sklearn.run_model(\n",
    "    splits,\n",
    "    n_feat_to_select=n_feat_best.loc['test_roc_auc', 'new'])\n",
    "results_model_new.name = f'{args.model_key} new'\n",
    "fname = args.out_folder / f'results_{results_model_new.name}.pkl'\n",
    "files_out[fname.name] = fname\n",
    "vaep.io.to_pickle(results_model_new, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ec22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_ald = Splits(\n",
    "    X_train=ald_study.loc[idx_train],\n",
    "    X_test=ald_study.loc[idx_test],\n",
    "    y_train=y_train,\n",
    "    y_test=y_test)\n",
    "results_ald_full = njab.sklearn.run_model(\n",
    "    splits_ald,\n",
    "    n_feat_to_select=n_feat_best.loc['test_roc_auc', 'ald'])\n",
    "results_ald_full.name = 'ALD study all'\n",
    "fname = args.out_folder / f'results_{results_ald_full.name}.pkl'\n",
    "files_out[fname.name] = fname\n",
    "vaep.io.to_pickle(results_ald_full, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b1db5",
   "metadata": {},
   "source": [
    "### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b82583",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "plot_split_auc(results_ald_full.test, results_ald_full.name, ax)\n",
    "plot_split_auc(results_model_full.test, results_model_full.name, ax)\n",
    "plot_split_auc(results_model_new.test, results_model_new.name, ax)\n",
    "fname = args.out_folder / 'auc_roc_curve.pdf'\n",
    "files_out[fname.name] = fname\n",
    "vaep.savefig(fig, name=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9a3f2-89aa-4bd5-a083-d8e16815020a",
   "metadata": {},
   "source": [
    "### Features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = pd.DataFrame(\n",
    "    [results_ald_full.selected_features,\n",
    "     results_model_full.selected_features,\n",
    "     results_model_new.selected_features],\n",
    "    index=[\n",
    "        results_ald_full.name,\n",
    "        results_model_full.name,\n",
    "        results_model_new.name]\n",
    ").T\n",
    "selected_features.index.name = 'rank'\n",
    "fname = args.out_folder / 'mrmr_feat_by_model.xlsx'\n",
    "files_out[fname.name] = fname\n",
    "selected_features.to_excel(fname)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce227174",
   "metadata": {},
   "source": [
    "### Precision-Recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "ax = plot_split_prc(results_ald_full.test, results_ald_full.name, ax)\n",
    "ax = plot_split_prc(results_model_full.test, results_model_full.name, ax)\n",
    "ax = plot_split_prc(results_model_new.test, results_model_new.name, ax)\n",
    "fname = folder = args.out_folder / 'prec_recall_curve.pdf'\n",
    "files_out[fname.name] = fname\n",
    "vaep.savefig(fig, name=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf0913",
   "metadata": {},
   "source": [
    "## Train data plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "ax = plot_split_prc(results_ald_full.train, results_ald_full.name, ax)\n",
    "ax = plot_split_prc(results_model_full.train, results_model_full.name, ax)\n",
    "ax = plot_split_prc(results_model_new.train, results_model_new.name, ax)\n",
    "fname = folder = args.out_folder / 'prec_recall_curve_train.pdf'\n",
    "files_out[fname.name] = fname\n",
    "vaep.savefig(fig, name=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fee389",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "plot_split_auc(results_ald_full.train, results_ald_full.name, ax)\n",
    "plot_split_auc(results_model_full.train, results_model_full.name, ax)\n",
    "plot_split_auc(results_model_new.train, results_model_new.name, ax)\n",
    "fname = folder = args.out_folder / 'auc_roc_curve_train.pdf'\n",
    "files_out[fname.name] = fname\n",
    "vaep.savefig(fig, name=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b7a34",
   "metadata": {},
   "source": [
    "Options:\n",
    "- F1 results for test data for best cutoff on training data?\n",
    "  (select best cutoff of training data, evaluate on test data)\n",
    "- plot X_train PCA/UMAP, map X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
