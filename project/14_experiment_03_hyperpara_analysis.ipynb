{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149ddbfc-c339-4843-8801-9eca57b0ff5e",
   "metadata": {},
   "source": [
    "# Analyis of grid hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a7b57-371d-4463-8da4-201e793f4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import vaep.nb\n",
    "matplotlib.rcParams['figure.figsize'] = [16.0, 7.0]\n",
    "\n",
    "import vaep.io\n",
    "import vaep.pandas\n",
    "import vaep.utils\n",
    "from vaep.analyzers import compare_predictions\n",
    "\n",
    "pd.options.display.max_columns = 45\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.multi_sparse = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b7560-f825-4461-95ad-bf90accd2e87",
   "metadata": {},
   "source": [
    "### Papermill parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd7732-e5c1-45fb-aff3-4a5dc2446078",
   "metadata": {},
   "source": [
    "papermill parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6189a40-cfe2-4a53-9ce9-d7f86080bf79",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metrics_json:str = \"path/to/all_metrics.json\" # file path to metrics json\n",
    "configs_json:str = \"path/to/all_configs.json\" # file path to configs json (\"meta data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b0bba-e6ed-44bf-a7cc-f8f378c42d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert pathlib.Path(metrics_json).exists()\n",
    "    assert pathlib.Path(configs_json).exists()\n",
    "except AssertionError:\n",
    "    metrics_json = snakemake.input.metrics\n",
    "    configs_json = snakemake.input.config\n",
    "    print(f\"{metrics_json = }\", f\"{configs_json = }\", sep=\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643bbea-09af-479a-b3e5-52fbd47fa6af",
   "metadata": {},
   "source": [
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc31625-6f9d-4f96-b531-93561e7bafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metrics_json = pathlib.Path(metrics_json)\n",
    "path_configs_json = pathlib.Path(configs_json)\n",
    "FOLDER = path_metrics_json.parent\n",
    "\n",
    "metrics_dict = vaep.io.load_json(path_metrics_json)\n",
    "configs_dict = vaep.io.load_json(path_configs_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c27e42-63a3-4ce8-b5e1-a022918c08b3",
   "metadata": {},
   "source": [
    "Random sample metric schema (all should be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05645db5-fed7-435a-a105-63c5166be601",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_sampled = vaep.utils.sample_iterable(metrics_dict, 1)[0]\n",
    "key_map = vaep.pandas.key_map(metrics_dict[key_sampled])\n",
    "key_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92fb12-c384-4bb2-acce-4ec1d0b6597c",
   "metadata": {},
   "source": [
    "Metrics a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f324d3-48bf-43ef-aa2a-c0bd1ab9c188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dict_multikey = {}\n",
    "for k, run_metrics in metrics_dict.items():\n",
    "    metrics_dict_multikey[k] = {eval(k): v for k, v in run_metrics.items()} #vaep.pandas.flatten_dict_of_dicts(run_metrics)\n",
    "\n",
    "# metrics_dicts = {\n",
    "#     'AEs': {k:v for k,v in metrics_dict_multikey.items() if 'collab' not in k},\n",
    "#     'collab': {k:v for k,v in metrics_dict_multikey.items() if 'collab' in k}\n",
    "# }\n",
    "\n",
    "metrics = pd.DataFrame.from_dict(metrics_dict_multikey, orient='index')\n",
    "metrics.columns.names = ['subset','data_split', 'model', 'metric_name']\n",
    "metrics.index.name = 'id'\n",
    "metrics = metrics.dropna(axis=1,how='all')\n",
    "metrics = metrics.stack('model')\n",
    "metrics = metrics.drop_duplicates()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1bfc3-f189-4a73-b13a-5e24ab113a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort_values(by=('NA interpolated', 'valid_fake_na', 'MAE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f9b28-195e-4c74-a8de-c776fd0f4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_by = 'MAE'\n",
    "metric_columns = ['MSE', 'MAE']\n",
    "model_keys = ['collab', 'dae', 'vae']\n",
    "subset = metrics.columns.levels[0][0]\n",
    "print(f\"{subset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7278b3-ef8a-43f8-ade0-d8777b9b41b4",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e754e-9c0e-46dd-962e-084da27c9229",
   "metadata": {},
   "source": [
    "Experiment metadata from configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815da3a8-11e7-4ed4-bdaf-dc331eddc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_json(path_configs_json).T\n",
    "meta['hidden_layers'] = meta.loc[meta['hidden_layers'].notna() ,'hidden_layers'].apply(tuple) # make list a tuple\n",
    "meta['n_hidden_layers'] = meta.hidden_layers.loc[meta['hidden_layers'].notna()].apply(len).fillna(0)\n",
    "\n",
    "mask_collab = meta.index.str.contains('collab')\n",
    "meta.loc[mask_collab, 'batch_size'] = meta.loc[mask_collab, 'batch_size_collab']\n",
    "meta.loc[mask_collab, 'hidden_layers'] = None\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd468f-8995-403d-a389-6c4e4e912cd5",
   "metadata": {},
   "source": [
    "Batch size for collab models depends on a factor (as the data in long format has roughly  N samples * M features entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef0010-3bec-4e5a-804c-5f861e975499",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Top 10 for fake na validation data\n",
    "- options see [2Dline plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb4643-91e2-4d40-b0e4-80b0fcf95861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = metrics[subset][\"valid_fake_na\"].sort_values(\n",
    "    'MSE').iloc[:10, :-1].plot(rot=70, \n",
    "                          x_compat=True, \n",
    "                          xticks=list(range(10)),\n",
    "                          marker='o',\n",
    "                          linestyle='',\n",
    "                          title='Top 10 results for hyperparameters',\n",
    "                          figsize=(16,7)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186839c9-c1c5-410c-9309-f950bf9341b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.savefig(fig, name='top_10_models_validation_fake_na', folder=FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c44238-09d1-4c79-95f3-597cce466cb2",
   "metadata": {},
   "source": [
    "## Colorcoded metrics\n",
    "\n",
    "- can be one of the [matplotlib color maps](https://matplotlib.org/stable/tutorials/colors/colormaps.html), which also have reversed version indicated by `*_r`\n",
    "\n",
    "``` python\n",
    "['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9c512-3d62-47bf-a2e6-cae812139181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='cividis_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40f89-177b-4750-8141-430ac49e5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_styled = metrics.unstack('model')\n",
    "\n",
    "metrics_styled = (\n",
    "    metrics_styled.set_index(\n",
    "        pd.MultiIndex.from_frame(\n",
    "            meta.loc[metrics_styled.index, ['latent_dim', 'hidden_layers', 'batch_size']]\n",
    "        ))\n",
    "    .sort_index()\n",
    "    .stack('model')\n",
    "    .style.background_gradient(cmap)\n",
    ")\n",
    "metrics = metrics_styled.data\n",
    "metrics_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98751f1e-e3e3-42ba-87e2-0d1b33d71927",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_styled.to_excel(FOLDER/ 'metrics_styled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58907b2-7230-4861-bc5b-b4b838c86a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in metrics.columns.levels[0][::-1]:\n",
    "    print(\"\\n\"+\"*\"*10, f\"Subset: {k}\\n\")\n",
    "    display(metrics[k].style.background_gradient(cmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57933a40-4833-43f4-aa1c-79e20c64ed34",
   "metadata": {},
   "source": [
    "### Plot Top 10 for fake na validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee241c3-ec2b-4a3c-bd7f-464dee83c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = metrics[subset][\"valid_fake_na\"].sort_values(\n",
    "    'MSE').iloc[:10,:-1].plot(rot=45,\n",
    "                          x_compat=False,\n",
    "                          xticks=list(range(10)),\n",
    "                          marker='o',\n",
    "                          linestyle='',\n",
    "                          figsize=(16,7)    \n",
    "                          )\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.savefig(fig, name='top_10_models_validation_fake_na_v02', folder=FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05589b16-d50b-472c-acef-dc6ac2e2383b",
   "metadata": {},
   "source": [
    "## Collection of Performance plots \n",
    "\n",
    "- similar to hyperparameter performance plots in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b486602-52ed-483f-aaf5-16561e7b7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.unstack('model').reset_index()\n",
    "metrics.iloc[:, :7].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0a0e4-a4be-4d9f-b3e9-b75795465a8f",
   "metadata": {},
   "source": [
    "### Parallel coordinates\n",
    "\n",
    "- similar to Tensorboard visualization of a set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef6715-ebac-484d-9052-13abd56b1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parallel_categories(metrics=metrics, model_type='DAE', metric_type='MSE', subset='NA interpolated', split='valid_fake_na'):\n",
    "    sel_metric = (subset, split , metric_type, model_type)\n",
    "    metric_sel = metrics.loc[:, [('latent_dim', '', '', ''),\n",
    "                                ('hidden_layers', '', '', ''),\n",
    "                                sel_metric]].dropna()\n",
    "    title = ' '.join(sel_metric)\n",
    "    metric_sel.columns = [' '.join(x[0].split('_'))\n",
    "                        for x in metric_sel.columns[:-1]] + [sel_metric[-2]]\n",
    "    fig = px.parallel_categories(metric_sel, dimensions=metric_sel.columns[:-1],\n",
    "                color=\"MSE\", color_continuous_scale=px.colors.sequential.Inferno,\n",
    "                title=title\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_parallel_categories(model_type='DAE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9231b-0eeb-49c6-b521-b46e3d578bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_parallel_categories(metrics, 'VAE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f2894-2d9c-4fb5-ad7b-9b693d66d464",
   "metadata": {},
   "source": [
    "### Plotting without Multi-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e41a08-e503-461d-89cb-a050e4c6e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {k: vaep.pandas.create_dict_of_dicts(d) for k, d in metrics_dict_multikey.items()}\n",
    "metrics = pd.json_normalize([{'index': k, **d} for k,d in metrics.items()], meta='index', sep= ' ')\n",
    "metrics = metrics.set_index('index')\n",
    "metrics = meta.join(metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf7405-e205-4558-9335-083b398b97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\"NA not interpolated valid_collab collab MSE\": 'MSE',\n",
    "               'batch_size_collab': 'bs',\n",
    "               'n_hidden_layers': \"No. of hidden layers\",\n",
    "               'latent_dim': 'hidden layer dimension',\n",
    "               'subset_w_N': 'subset',\n",
    "               'n_params': 'no. of parameter',\n",
    "               \"metric_value\": 'value',\n",
    "               'metric_name': 'metric'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bad110-eedf-4cbb-84e6-2d8d3dee6b6e",
   "metadata": {},
   "source": [
    "#### Single model metric - collab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b21959-b63d-45ba-9c02-486c49f9e1f6",
   "metadata": {},
   "source": [
    "### Plotting from long format\n",
    "\n",
    "To use colors meaningfully, the long format of the data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279f91a-37fd-4fbf-875d-ed34a4c3d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long = pd.DataFrame.from_dict(metrics_dict_multikey, orient='index')\n",
    "columns_names = ['subset', 'data_split', 'model', 'metric_name']\n",
    "metrics_long.columns.names = columns_names\n",
    "metrics_long.index.name = 'id'\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862bcfa-c01b-43ed-8a51-ddb994533d5e",
   "metadata": {},
   "source": [
    "Combine N into single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077fed-91dd-4459-9e64-257114ef3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_N = metrics_long.loc[:, pd.IndexSlice[:,:,:, 'N']]\n",
    "metrics_N = metrics_N.stack(['subset', 'data_split', 'model', 'metric_name']).unstack('metric_name').astype(int)\n",
    "metrics_N #.unstack(['subset', 'data_split', 'model',])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b761ec0-6f98-4cf7-a119-a9e3cfdca275",
   "metadata": {},
   "source": [
    "join N used to compute metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816c310-86ed-498b-9b3f-31ff2761317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long=metrics_long.loc[:, pd.IndexSlice[:,:,:, metric_columns]]\n",
    "metrics_long = metrics_long.stack(metrics_long.columns.names).to_frame('metric_value').reset_index('metric_name').join(metrics_N)\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff17f3-2723-440c-9a26-1ca40ed5008b",
   "metadata": {},
   "source": [
    "join metadata for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccda5f-354e-40ae-8b5e-c37a34219a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long = metrics_long.reset_index(['subset', 'data_split', 'model']).join(meta)\n",
    "metrics_long.index.name = 'id'\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a8b50-fa2e-4b37-bda5-464e337f6bbb",
   "metadata": {},
   "source": [
    "Combine number of parameters into one columns (they are mutually exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3467a-4b2b-4271-8550-827166398c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long['n_params'] = metrics_long['n_params_collab']\n",
    "for key in ['DAE', 'VAE']:\n",
    "    mask = metrics_long.model == key\n",
    "    metrics_long.loc[mask, 'n_params'] = metrics_long.loc[mask, f'n_params_{key.lower()}']\n",
    "mask = metrics_long.model == 'interpolated'\n",
    "metrics_long.loc[mask, 'n_params'] = 1 # at least overall (and 1 for the number of replicates?)\n",
    "mask = metrics_long.model == 'median'\n",
    "metrics_long.loc[mask, 'n_params'] = metrics_long.loc[mask, 'M'] # number of features to calculate median of\n",
    "\n",
    "metrics_long[[*columns_names, 'n_params', 'n_params_vae', 'n_params_dae', 'n_params_collab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe64834f-b73f-47c2-b669-0c50b8aa6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long['subset_w_N'] = metrics_long['subset'].str[0:] + ' - N: ' + metrics_long['N'].astype(str)\n",
    "metrics_long[['subset_w_N', 'subset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0513100-b917-4f3d-b85b-0e054c99f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long.to_csv(FOLDER / 'metrics_long_df.csv') # Should all the plots be done without the metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60021c-fbef-45e0-a7df-01267e1691d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_orders = {'model': ['median', 'interpolated', 'collab', 'DAE', 'VAE'],\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa12123-a809-407c-81a2-62bf1b54b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"NA interpolated valid_fake_na collab MAE\"\n",
    "# col = (\"NA interpolated\",\"valid_fake_na\",\"collab\",\"MSE\")\n",
    "fig = px.scatter(metrics_long.query('model == \"collab\"'),\n",
    "                 x=\"latent_dim\",\n",
    "                 y='metric_value',\n",
    "                 color=\"subset\", # needs data in long format\n",
    "                 facet_row=\"metric_name\",\n",
    "                 facet_col=\"data_split\",\n",
    "                 title='Performance of collaborative filtering models',\n",
    "                 labels={**labels_dict, 'data_split': 'data split'},\n",
    "                 category_orders={'data_split': ['valid_fake_na', 'test_fake_na']},\n",
    "                 width=1600,\n",
    "                 height=700,\n",
    "                 template='seaborn',\n",
    "                 )\n",
    "fig.update_layout(\n",
    "        font={'size': 18},\n",
    "        xaxis={'title': {'standoff': 15}},\n",
    "        yaxis={'title': {'standoff': 15}})\n",
    "fig.update_xaxes(dict(\n",
    "            tickmode='array',\n",
    "            tickvals=sorted(metrics_long[\"latent_dim\"].unique()),\n",
    "        )\n",
    "    )\n",
    "fig.write_image(FOLDER / 'collab_performance_overview.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba3f23-458e-4b20-8d02-527ef24c03a2",
   "metadata": {},
   "source": [
    "## Plot hyperparameter results - overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31231114-7184-4c38-a0c5-5d399a6ba901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_params(data_split: str = '', subset: str = ''):\n",
    "    selected = metrics_long\n",
    "    if data_split:\n",
    "        selected = selected.query(f'data_split == \"{data_split}\"')\n",
    "    if subset:\n",
    "        selected = selected.query(f'subset == \"{subset}\"')\n",
    "    fig = px.scatter(selected,\n",
    "                     x='n_params',\n",
    "                     y='metric_value',\n",
    "                     color=\"model\",\n",
    "                     facet_row=\"metric_name\",\n",
    "                     facet_col=\"subset_w_N\",\n",
    "                     hover_data=['hidden_layers', 'latent_dim'],\n",
    "                     #             'batch_size', 'batch_size_collab',\n",
    "                     # 'subset', f'NA not interpolated {dataset} N', f'NA interpolated {dataset} N'],\n",
    "                     title=f'Performance by number of parameters for {data_split.replace(\"_\", \" \")} data'.replace(\n",
    "                         \"  \", \" \"),\n",
    "                     labels=labels_dict,\n",
    "                     category_orders=category_orders,\n",
    "                     width=1600,\n",
    "                     height=700,\n",
    "                     template='seaborn',\n",
    "                     )\n",
    "    \n",
    "    fig.update_layout(\n",
    "            font={'size': 18},\n",
    "            xaxis={'title': {'standoff': 15}},\n",
    "            yaxis={'title': {'standoff': 15}})\n",
    "    return fig\n",
    "\n",
    "\n",
    "dataset = \"valid_fake_na\"\n",
    "fig = plot_by_params(dataset)\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results_by_parameters_all.pdf\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8725a-4e94-4b6b-ba0a-f9fbc0e03937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_by_params('', subset='NA interpolated')\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results_by_parameters_na_interpolated.pdf\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8190d51-c4db-4aae-8b91-11641958a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"test_fake_na\"\n",
    "fig = plot_by_params(dataset, 'NA interpolated')\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results_by_parameters_na_interpolated.pdf\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47534519",
   "metadata": {},
   "source": [
    "### select best run (->minimum loss) for criteria compared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdcc559-28de-4056-84b3-5f24ea175fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['data_split','subset', 'latent_dim', 'metric_name', 'model']\n",
    "metrics_long_sel_min = metrics_long.reset_index(\n",
    "    ).groupby(by=group_by\n",
    "    ).apply(lambda df: df.sort_values(by='metric_value').iloc[0]) \n",
    "metrics_long_sel_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43eceaa-ee22-456c-a3ca-1e830c17f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotly_figure(dataset: str, x='latent_dim'):\n",
    "    fig = px.scatter(metrics_long_sel_min.loc[dataset],\n",
    "                     x=x,\n",
    "                     y='metric_value',\n",
    "                     color=\"model\",\n",
    "                     facet_row=\"metric_name\",\n",
    "                     facet_col=\"subset_w_N\",\n",
    "                     hover_data=['n_hidden_layers', 'hidden_layers',\n",
    "                                 'batch_size', 'batch_size_collab',\n",
    "                                 'n_params'\n",
    "                                ],\n",
    "                     title=f'Performance on {dataset.replace(\"_\", \" \")} data',\n",
    "                     labels=labels_dict,\n",
    "                     category_orders=category_orders,\n",
    "                     width=1600,\n",
    "                     height=700,\n",
    "                     template='seaborn',\n",
    "                     )\n",
    "    fig.update_xaxes(dict(\n",
    "            tickmode='array',\n",
    "            tickvals=sorted(metrics_long[x].unique()),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "            font={'size': 18},\n",
    "            xaxis={'title': {'standoff': 15}},\n",
    "            yaxis={'title': {'standoff': 15}})\n",
    "    return fig\n",
    "\n",
    "\n",
    "dataset = 'test_fake_na'\n",
    "fig = get_plotly_figure(dataset)\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results_best.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061609a-7179-45dc-a8eb-3172731fce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'valid_fake_na'\n",
    "fig = get_plotly_figure(dataset)\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results_best.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa690af-5dcc-4857-a248-1860999f79d1",
   "metadata": {},
   "source": [
    "## Plot for best models predictions along completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655092b2-0ba2-4ff0-b408-d982df1501c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'valid_fake_na'\n",
    "group_by = ['data_split', 'subset', 'metric_name', 'model', 'latent_dim' ]\n",
    "selected = metrics_long.reset_index(\n",
    "    ).groupby(by=group_by\n",
    "    ).apply(lambda df: df.sort_values(by='metric_value').iloc[0]).loc[dataset]\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b26f17-7912-49f3-a2cd-07c8115bfa00",
   "metadata": {},
   "source": [
    "select minimum value of latent dim over trained models on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e3210-bafe-4456-b7e8-2bad861d0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_latent = selected.loc['NA interpolated'].loc['MAE'].loc[['DAE', 'VAE', 'collab']].groupby(level='latent_dim').mean().sort_values('metric_value')\n",
    "min_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abef54-3dff-4b89-b4df-50bc6ceb87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_latent = min_latent.index[0]\n",
    "print(\"Minimum latent value for average of models:\", min_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d4f94-2734-4352-a71e-4574aa1742ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.loc['NA interpolated'].loc['MAE'].loc[['collab', 'DAE', 'VAE']].loc[pd.IndexSlice[:, min_latent], :]\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58717630-1cd3-49c4-bbb1-6fd72c3688b1",
   "metadata": {},
   "source": [
    "load predictions (could be made better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f0b38-c04f-4161-b8f9-b9c224b45bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected['pred_to_load'] = (\n",
    "    selected['out_preds']\n",
    "    + ('/pred_val' if 'val' in dataset else '/pred_test_')  # not good...\n",
    "    + selected['hidden_layers'].apply(lambda s: '_hl_' + '_'.join(str(x) for x in s) + '_' if s is not None else '_')\n",
    "    + selected.model.str.lower()\n",
    "    + '.csv'\n",
    ")\n",
    "selected['pred_to_load'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67d69d-79be-4ae0-a02a-ca7d03d43244",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.to_csv(FOLDER / 'best_models_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2b861-4c89-4477-8961-b5009afaacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248050bc-5dfc-4923-aa16-7bc4888813d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {k: f'{k} - ' + \"HL: {}\".format(\n",
    "    str(selected.loc[k, 'hidden_layers'].to_list()[0]))\n",
    "          for k in selected.model\n",
    "         }\n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daea0ae-755d-4787-a319-4c737edc1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = compare_predictions.load_predictions(selected['pred_to_load'].to_list())[['observed', *category_orders['model']]]\n",
    "pred_val = pred_val.rename(mapper, axis=1)\n",
    "category_orders['model'] = list(pred_val.columns[1:])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610f3b7-4263-4932-9de6-dd2120eb685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.io import datasplits\n",
    "from vaep import sampling\n",
    "\n",
    "data = datasplits.DataSplits.from_folder(FOLDER / 'data', file_format='pkl') \n",
    "\n",
    "freq_feat = sampling.frequency_by_index(data.train_X, 0)\n",
    "freq_feat.name = 'freq'\n",
    "freq_feat.head() # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d47c6-1980-44cc-9b75-26fc406b5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val = pred_val.drop('observed', axis=1).sub(pred_val['observed'], axis=0)\n",
    "errors_val = errors_val.abs().groupby(freq_feat.index.name).mean()# # absolute error\n",
    "errors_val = errors_val.join(freq_feat)\n",
    "errors_val = errors_val.sort_values(by=freq_feat.name, ascending=True)\n",
    "errors_val.columns.name = 'model'\n",
    "errors_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52170533-1a9d-469a-9300-8811f50fc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_feat = len(errors_val)\n",
    "window_size = int(M_feat / 50)\n",
    "print(f\"Features in split: {M_feat}, set window size for smoothing: {window_size}\")\n",
    "msg_annotation = f\"(Latend dim: {min_latent}, No. of feat: {M_feat}, window_size: {window_size})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bec1c-399a-4fe5-86c6-4ef7dd0a909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val_smoothed = errors_val.copy()\n",
    "# errors_val_smoothed[errors_val.columns[:-1]] = errors_val[errors_val.columns[:-1]].rolling(window=window_size, min_periods=1).mean()\n",
    "errors_val_smoothed[category_orders['model']] = errors_val[category_orders['model']].rolling(window=window_size, min_periods=1).mean()\n",
    "ax = errors_val_smoothed.plot(x=freq_feat.name, ylabel='rolling error average', \n",
    "                             title=f'Rolling average error by feature frequency {msg_annotation}')\n",
    "\n",
    "vaep.savefig(\n",
    "    ax.get_figure(),\n",
    "    folder=FOLDER,\n",
    "    name=f'best_models_ld_{min_latent}_rolling_errors_by_freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a4be1-26d2-4983-ac39-b32d4918e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val_smoothed_long = errors_val_smoothed.drop('freq', axis=1).stack().to_frame('rolling error average').reset_index(-1).join(freq_feat)\n",
    "errors_val_smoothed_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2199ed3-7593-49f8-8620-f8eb779250fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig= px.line(errors_val_smoothed_long.sort_values(by='freq'),\n",
    "             x=freq_feat.name,\n",
    "             color='model',\n",
    "             y='rolling error average',\n",
    "             title=f'Rolling average error by feature frequency {msg_annotation}',\n",
    "             labels=labels_dict,\n",
    "             category_orders=category_orders,\n",
    "             width=1600,\n",
    "             height=700,\n",
    "             template='seaborn',\n",
    "                     )\n",
    "fig.update_layout(\n",
    "        font={'size': 18},\n",
    "        xaxis={'title': {'standoff': 15}},\n",
    "        yaxis={'title': {'standoff': 15}})\n",
    "fig.write_image(FOLDER / f'best_models_ld_{min_latent}_errors_by_freq_plotly.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68be9bc-4327-4df9-bc6b-67d39fd77318",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val_smoothed = errors_val.copy()\n",
    "ax = errors_val_smoothed.groupby(by='freq'\n",
    "                       ).mean(\n",
    "                       ).sort_index(\n",
    "                       ).rolling(window=5, min_periods=1\n",
    "                       ).mean().plot(\n",
    "    ylabel='rolling error average',\n",
    "    title='mean error for features averaged for each frequency'\n",
    ")\n",
    "\n",
    "vaep.savefig(\n",
    "    ax.get_figure(),\n",
    "    folder=FOLDER,\n",
    "    name=f'best_models_ld_{min_latent}_errors_by_freq_averaged')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7d773e1285093e5d1efa66e5c257432b552c5ab759d2ddd74cbe595bf26f7542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
