{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149ddbfc-c339-4843-8801-9eca57b0ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyis of grid hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a7b57-371d-4463-8da4-201e793f4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import vaep.io\n",
    "import vaep.pandas\n",
    "import vaep.utils\n",
    "\n",
    "pd.options.display.max_columns = 45\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.multi_sparse = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b7560-f825-4461-95ad-bf90accd2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Papermill parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd7732-e5c1-45fb-aff3-4a5dc2446078",
   "metadata": {},
   "outputs": [],
   "source": [
    "papermill parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6189a40-cfe2-4a53-9ce9-d7f86080bf79",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metrics_json:str = \"path/to/all_metrics.json\" # file path to metrics json\n",
    "configs_json:str = \"path/to/all_configs.json\" # file path to configs json (\"meta data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b0bba-e6ed-44bf-a7cc-f8f378c42d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert pathlib.Path(metrics_json).exists()\n",
    "    assert pathlib.Path(configs_json).exists()\n",
    "except AssertionError:\n",
    "    metrics_json = snakemake.input.metrics\n",
    "    configs_json = snakemake.input.config\n",
    "    print(f\"{metrics_json = }\", f\"{configs_json = }\", sep=\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643bbea-09af-479a-b3e5-52fbd47fa6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc31625-6f9d-4f96-b531-93561e7bafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metrics_json = pathlib.Path(metrics_json)\n",
    "path_configs_json = pathlib.Path(configs_json)\n",
    "FOLDER = path_metrics_json.parent\n",
    "\n",
    "metrics_dict = vaep.io.load_json(path_metrics_json)\n",
    "configs_dict = vaep.io.load_json(path_configs_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c27e42-63a3-4ce8-b5e1-a022918c08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random sample metric schema (all should be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05645db5-fed7-435a-a105-63c5166be601",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_sampled = vaep.utils.sample_iterable(metrics_dict, 1)[0]\n",
    "key_map = vaep.pandas.key_map(metrics_dict[key_sampled])\n",
    "key_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92fb12-c384-4bb2-acce-4ec1d0b6597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f324d3-48bf-43ef-aa2a-c0bd1ab9c188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dict_multikey = {}\n",
    "for k, run_metrics in metrics_dict.items():\n",
    "    metrics_dict_multikey[k] = {eval(k): v for k, v in run_metrics.items()} #vaep.pandas.flatten_dict_of_dicts(run_metrics)\n",
    "\n",
    "# metrics_dicts = {\n",
    "#     'AEs': {k:v for k,v in metrics_dict_multikey.items() if 'collab' not in k},\n",
    "#     'collab': {k:v for k,v in metrics_dict_multikey.items() if 'collab' in k}\n",
    "# }\n",
    "\n",
    "metrics = pd.DataFrame.from_dict(metrics_dict_multikey, orient='index')\n",
    "metrics.columns.names = ['subset','data_split', 'model', 'metric_name']\n",
    "metrics.index.name = 'id'\n",
    "metrics = metrics.dropna(axis=1,how='all')\n",
    "metrics = metrics.stack('model')\n",
    "metrics = metrics.drop_duplicates()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1bfc3-f189-4a73-b13a-5e24ab113a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['NA interpolated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f9b28-195e-4c74-a8de-c776fd0f4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by = 'MSE'\n",
    "metric_columns = ['MSE', 'MAE']\n",
    "subset = metrics.columns.levels[0][0]\n",
    "print(f\"{subset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7278b3-ef8a-43f8-ade0-d8777b9b41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e754e-9c0e-46dd-962e-084da27c9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment metadata from configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815da3a8-11e7-4ed4-bdaf-dc331eddc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_json(path_configs_json).T\n",
    "meta['hidden_layers'] = meta['hidden_layers'].apply(tuple) # make list a tuple\n",
    "meta['n_hidden_layers'] = meta.hidden_layers.apply(len)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd468f-8995-403d-a389-6c4e4e912cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch size for collab models depends on a factor (as the data in long format has roughly  N samples * M features entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ca3d0-0246-4c42-90e8-3186ae7fc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_collab = meta.index.str.contains('collab')\n",
    "meta.loc[mask_collab, 'batch_size'] = meta.loc[mask_collab, 'batch_size_collab']\n",
    "meta.loc[mask_collab, 'hidden_layers'] = None\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef0010-3bec-4e5a-804c-5f861e975499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plot Top 10 for fake na validation data\n",
    "- options see [2Dline plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb4643-91e2-4d40-b0e4-80b0fcf95861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = metrics[subset][\"valid_fake_na\"].sort_values(\n",
    "    'MSE').iloc[:10, :-1].plot(rot=70, \n",
    "                          x_compat=True, \n",
    "                          xticks=list(range(10)),\n",
    "                          marker='o',\n",
    "                          linestyle='',\n",
    "                          title='Top 10 results for hyperparameters',\n",
    "                          figsize=(16,7)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186839c9-c1c5-410c-9309-f950bf9341b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.savefig(fig, name='top_10_models_validation_fake_na', folder=FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c44238-09d1-4c79-95f3-597cce466cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colorcoded metrics\n",
    "\n",
    "- can be one of the [matplotlib color maps](https://matplotlib.org/stable/tutorials/colors/colormaps.html), which also have reversed version indicated by `*_r`\n",
    "\n",
    "``` python\n",
    "['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9c512-3d62-47bf-a2e6-cae812139181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='cividis_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40f89-177b-4750-8141-430ac49e5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_styled = metrics.unstack('model')\n",
    "\n",
    "metrics_styled = (\n",
    "    metrics_styled.set_index(\n",
    "        pd.MultiIndex.from_frame(\n",
    "            meta.loc[metrics_styled.index, ['latent_dim', 'hidden_layers', 'batch_size']]\n",
    "        ))\n",
    "    .sort_index()\n",
    "    .stack('model')\n",
    "    .style.background_gradient(cmap)\n",
    ")\n",
    "metrics = metrics_styled.data\n",
    "metrics_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98751f1e-e3e3-42ba-87e2-0d1b33d71927",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_styled.to_excel(FOLDER/ 'metrics_styled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58907b2-7230-4861-bc5b-b4b838c86a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in metrics.columns.levels[0][::-1]:\n",
    "    print(\"\\n\"+\"*\"*10, f\"Subset: {k}\\n\")\n",
    "    display(metrics[k].style.background_gradient(cmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57933a40-4833-43f4-aa1c-79e20c64ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Top 10 for fake na validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee241c3-ec2b-4a3c-bd7f-464dee83c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = metrics[subset][\"valid_fake_na\"].sort_values(\n",
    "    'MSE').iloc[:10,:-1].plot(rot=45,\n",
    "                          x_compat=False,\n",
    "                          xticks=list(range(10)),\n",
    "                          marker='o',\n",
    "                          linestyle='',\n",
    "                          figsize=(16,7)    \n",
    "                          )\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.savefig(fig, name='top_10_models_validation_fake_na_v02', folder=FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05589b16-d50b-472c-acef-dc6ac2e2383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collection of Performance plots \n",
    "\n",
    "- similar to hyperparameter performance plots in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b486602-52ed-483f-aaf5-16561e7b7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.unstack('model').reset_index()\n",
    "metrics.iloc[:, :7].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0a0e4-a4be-4d9f-b3e9-b75795465a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parallel coordinates\n",
    "\n",
    "- similar to Tensorboard visualization of a set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef6715-ebac-484d-9052-13abd56b1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parallel_categories(metrics=metrics, model_type='DAE', metric_type='MSE', subset='NA interpolated', split='valid_fake_na'):\n",
    "    sel_metric = (subset, split , metric_type, model_type)\n",
    "    metric_sel = metrics.loc[:, [('latent_dim', '', '', ''),\n",
    "                                ('hidden_layers', '', '', ''),\n",
    "                                sel_metric]].dropna()\n",
    "    title = ' '.join(sel_metric)\n",
    "    metric_sel.columns = [' '.join(x[0].split('_'))\n",
    "                        for x in metric_sel.columns[:-1]] + [sel_metric[-2]]\n",
    "    fig = px.parallel_categories(metric_sel, dimensions=metric_sel.columns[:-1],\n",
    "                color=\"MSE\", color_continuous_scale=px.colors.sequential.Inferno,\n",
    "                title=title\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_parallel_categories(model_type='DAE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9231b-0eeb-49c6-b521-b46e3d578bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_parallel_categories(metrics, 'VAE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f2894-2d9c-4fb5-ad7b-9b693d66d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting without Multi-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e41a08-e503-461d-89cb-a050e4c6e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {k: vaep.pandas.create_dict_of_dicts(d) for k, d in metrics_dict_multikey.items()}\n",
    "metrics = pd.json_normalize([{'index': k, **d} for k,d in metrics.items()], meta='index', sep= ' ')\n",
    "metrics = metrics.set_index('index')\n",
    "metrics = meta.join(metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf7405-e205-4558-9335-083b398b97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\"NA not interpolated valid_collab collab MSE\": 'MSE',\n",
    "               'batch_size_collab': 'bs',\n",
    "               'n_hidden_layers': \"No. of hidden layers\",\n",
    "               'latent_dim': 'hidden layer dimension'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bad110-eedf-4cbb-84e6-2d8d3dee6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Single model metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452893e2-afa7-447d-83a8-21cf8ee8d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"NA interpolated valid_fake_na collab MSE\"\n",
    "# col = (\"NA interpolated\",\"valid_fake_na\",\"collab\",\"MSE\")\n",
    "fig = px.scatter(metrics.dropna(subset=[col]),\n",
    "                 x=\"latent_dim\",\n",
    "                 y=col,\n",
    "                 # color=\"hidden layers\", # needs data in long format\n",
    "                 facet_row=\"batch_size_collab\",\n",
    "                #  facet_col=\"n_hidden_layers\",\n",
    "                 title='Performance on validation data for collaborative filtering model',\n",
    "                 labels=labels_dict\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b21959-b63d-45ba-9c02-486c49f9e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting from long format\n",
    "\n",
    "To use colors meaningfully, the long format of the data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279f91a-37fd-4fbf-875d-ed34a4c3d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long = pd.DataFrame.from_dict(metrics_dict_multikey, orient='index')\n",
    "metrics_long.columns.names = ['subset', 'data_split', 'model', 'metric_name']\n",
    "metrics_long.index.name = 'id'\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9664db-0006-4270-a0e8-a0e4f6fe1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_N = metrics_long.loc[:, pd.IndexSlice[:,:,:, 'N']]\n",
    "metrics_N.columns = [' '.join([*x[:2], x[3]]) for x in metrics_N.columns] #0, 1, 3 column index\n",
    "metrics_N = metrics_N.groupby(lambda x:x, axis=1).mean().astype(int) # aggregate non-missing entries -> summarize\n",
    "metrics_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816c310-86ed-498b-9b3f-31ff2761317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long=metrics_long.loc[:, pd.IndexSlice[:,:,:, metric_columns]]\n",
    "metrics_long = metrics_long.stack(metrics_long.columns.names).to_frame('metric_value').reset_index().set_index('id').join(metrics_N).join(meta)\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82413197-9663-4de2-b4a3-54fc56b081f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long = metrics_long.reset_index().set_index('data_split')\n",
    "metrics_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60021c-fbef-45e0-a7df-01267e1691d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(metrics_N.columns, key=lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d005b15-e234-4947-ab50-a92e15bb8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All model metrics for one subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367e684-836f-42e4-819d-43ffb3649398",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_long.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43eceaa-ee22-456c-a3ca-1e830c17f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test_fake_na'\n",
    "\n",
    "def get_plotly_figure(dataset):\n",
    "    fig = px.scatter(metrics_long.loc[dataset],\n",
    "                     x=\"latent_dim\",\n",
    "                     y='metric_value',\n",
    "                     color=\"model\",\n",
    "                     facet_row=\"metric_name\",\n",
    "                     facet_col=\"subset\",\n",
    "                     hover_data=['n_hidden_layers', 'hidden_layers',\n",
    "                                 'batch_size', 'batch_size_collab',\n",
    "                                 'n_params_dae', 'n_params_collab', 'n_params_vae',\n",
    "                                 'subset', f'NA not interpolated {dataset} N', f'NA interpolated {dataset} N'],\n",
    "                     title=f'Performance on {dataset.replace(\"_\", \" \")} data',\n",
    "                     labels={**labels_dict,\n",
    "                               \"metric_value\": '', 'metric_name': 'metric'}\n",
    "                     )\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = get_plotly_figure(dataset)\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061609a-7179-45dc-a8eb-3172731fce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'valid_fake_na'\n",
    "fig = get_plotly_figure(dataset)\n",
    "fig.write_image(FOLDER / f\"hyperpar_{dataset}_results.pdf\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
