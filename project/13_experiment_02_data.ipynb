{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02 - Data\n",
    "\n",
    "Find all samples in single plots.\n",
    "    - [ ] 1000 most abundant peptides\n",
    "\n",
    "Create batches of samples. Partition data to clusters of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from src.nb_imports import *\n",
    "\n",
    "\n",
    "import vaep.io_images\n",
    "import seaborn\n",
    "\n",
    "from pathlib import Path\n",
    "from src import metadata\n",
    "\n",
    "\n",
    "import logging\n",
    "from src.logging import setup_logger\n",
    "\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 02\")\n",
    "\n",
    "figures = {}  # collection of ax or figures\n",
    "\n",
    "ADD_TENSORBOARD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None takes all\n",
    "N_SAMPLES = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change some Matplotlib configuration defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'xtick.labelsize': 'xx-large',\n",
    "                     'ytick.labelsize': 'xx-large',\n",
    "                     'axes.titlesize' : 'xx-large',\n",
    "                     'axes.labelsize' : 'xx-large',\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only some sample have many missings\n",
    "\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N07813_M01000'  # all\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N07637_M01000'  # 60%\n",
    "FN_PEPTIDE_INTENSITIES = config.FOLDER_DATA / 'df_intensities_N07285_M01000'  # 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = AnalyzePeptides(fname=FN_PEPTIDE_INTENSITIES, nrows=None)\n",
    "analysis.df.columns.name = 'peptide'\n",
    "analysis.log_transform(np.log2)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date are not possible in the indices\n",
    "rename_indices_w_wrong_dates = {'20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_03': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_03',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_12': '20180330_QE10_nLC0_MR_QC_MNT_Hela_12',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_01': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_01',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_11': '20180330_QE10_nLC0_MR_QC_MNT_Hela_11',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_02': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_02',\n",
    "                                '20171208_MR_QC_HeLa2': '20171208_?_MR_QC_HeLa2'}\n",
    "analysis.df.rename(index=rename_indices_w_wrong_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N consecutive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort index\n",
    "analysis.df.sort_index(inplace=True)\n",
    "analysis.df_all = analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = min(len(analysis.df), N_SAMPLES) if N_SAMPLES else len(analysis.df)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "def get_consecutive_data_indices(df, n_samples=N_SAMPLES):\n",
    "    index = df.sort_index().index\n",
    "    start_sample = len(index) - n_samples\n",
    "    start_sample = random.randint(0, start_sample)\n",
    "    return df.loc[index[start_sample:start_sample+n_samples]]\n",
    "\n",
    "_attr_name = f'df_{N_SAMPLES}'\n",
    "setattr(analysis,_attr_name,get_consecutive_data_indices(analysis.df_all) )\n",
    "print(\"Training data stored under:\", _attr_name)\n",
    "analysis.df = getattr(analysis, _attr_name)\n",
    "analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not analysis.df._is_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove samples based on completeness\n",
    "\n",
    "- some sample have a low peptide count as they are originating from fractionated samples\n",
    "- remove samples based on a certain treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current minimal number of features out of {} in a single sample: {}\".format(\n",
    "    analysis.df.shape[-1],\n",
    "    analysis.df.notna().sum(axis=1).min()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ax = analysis.df.notna().sum(axis=1).hist(figsize=(10,5))\n",
    "_ = _ax.set_ylabel('counts')\n",
    "_ = _ax.set_xlabel('number of non-missing peptides')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- biological stock differences in PCA plot. Show differences in models. Only see biological variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.add_metadata()\n",
    "analysis.df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _idx, v in analysis.df_meta.researcher.value_counts().sort_index().items():\n",
    "    print(f'{_idx:7} - {v:3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to find date parsing errors, used for renaming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_dates = pd.to_datetime(analysis.df_meta.date, errors='coerce').isna()\n",
    "# display(analysis.df_meta.loc[invalid_dates])\n",
    "# {i : i for i in analysis.df_meta.loc[invalid_dates].index} # to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analysis.df_meta.lc_instrument.value_counts().sort_index()\n",
    "_.to_csv(config.PROCESSED_DATA / f'counts_{_.name}.csv')\n",
    "for _idx, v in _.items():\n",
    "    print(f'{_idx:7} - {v:3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analysis.df_meta.ms_instrument.value_counts().sort_index()\n",
    "_.to_csv(config.PROCESSED_DATA / f'counts_{_.name}.csv')\n",
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See rare instrument types (potential labeling errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MIN_INSTRUMENT = 10\n",
    "column = 'ms_instrument'\n",
    "ms_instruments = analysis.df_meta.ms_instrument.value_counts()\n",
    "ms_instruments = ms_instruments[ms_instruments <= N_MIN_INSTRUMENT].index\n",
    "print(f'Entries with less than {N_MIN_INSTRUMENT} in {column}: {\", \".join(str(x) for x in ms_instruments)}')\n",
    "mask = analysis.df_meta.ms_instrument.isin(ms_instruments)\n",
    "analysis.df_meta.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some further information in the rest\n",
    "\n",
    "abbreviation | what it stands for\n",
    "--- | ---\n",
    "MNT | maintanance (weekly runs to access quality)\n",
    "QC  | quality control (assessing instrument quality during an experiment) <br> - every x runs a QC is taken\n",
    "\n",
    "\n",
    "On liquid chromatography instruments:\n",
    "\n",
    "- sometimes instrument names are provided (LC1200) instead of their tags\n",
    "- `LC` and `nLC` are most likely the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of non-missing values\n",
    "\n",
    "- used for plotting the data in PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.prop_not_na "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis.plot_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.io_images._savefig(fig, config.FIGUREFOLDER/ f'pca_plot_raw_data_{analysis.fname_stub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single plots without titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "    15, 10), constrained_layout=True)\n",
    "pca = analysis.get_PCA()\n",
    "cols = pca.columns\n",
    "seaborn.scatterplot(x=pca[cols[0]], y=pca[cols[1]], hue=pca['ms_instrument'], ax=ax, palette='deep')\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.11, 0.5))\n",
    "\n",
    "vaep.io_images._savefig(fig, config.FIGUREFOLDER/ f'pca_plot_raw_data_{analysis.fname_stub}_by_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "    15, 10), constrained_layout=True)\n",
    "\n",
    "\n",
    "path_collection = analyzers.scatter_plot_w_dates(\n",
    "    ax, pca, dates=analysis.df_meta.date, errors='raise')\n",
    "path_collection = analyzers.add_date_colorbar(path_collection, ax=ax, fig=fig)\n",
    "ax.set_xlabel(cols[0])\n",
    "ax.set_ylabel(cols[1])\n",
    "\n",
    "vaep.io_images._savefig(fig, config.FIGUREFOLDER/ f'pca_plot_raw_data_{analysis.fname_stub}_by_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "    15, 10), constrained_layout=True)\n",
    "\n",
    "path_collection = ax.scatter(\n",
    "x=cols[0], y=cols[1], c=analysis.df_meta['prop_not_na'], data=pca, alpha=0.3)\n",
    "_ = fig.colorbar(path_collection, ax=ax)\n",
    "\n",
    "ax.set_xlabel(cols[0])\n",
    "ax.set_ylabel(cols[1])\n",
    "\n",
    "vaep.io_images._savefig(fig, config.FIGUREFOLDER/ f'pca_plot_raw_data_{analysis.fname_stub}_by_prop_not_NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching data using Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename get_PCA to get_PCs\n",
    "from sklearn.mixture import GaussianMixture \n",
    "N_COMPONENTS = 6\n",
    "gm = GaussianMixture(n_components=N_COMPONENTS, covariance_type='full')\n",
    "\n",
    "X = pca.iloc[:, :2].copy()\n",
    "gm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.means_, gm.covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['batch_predicted'] = gm.predict(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.columns\n",
    "seaborn.scatterplot(x=X[cols[0]], y=X[cols[1]], hue=X[cols[2]], palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['batch_predicted']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(config.PROCESSED_DATA / 'gaussian_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive PCA plots of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# seaborn.scatterplot(x=pca[cols[0]], y=pca[cols[1]], hue=pca['ms_instrument'], ax=ax, palette='deep')\n",
    "fig = px.scatter(pca, x=cols[0], y=cols[1], color=\"ms_instrument\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_format(self, colname_values='intensity', inplace=False):\n",
    "    df = self.df\n",
    "    df_long = df.unstack().dropna().to_frame(colname_values)\n",
    "    df_long = df_long.reset_index('Sample ID')\n",
    "    if inplace:\n",
    "        self.df_long = df_long\n",
    "        return\n",
    "    return df_long\n",
    "\n",
    "\n",
    "get_long_format(analysis, inplace=True)\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_long.isna().sum().sum() == 0, \"There are still missing values in the long format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wide_format(self, columns='Sample ID', name_values='intensity', inplace=False):\n",
    "    df_wide = self.df_long.pivot(columns=columns, values=name_values)\n",
    "    df_wide = df_wide.T\n",
    "    if inplace:\n",
    "        self.df_wide = df_wide\n",
    "        return\n",
    "    return df_wide\n",
    "\n",
    "\n",
    "get_wide_format(analysis, inplace=True)\n",
    "analysis.df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df_wide.isna().sum().sum() > 0, \"There are no missing values left in the wide format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling peptides by their frequency (important for later)\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_per_peptide = analysis.df.unstack().to_frame('intensity').reset_index(1, drop=True)\n",
    "freq_per_peptide = analysis.df_long['intensity']\n",
    "freq_per_peptide = freq_per_peptide.notna().groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = analysis.df.unstack().to_frame('intensity').reset_index(1)\n",
    "analysis.df_train = analysis.df_long.groupby(\n",
    "    by='Sample ID').sample(frac=0.95, weights=freq_per_peptide, random_state=42)\n",
    "analysis.df_train = analysis.df_train.reset_index().set_index([\n",
    "    'Sample ID', 'peptide'])\n",
    "analysis.df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex \n",
    "\n",
    "- use mulitindex for obtaining validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long = analysis.df_long.reset_index(\n",
    ").set_index(['Sample ID', 'peptide'])\n",
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.indices_valid = analysis.df_long.index.difference(\n",
    "    analysis.df_train.index)\n",
    "analysis.df_valid = analysis.df_long.loc[analysis.indices_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(analysis.df_long) == len(analysis.df_train) + len(analysis.df_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
