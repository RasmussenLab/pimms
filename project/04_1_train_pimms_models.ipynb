{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae0a078",
   "metadata": {},
   "source": [
    "# PIMMS Tutorial: Scikit-learn style transformers\n",
    "\n",
    "1. Load data into pandas dataframe\n",
    "2. Fit model on training data, potentially specify validation data\n",
    "3. Impute only missing values with predictions from model\n",
    "\n",
    "Autoencoders need wide training data, i.e. a sample with all its features' intensities, whereas\n",
    "Collaborative Filtering needs long training data, i.e. sample identifier a feature identifier and the intensity.\n",
    "Both data formats can be transformed into each other, but models using long data format do not need to\n",
    "take care of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0650846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import metadata\n",
    "IN_COLAB = 'COLAB_GPU' in os.environ\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        _v = metadata.version('pimms-learn')\n",
    "        print(f\"Running in colab and pimms-learn ({_v}) is installed.\")\n",
    "    except metadata.PackageNotFoundError:\n",
    "        print(\"Install PIMMS...\")\n",
    "        # !pip install git+https://github.com/RasmussenLab/pimms.git@dev\n",
    "        !pip install pimms-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5a27d",
   "metadata": {},
   "source": [
    "If on colab, please restart the environment and run everything from here on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b5bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "IN_COLAB = 'COLAB_GPU' in os.environ\n",
    "\n",
    "fn_intensities = 'data/dev_datasets/HeLa_6070/protein_groups_wide_N50.csv'\n",
    "if IN_COLAB:\n",
    "    fn_intensities = 'https://raw.githubusercontent.com/RasmussenLab/pimms/main/project/data/dev_datasets/HeLa_6070/protein_groups_wide_N50.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c289d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from vaep.plotting.defaults import color_model_mapping\n",
    "import vaep.plotting.data\n",
    "import vaep.sampling\n",
    "\n",
    "from vaep.sklearn.cf_transformer import CollaborativeFilteringTransformer\n",
    "from vaep.sklearn.ae_transformer import AETransformer\n",
    "\n",
    "vaep.plotting.make_large_descriptors(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b6650",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3edbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fn_intensities, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3ace",
   "metadata": {},
   "source": [
    "We will need the data in long format for Collaborative Filtering.\n",
    "Naming both the row and column index assures\n",
    "that the data can be transformed very easily into long format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'Sample ID'  # already set\n",
    "df.columns.name = 'protein group'  # not set due to csv disk file format\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c788f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab8dc7f",
   "metadata": {},
   "source": [
    "Transform the data using the logarithm, here using base 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d4fa7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df = np.log2(df + 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce73d1",
   "metadata": {},
   "source": [
    "two plots on data availability:\n",
    "\n",
    "1. proportion of missing values per feature median (N = protein groups)\n",
    "2. CDF of available intensities per protein group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536793bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ax = vaep.plotting.data.plot_feat_median_over_prop_missing(\n",
    "    data=df, type='boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bc55e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df.notna().sum().sort_values().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54a3af",
   "metadata": {},
   "source": [
    "define a minimum feature and sample frequency for a feature to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad27de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SELECT_FEAT = True\n",
    "\n",
    "\n",
    "def select_features(df, feat_prevalence=.2, axis=0):\n",
    "    # # ! vaep.filter.select_features\n",
    "    N = df.shape[axis]\n",
    "    minimum_freq = N * feat_prevalence\n",
    "    freq = df.notna().sum(axis=axis)\n",
    "    mask = freq >= minimum_freq\n",
    "    print(f\"Drop {(~mask).sum()} along axis {axis}.\")\n",
    "    freq = freq.loc[mask]\n",
    "    if axis == 0:\n",
    "        df = df.loc[:, mask]\n",
    "    else:\n",
    "        df = df.loc[mask]\n",
    "    return df\n",
    "\n",
    "\n",
    "if SELECT_FEAT:\n",
    "    # potentially this can take a few iterations to stabilize.\n",
    "    df = select_features(df, feat_prevalence=.2)\n",
    "    df = select_features(df=df, feat_prevalence=.3, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b1ee5",
   "metadata": {},
   "source": [
    "Transform to long-data format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ea5bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df = df.stack().to_frame('intensity')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792ce6e",
   "metadata": {},
   "source": [
    "The resulting DataFrame with one column has an `MulitIndex` with the sample and feature identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2390859",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567854c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # CollaborativeFilteringTransformer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ba4ce",
   "metadata": {},
   "source": [
    "Let's set up collaborative filtering without a validation or test set, using\n",
    "all the data there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b547a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model = CollaborativeFilteringTransformer(\n",
    "    target_column='intensity',\n",
    "    sample_column='Sample ID',\n",
    "    item_column='protein group',\n",
    "    out_folder='runs/scikit_interface')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86364d4",
   "metadata": {},
   "source": [
    "We use `fit` and `transform` to train the model and impute the missing values.\n",
    "> Scikit learns interface requires a `X` and `y`. `y` is the validation data in our context.\n",
    "> We might have to change the interface to allow usage within pipelines (-> `y` is not needed).\n",
    "> This will probably mean setting up a validation set within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ac432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.fit(df,\n",
    "             cuda=False,\n",
    "             epochs_max=20,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dac537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = cf_model.transform(df).unstack()\n",
    "assert df_imputed.isna().sum().sum() == 0\n",
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ba21b",
   "metadata": {},
   "source": [
    "Let's plot the distribution of the imputed values vs the ones used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df_imputed.stack()  # long-format\n",
    "observed = df_imputed.loc[df.index]\n",
    "imputed = df_imputed.loc[df_imputed.index.difference(df.index)]\n",
    "df_imputed = df_imputed.unstack()  # back to wide-format\n",
    "# some checks\n",
    "assert len(df) == len(observed)\n",
    "assert df_imputed.shape[0] * df_imputed.shape[1] == len(imputed) + len(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(8, 4))\n",
    "\n",
    "min_max = vaep.plotting.data.get_min_max_iterable(\n",
    "    [observed, imputed])\n",
    "label_template = '{method} (N={n:,d})'\n",
    "ax, _ = vaep.plotting.data.plot_histogram_intensities(\n",
    "    observed,\n",
    "    ax=axes[0],\n",
    "    min_max=min_max,\n",
    "    label=label_template.format(method='measured',\n",
    "                                n=len(observed),\n",
    "                                ),\n",
    "    color='grey',\n",
    "    alpha=1)\n",
    "_ = ax.legend()\n",
    "ax, _ = vaep.plotting.data.plot_histogram_intensities(\n",
    "    imputed,\n",
    "    ax=axes[1],\n",
    "    min_max=min_max,\n",
    "    label=label_template.format(method='CF imputed',\n",
    "                                n=len(imputed),\n",
    "                                ),\n",
    "    color=color_model_mapping['CF'],\n",
    "    alpha=1)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6552c",
   "metadata": {},
   "source": [
    "## AutoEncoder architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7184c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data (for demonstration)\n",
    "\n",
    "df = pd.read_csv(fn_intensities, index_col=0)\n",
    "df.index.name = 'Sample ID'  # already set\n",
    "df.columns.name = 'protein group'  # not set due to csv disk file format\n",
    "df = np.log2(df + 1)  # log transform\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52c6fe",
   "metadata": {},
   "source": [
    "The AutoEncoder model currently need validation data for training.\n",
    "We will use 10% of the training data for validation.\n",
    "> Expect this limitation to be dropped in the next release. It will still be recommended\n",
    "> to use validation data for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_feat = df.notna().sum()\n",
    "freq_feat.head()  # training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6c4e2",
   "metadata": {},
   "source": [
    "We will use the `sampling` module to sample the validation data from the training data.\n",
    "Could be split differently by providing another `weights` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X, train_X = vaep.sampling.sample_data(df.stack(),\n",
    "                                           sample_index_to_drop=0,\n",
    "                                           weights=freq_feat,\n",
    "                                           frac=0.1,\n",
    "                                           random_state=42,)\n",
    "val_X, train_X = val_X.unstack(), train_X.unstack()\n",
    "val_X = pd.DataFrame(pd.NA, index=train_X.index,\n",
    "                     columns=train_X.columns).fillna(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9c22c",
   "metadata": {},
   "source": [
    "Training data and validation data have the same shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.shape, train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fb41f",
   "metadata": {},
   "source": [
    "... but different number of intensities (non-missing values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.notna().sum().sum(), val_X.notna().sum().sum(),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0b973",
   "metadata": {},
   "source": [
    "Select either `DAE` or `VAE` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a12a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selected = 'VAE'  # 'DAE'\n",
    "model = AETransformer(\n",
    "    model=model_selected,\n",
    "    hidden_layers=[512,],\n",
    "    latent_dim=50,\n",
    "    out_folder='runs/scikit_interface',\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c7922",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, val_X,\n",
    "          epochs_max=50,\n",
    "          cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = model.transform(train_X)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17398941",
   "metadata": {},
   "source": [
    "Evaluate the model using the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a664072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = val_X.stack().to_frame('observed')\n",
    "pred_val[model_selected] = df_imputed.stack()\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = vaep.models.calculte_metrics(pred_val, 'observed')\n",
    "# val_metrics = metrics.add_metrics(\n",
    "#     pred_val, key='test data')\n",
    "# val_metrics = pd.DataFrame(val_metrics)\n",
    "# val_metrics\n",
    "pd.DataFrame(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3013daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "\n",
    "ax, errors_binned = vaep.plotting.errors.plot_errors_by_median(\n",
    "    pred=pred_val,\n",
    "    target_col='observed',\n",
    "    feat_medians=train_X.median(),\n",
    "    ax=ax,\n",
    "    metric_name='MAE',\n",
    "    palette=color_model_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215dba2",
   "metadata": {},
   "source": [
    "replace predicted values with validation data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89799e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df_imputed.replace(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fdb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.stack()  # long-format\n",
    "df_imputed = df_imputed.stack()  # long-format\n",
    "observed = df_imputed.loc[df.index]\n",
    "imputed = df_imputed.loc[df_imputed.index.difference(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ab631",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(8, 4))\n",
    "\n",
    "min_max = vaep.plotting.data.get_min_max_iterable(\n",
    "    [observed, imputed])\n",
    "label_template = '{method} (N={n:,d})'\n",
    "ax, _ = vaep.plotting.data.plot_histogram_intensities(\n",
    "    observed,\n",
    "    ax=axes[0],\n",
    "    min_max=min_max,\n",
    "    label=label_template.format(method='measured',\n",
    "                                n=len(observed),\n",
    "                                ),\n",
    "    color='grey',\n",
    "    alpha=1)\n",
    "_ = ax.legend()\n",
    "ax, _ = vaep.plotting.data.plot_histogram_intensities(\n",
    "    imputed,\n",
    "    ax=axes[1],\n",
    "    min_max=min_max,\n",
    "    label=label_template.format(method=f'{model_selected} imputed',\n",
    "                                n=len(imputed),\n",
    "                                ),\n",
    "    color=color_model_mapping[model_selected],\n",
    "    alpha=1)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235f133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "mystnb": {
   "execution_raise_on_error": true,
   "execution_timeout": 120
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
