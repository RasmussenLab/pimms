{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# MaxQuant (MQ) Output-Files\n",
    "\n",
    "Files compared:\n",
    "1. `Summary.txt`\n",
    "2. `mqpar.xml`\n",
    "3. `peptides.txt`\n",
    "4. `proteins.txt`\n",
    "\n",
    "There is are many files more, where several files seem to be available in several times in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import src\n",
    "import src.file_utils as file_io\n",
    "from src.file_utils import search_files, search_subfolders, check_for_key, PathsList\n",
    "from src.file_utils import process_files\n",
    "from src.file_utils import load_summary, load_mqpar_xml, load_peptide_intensities, load_protein_intensities\n",
    "\n",
    "##################\n",
    "##### CONFIG #####\n",
    "##################\n",
    "from config import FOLDER_RAW_DATA, FOLDER_PROCESSED\n",
    "from config import FOLDER_KEY  # defines how filenames are parsed for use as indices\n",
    "\n",
    "from config import FOLDER_DATA # project folder for storing the data\n",
    "print(f\"Search Raw-Files on path: {FOLDER_RAW_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "folders= search_subfolders(path=FOLDER_RAW_DATA, depth=1, exclude_root=True)\n",
    "folders[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will be saved in a subfolder under `vaep/project/data` using the name of the specified input-folder per default. Change to your liking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = search_files(path=FOLDER_DATA, query='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Go to the block you are interested in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MQ Summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "paths_summaries = PathsList([file for file in all_files.files if 'summary.txt' in file], folder=all_files.folder)\n",
    "w_file = widgets.Dropdown(options=paths_summaries.files, description='View files')\n",
    "w_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### File Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "load_summary??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if paths_summaries.files:\n",
    "    df, names, failed = process_files(handler_fct=load_summary, filepaths=paths_summaries.files, key=FOLDER_KEY, relative_to=paths_summaries.folder)\n",
    "    df.columns = names\n",
    "    print(f\"Number of failed reads: {len(failed)}\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if paths_summaries.files:\n",
    "    df.to_csv(os.path.join(FOLDER_PROCESSED, 'all_summary_txt.csv'))\n",
    "    df.to_pickle(os.path.join(FOLDER_PROCESSED, 'all_summary_txt.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SIL - MS2 based on precursor which was a set of peaks\n",
    "- PEAK - MS2 scan based on a single peak on precursor spectrum\n",
    "- ISO - isotopic pattern detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if paths_summaries.files:\n",
    "    MS_spectra = df.loc[['MS', 'MS/MS Identified']].T.astype('int64')\n",
    "    mask  = MS_spectra['MS/MS Identified'] > 0\n",
    "    display(MS_spectra.loc[mask].describe())\n",
    "    MS_spectra.to_csv(os.path.join(FOLDER_PROCESSED, 'overview_stats.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MaxQuant Parameter File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "paths_parameters = PathsList(files=[file for file in all_files.files if '.xml' in file], folder=all_files.folder)\n",
    "w_file = widgets.Dropdown(options=paths_parameters.files, description='Select a file')\n",
    "w_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Parameter Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "load_mqpar_xml??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fname_mqpar_xml = os.path.join(FOLDER_PROCESSED, 'peptide_intensities.{}')\n",
    "\n",
    "if paths_parameters.files:\n",
    "    df, col_names, failed = process_files(handler_fct=load_mqpar_xml, filepaths=paths_parameters.files, key=FOLDER_KEY, relative_to=paths_parameters.folder) \n",
    "    df.columns = col_names\n",
    "    print(f\"Number of failed reads: {len(failed)}\")\n",
    "    pd.set_option('max_rows', 160)\n",
    "    display(df)\n",
    "    df.to_pickle(fname_mqpar_xml.format(\"pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "paths_peptides = PathsList(files = [file for file in all_files.files if 'peptides.txt' in file], folder=all_files.folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0, len(paths_peptides.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(os.path.join(paths_peptides.folder, \n",
    "                                paths_peptides.files[random.randint(0, len(paths_peptides.files))]),\n",
    "                   index_col='Sequence')\n",
    "pd.set_option('max_columns', 60)\n",
    "# types = dict(df.dtypes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_intensities = load_peptide_intensities(os.path.join(paths_peptides.folder, \n",
    "                                paths_peptides.files[random.randint(0, len(paths_peptides.files))]))\n",
    "s_intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### File-Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "load_peptide_intensities??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Load Peptide Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "FOLDER_PROCESSED = Path(FOLDER_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_intensities_ = [x for x in os.listdir(FOLDER_PROCESSED)  if 'peptide_intensities' in x and 'pkl' in x]\n",
    "i = len(peptide_intensities_)\n",
    "peptide_intensities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fname_files_loaded = FOLDER_PROCESSED / 'peptides_files_processed.pkl'\n",
    "\n",
    "# files_previously_loaded = set()\n",
    "# for fname_dump in peptide_intensities_:\n",
    "#     loaded = pd.read_pickle(FOLDER_PROCESSED / fname_dump)\n",
    "#     files_previously_loaded |= set(loaded.index)\n",
    "#     del loaded\n",
    "\n",
    "# with open(fname_files_loaded, \"wb\") as f:\n",
    "#     pickle.dump(files_previously_loaded, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(fname_files_loaded, \"rb\") as f:\n",
    "        files_previously_loaded = pickle.load(f)\n",
    "    logging.info(f\"Previously processed files: {len(files_previously_loaded)}\")\n",
    "except FileNotFoundError:\n",
    "    logging.info(\"Not files were processed so far.\")\n",
    "    files_previously_loaded = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ToDo: Pull out query-process of previously loaded files. Only load a set of files.\n",
    "def get_intensities(paths_,\n",
    "                    fname_MQ_txt,\n",
    "                    fnames_dumped:set=None):\n",
    "    \"\"\"Take a path namedtuple and check if files have been loaded previously.\n",
    "    \n",
    "    paths_: namedtuple\n",
    "        Custom path object with file paths to consider.\n",
    "    fnames_dumped: set\n",
    "        Set of filenames previously dumped.\n",
    "        \n",
    "    \"\"\"\n",
    "    if fnames_dumped is not None:\n",
    "        logging.info(f\"Previously processed files: {len(fnames_dumped)}\")\n",
    "        set_files_already_processed = {os.path.join(_folder, fname_MQ_txt) for _folder in fnames_dumped}\n",
    "        paths_peptides_to_do = list(set(paths_.files) - set_files_already_processed)\n",
    "    else:\n",
    "        logging.info(f'No previous processed files provided.')\n",
    "        paths_peptides_to_do = paths_peptides.files\n",
    "\n",
    "    #ToDo: add more functionality   names\n",
    "    _peptides, _names, _failed = process_files(handler_fct=load_peptide_intensities,\n",
    "                                        filepaths=paths_peptides_to_do,\n",
    "                                        key=FOLDER_KEY,\n",
    "                                        relative_to=paths_peptides.folder) \n",
    "    if _failed:\n",
    "        logging.info(f'Failed: {\", \".join(_failed)}')\n",
    "        \n",
    "    _peptides.columns = _names\n",
    "    \n",
    "    return _peptides.T\n",
    "    \n",
    "peptides_new = get_intensities(paths_peptides, fname_MQ_txt= 'peptides.txt', fnames_dumped=files_previously_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_peptides = 'peptide_intensities_{i}.{format}'\n",
    "peptides_new.to_pickle(FOLDER_PROCESSED / fname_peptides.format(i=i, format='pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if files_previously_loaded:\n",
    "    logging.info(f\"Add newly loaded files to set of processed files. No. {len(set(peptides_new.index))}\")\n",
    "    files_previously_loaded |= set(peptides_new.index)\n",
    "\n",
    "    with open(fname_files_loaded, \"wb\") as f:\n",
    "        pickle.dump(files_previously_loaded, f)\n",
    "    logging.info(f\"Dumped set of previously loaded files to {fname_files_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_new.to_csv(os.path.join(FOLDER_PROCESSED, f'peptide_intensities_{i}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# print(f\"Peptide intesities take up {peptides.memory_usage(deep=False).sum() / 1000000:7.2f} MB of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# pd.options.display.float_format = '{:,.0f}'.format\n",
    "# peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# peptides.sort_values(by='AAAAAAAAAPAAAATAPTTAATTAATAAQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# peptides_ordered_by_availability = peptides.notna().sum().sort_values(ascending=False)\n",
    "# peptides_ordered_by_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_peptides_notna = (peptides_ordered_by_availability >= max(peptides_ordered_by_availability)).sum()\n",
    "# print(f'A total of {N_peptides_notna} peptides have been identified in {max(peptides_ordered_by_availability)} samples (max identification) out of {len(peptides)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# N_CONSIDER_FIRST = 2000\n",
    "# peptides = peptides[peptides_ordered_by_availability.index]\n",
    "# peptides.sort_values(by=list(peptides_ordered_by_availability.index[:N_CONSIDER_FIRST]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identified Peptides by sample (reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In case no summary.txt is available or for comparison\n",
    "# ms_ms_identified = peptides.notna().sum(axis=1).to_frame(name='MS/MS Identified')\n",
    "# ms_ms_identified.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Peptide sequences\n",
    "- average length, max, min, etc.\n",
    "- overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "peptides.columns.to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Comparison Intensities (e.g. between MaxQuant v1.6.0.1 and v1.6.1.12, if you have it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# peptides_1601  = peptides.loc['MQ1.6.0.1_20190103_QE8_nLC0_LiNi_QC_MNT_15cm_Hela_01_200327']\n",
    "# peptides_16112 =  peptides.loc['MQ1.6.1.12_20190103_QE8_nLC0_LiNi_QC_MNT_15cm_Hela_01_200330']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# mask_diff = peptides_1601 == peptides_16112\n",
    "# mask_diff.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# differences = pd.DataFrame([peptides_1601[~mask_diff], peptides_16112[~mask_diff]])\n",
    "# differences = differences.dropna(axis=1, how='all')\n",
    "# differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Amount of _overall_ assigned intensity is not the same.all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# differences.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "paths_proteins = PathsList([file for file in all_files.files if 'proteinGroups.txt' in file], folder=all_files.folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "run_protein = pd.read_table(os.path.join(paths_proteins.folder, paths_proteins.files[2]))\n",
    "run_protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Most proteins are grouped\n",
    "- How many proteins are grouped together for one intensity value?\n",
    "- Are proteins uniquely placed into one of the protein groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ax = run_protein[\"Number of proteins\"].value_counts().sort_index().plot(kind='bar', title='Counts of protein-groups\\' sizes')\n",
    "ax.set_xlabel('Number of proteins in group (group size)')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "protein_index = run_protein[\"Protein IDs\"].str.split(';').apply(set)\n",
    "protein_index.apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "protein_index.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "protein_index_set = set()\n",
    "for _set in protein_index:\n",
    "    protein_index_set = protein_index_set.union(_set)\n",
    "len(protein_index_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Unique entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Load Protein Intensities\n",
    "- by all proteins\n",
    "- by majority proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dtypes_proteins = run_protein.dtypes.to_dict()\n",
    "dtypes_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "load_protein_intensities??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "proteins, col_names, failed = process_files(handler_fct=load_protein_intensities, filepaths=paths_proteins.files[:20], key=FOLDER_KEY, relative_to=paths_proteins.folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "proteins.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "proteins.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Verify: ~500 proteins have no unique peptides\n",
    "Theoretical analysis has established that roughly ~500 out of the ~20000 human proteins have no unique peptides using trypsin as protease. \n",
    "\n",
    "- ask Marie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Theoretial Peptides from used fasta-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc-autonumbering": true,
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
