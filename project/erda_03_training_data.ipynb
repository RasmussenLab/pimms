{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a set of training data\n",
    "\n",
    "Use a set of (most) common peptides to create inital data sets\n",
    "\n",
    "- based on `Counter` over all outputs from search (here: MaxQuant)\n",
    "   - keep based on threshold `FEAT_COMPLETNESS_CUTOFF` possible features\n",
    "   - option: select samples based on `YEARS` (e.g. due constrain by a batch of strains)\n",
    "   - collect in wide format data from output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import vaep\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def select_files_by_parent_folder(fpaths:List, years:List):\n",
    "    selected = []\n",
    "    for year_folder in years:\n",
    "        # several passes, but not a bottle neck\n",
    "        selected += [dump for dump in fpaths if year_folder in dump.parent.stem]\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "incorrectly_encoded_metadata": "[tag=parameters]",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED: int = 42  # Random seed for reproducibility\n",
    "FEAT_COMPLETNESS_CUTOFF = 0.25 # Minimal proportion of samples which have to share a feature\n",
    "YEARS = ['2017','2018', '2019', '2020']\n",
    "SAMPLE_COL = 'Sample ID'\n",
    "OUT_FOLDER = 'data/selected/'\n",
    "FN_ID_OLD_NEW: str = 'data/rename/selected_old_new_id_mapping.csv' # selected samples with pride and original id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# options = ['peptides', 'evidence', 'proteinGroups']\n",
    "from config.training_data import peptides as cfg\n",
    "# from config.training_data import evidence as cfg\n",
    "# from config.training_data import proteinGroups as cfg\n",
    "\n",
    "cfg_dict = {k: getattr(cfg, k) for k in dir(cfg) if not k.startswith('_')}\n",
    "cfg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set defaults from file (allows to potentially overwrite parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal structure of config.py files\n",
    "NAME = cfg.NAME\n",
    "BASE_NAME = cfg.BASE_NAME\n",
    "\n",
    "TYPES_DUMP = cfg.TYPES_DUMP\n",
    "TYPES_COUNT = cfg.TYPES_COUNT\n",
    "\n",
    "IDX_COLS_LONG = cfg.IDX_COLS_LONG\n",
    "\n",
    "LOAD_DUMP = cfg.LOAD_DUMP\n",
    "\n",
    "CounterClass = cfg.CounterClass\n",
    "FNAME_COUNTER = cfg.FNAME_COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "out_folder = Path(OUT_FOLDER) / cfg.NAME\n",
    "out_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected IDs\n",
    "\n",
    "- currently only `Sample ID` is used\n",
    "- path are to `.raw` raw files, not the output folder (could be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = pd.read_csv(FN_ID_OLD_NEW)\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CounterClass(FNAME_COUNTER)\n",
    "counts = counter.get_df_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPES_COUNT:\n",
    "    counts = counts.convert_dtypes().astype({'Charge': int}) #\n",
    "mask = counts['proportion'] >= FEAT_COMPLETNESS_CUTOFF\n",
    "counts.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on selected samples, retain features that potentially could be in the subset\n",
    "\n",
    "- if 1000 samples are selected, and given at treshold of 25%, one would need at least 250 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold_counts = int(len(df_ids) * FEAT_COMPLETNESS_CUTOFF)\n",
    "mask = counts['counts'] >= treshold_counts\n",
    "counts.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_selected = counts.loc[mask].set_index('Sequence').index\n",
    "IDX_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dumps = df_ids[\"Sample ID\"]\n",
    "selected_dumps = {k: counter.dumps[k] for k in selected_dumps}\n",
    "selected_dumps = list(selected_dumps.items())\n",
    "selected_dumps[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potentially select meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_dumps = select_files_by_parent_folder(list(counter.dumps.values()), years=YEARS)\n",
    "# print(\"Total number of files:\", len(selected_dumps))\n",
    "# selected_dumps[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_fct(path):\n",
    "#     s = (\n",
    "#     pd.read_csv(path, index_col=\"Sequence\", usecols=[\"Sequence\", \"Intensity\"])\n",
    "#     .notna()\n",
    "#     .squeeze()\n",
    "#     .astype(pd.Int8Dtype())\n",
    "#     )\n",
    "#     return s\n",
    "\n",
    "\n",
    "def collect(folders, index, load_fct):\n",
    "    current = multiprocessing.current_process()\n",
    "    i = current._identity[0] % N_WORKERS + 1\n",
    "    print(\" \", end=\"\", flush=True)\n",
    "\n",
    "    failed = []\n",
    "    all = pd.DataFrame(index=index)\n",
    "\n",
    "    with tqdm_notebook(total=len(folders), position=i) as pbar:\n",
    "        for id, path in folders:\n",
    "            try:\n",
    "                s = load_fct(path)\n",
    "                s.name = id\n",
    "                all = all.join(s, how='left')\n",
    "            except FileNotFoundError:\n",
    "                logging.warning(f\"File not found: {path}\")\n",
    "                failed.append((id, path))\n",
    "            except pd.errors.EmptyDataError:\n",
    "                logging.warning(f\"Empty file: {path}\")\n",
    "                failed.append((id, path))\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect intensities in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fct(path):\n",
    "    s = (\n",
    "    pd.read_csv(path, index_col=\"Sequence\", usecols=[\"Sequence\", \"Intensity\"])\n",
    "    .squeeze()\n",
    "    .astype(pd.Int64Dtype())\n",
    "    )\n",
    "    return s\n",
    "\n",
    "all = None # free memory\n",
    "\n",
    "collect_intensities = partial(collect, index=IDX_selected, load_fct=load_fct)\n",
    "\n",
    "N_WORKERS = 8\n",
    "\n",
    "with multiprocessing.Pool(N_WORKERS) as p:\n",
    "    all = list(\n",
    "        tqdm_notebook(\n",
    "            p.imap(collect_intensities,\n",
    "                   np.array_split(selected_dumps, N_WORKERS)),\n",
    "                   total=N_WORKERS,\n",
    "        )\n",
    "    )  \n",
    "    \n",
    "all = pd.concat(all, axis=1)\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all.memory_usage(deep=True).sum() / (2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fname = out_folder / config.insert_shape(all,  'intensities_wide_selected{}.pkl') \n",
    "all.to_pickle(fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all.to_csv(fname.with_suffix('.csv'), chunksize=1_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples as rows, feature columns as columns\n",
    "\n",
    "- can fail due to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all = all.T # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# fname = out_folder / config.insert_shape(all,  template='intensities_wide_selected{}.pkl', shape=(N, M)) \n",
    "# all.to_pickle(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
