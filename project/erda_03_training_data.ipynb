{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a set of training data\n",
    "\n",
    "Use a set of (most) common peptides to create inital data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import random  # shuffle, seed\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from vaep.io import data_objects\n",
    "\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def select_files_by_parent_folder(fpaths:List, years:List):\n",
    "    selected = []\n",
    "    for year_folder in years:\n",
    "        # several passes, but not a bottle neck\n",
    "        selected += [dump for dump in fpaths if year_folder in dump.parent.stem]\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED: int = 42  # Random seed for reproducibility\n",
    "\n",
    "FEAT_COMPLETNESS_CUTOFF = 0.25 # Minimal proportion of samples which have to share a feature\n",
    "\n",
    "YEARS = ['2017','2018', '2019', '2020']\n",
    "\n",
    "SAMPLE_COL = 'Sample ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['peptides', 'evidence', 'proteinGroups']\n",
    "from config.training_data import peptides as cfg\n",
    "# from config.training_data import evidence as cfg\n",
    "# from config.training_data import proteinGroups as cfg\n",
    "\n",
    "{k: getattr(cfg, k) for k in dir(cfg) if not k.startswith('_')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set defaults from file (allows to potentially overwrite parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal structure of config.py files\n",
    "NAME = cfg.NAME\n",
    "BASE_NAME = cfg.BASE_NAME\n",
    "\n",
    "TYPES_DUMP = cfg.TYPES_DUMP\n",
    "TYPES_COUNT = cfg.TYPES_COUNT\n",
    "\n",
    "IDX_COLS_LONG = cfg.IDX_COLS_LONG\n",
    "\n",
    "LOAD_DUMP = cfg.LOAD_DUMP\n",
    "\n",
    "CounterClass = cfg.CounterClass\n",
    "FNAME_COUNTER = cfg.FNAME_COUNTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CounterClass(FNAME_COUNTER)\n",
    "counts = counter.get_df_counts()\n",
    "\n",
    "if TYPES_COUNT:\n",
    "    counts = counts.convert_dtypes().astype({'Charge': int}) #\n",
    "mask = counts['proportion'] >= FEAT_COMPLETNESS_CUTOFF\n",
    "counts.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Features\n",
    "\n",
    "- index names should also match!\n",
    "- if not-> rather use a list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = counts.loc[mask].set_index(counter.idx_names).sort_index().index\n",
    "# selected_features.name = 'Gene names' # needs to be fixed\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dumps = select_files_by_parent_folder(list(counter.dumps.values()), years=YEARS)\n",
    "print(\"Total number of files:\", len(selected_dumps))\n",
    "selected_dumps[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load one dump\n",
    "\n",
    "- check that this looks like you expect it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_DUMP(selected_dumps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process folders\n",
    "\n",
    "- potentially in parallel, aggregating results\n",
    "- if needed: debug using two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from pandas.errors import EmptyDataError\n",
    "def process_folders(fpaths: List[Path],\n",
    "                    selected_features: pd.Index,\n",
    "                    load_folder: Callable,\n",
    "                    id_col='Sample ID',\n",
    "                    dtypes: dict = {\n",
    "                        'Sample ID': 'category',\n",
    "                        'Sequence': 'category'}) -> tuple:\n",
    "    print(f\"started new process with {len(fpaths)} files.\")\n",
    "    data_intensity = []\n",
    "    for i, fpath in enumerate(fpaths):\n",
    "        if not i % 10: print(f\"File ({i}): {fpath}\")\n",
    "        sample_name = fpath.stem\n",
    "        try:\n",
    "            dump = load_folder(fpath)\n",
    "        except EmptyDataError:\n",
    "            logging.warning(f'Empty dump: {fpath}')\n",
    "            continue\n",
    "        except FileNotFoundError:\n",
    "            logging.warning(f'Missing dump: {fpath}')\n",
    "            continue\n",
    "        sequences_available = dump.index.intersection(selected_features)\n",
    "        dump = dump.loc[sequences_available, 'Intensity'].reset_index()\n",
    "        dump[id_col] = sample_name\n",
    "        dump = dump.astype(dtypes)\n",
    "        data_intensity.append(dump)\n",
    "    \n",
    "    data_intensity = pd.concat(data_intensity, copy=False, ignore_index=True)\n",
    "    data_intensity = data_intensity.astype(dtypes)\n",
    "    return data_intensity\n",
    "\n",
    "# # experiment\n",
    "# process_folders(selected_dumps[:2],\n",
    "#                 selected_features=selected_features,\n",
    "#                 load_folder=LOAD_DUMP,\n",
    "#                 dtypes=TYPES_DUMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "process_folders_peptides = functools.partial(process_folders,\n",
    "                                             selected_features=selected_features,\n",
    "                                             load_folder=LOAD_DUMP,\n",
    "                                             dtypes=TYPES_DUMP)\n",
    "collected_dfs = data_objects.collect_in_chuncks(paths=selected_dumps,\n",
    "                                                process_chunk_fct=process_folders_peptides,\n",
    "                                                chunks=200,\n",
    "                                                n_workers=1 # to debug, don't multiprocess\n",
    "                                               )\n",
    "\n",
    "# one would need to aggregate categories first to keep them during aggregation?\n",
    "collected_dfs = pd.concat(collected_dfs, copy=False, ignore_index=True)\n",
    "collected_dfs = collected_dfs.astype(TYPES_DUMP)\n",
    "df_intensities = collected_dfs\n",
    "df_intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except Intensities everything should be of data type category in order to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check how many samples could be loaded, set total number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df_intensities[SAMPLE_COL].nunique()\n",
    "M = len(selected_features)\n",
    "N,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities = df_intensities.set_index(IDX_COLS_LONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = f'{BASE_NAME}_' + '_'.join(YEARS)\n",
    "fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.pkl', shape=(N,M))\n",
    "print(f\"{fname = }\")\n",
    "df_intensities.to_pickle(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only binary pickle format works for now\n",
    "- csv and reshaping the data needs to much memory for a single erda instance with many samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_intensities = df_intensities.unstack(['Sample ID'])\n",
    "# df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_intensities.sort_index(inplace=True)\n",
    "# base_name = \"df_intensities_evidence_long\" + '_'.join(YEARS)\n",
    "# fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.csv', shape=(N,M))\n",
    "# print(f\"{fname = }\")\n",
    "# df_intensities.to_csv(fname)\n",
    "# df_intensities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
