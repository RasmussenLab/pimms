{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse peptides\n",
    "\n",
    "## Specification\n",
    "- access different levels of peptides easily\n",
    "- select training data per gene easily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO) # configures root logger\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import FN_FASTA_DB, FN_ID_MAP, FN_PEPTIDE_INTENSITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = pd.read_json(FN_ID_MAP, orient=\"split\")\n",
    "\n",
    "mask_no_gene = id_map.gene.isna()\n",
    "id_map.loc[mask_no_gene, \"gene\"] = \"-\"\n",
    "\n",
    "\n",
    "with open(FN_FASTA_DB) as f:\n",
    "    data_fasta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides = pd.read_pickle(FN_PEPTIDE_INTENSITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_peptides = set(data_peptides.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- switch between list of proteins with any support and non\n",
    "    - set threshold of number of peptides per protein over all samples (some peptides uniquely matched to one protein in on sample is just noise -> check razor peptides)\n",
    "- show support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ipywidgets as w\n",
    "from config import KEY_FASTA_HEADER, KEY_FASTA_SEQ, KEY_PEPTIDES, KEY_GENE_NAME, KEY_GENE_NAME_FASTA\n",
    "\n",
    "TGREEN = \"\\033[32m\"  # Green Text\n",
    "RESET = \"\\033[0;0m\"\n",
    "\n",
    "w_first_letter = w.Dropdown(\n",
    "    options=id_map[KEY_GENE_NAME_FASTA].str[0].unique())\n",
    "w_genes = w.Dropdown(\n",
    "    options=id_map.gene.loc[id_map[KEY_GENE_NAME_FASTA].str[0] == w_first_letter.value].unique(),\n",
    "    value='ACTB'\n",
    ")\n",
    "\n",
    "mask = id_map.gene == w_genes.value\n",
    "selected = id_map.loc[mask, \"protein\"]\n",
    "\n",
    "\n",
    "w_proteins_ids = w.Dropdown(options=selected.index)\n",
    "w_protein = w.Dropdown(options=selected.unique())\n",
    "\n",
    "\n",
    "def update_gene_list(first_letter):\n",
    "    \"\"\"Update proteins when new gene is selected\"\"\"\n",
    "    mask_selected_genes = id_map[KEY_GENE_NAME_FASTA].str[0] == w_first_letter.value\n",
    "    w_genes.options = id_map.gene.loc[mask_selected_genes].unique()\n",
    "\n",
    "\n",
    "_ = w.interactive_output(update_gene_list, {\"first_letter\": w_first_letter})\n",
    "\n",
    "\n",
    "def update_protein_list(gene):\n",
    "    mask = id_map[KEY_GENE_NAME_FASTA] == gene\n",
    "    selected = id_map.loc[mask, \"protein\"]\n",
    "    w_protein.options = selected.unique()\n",
    "#     w_proteins_ids.options = selected.loc[selected == w_protein.value].index\n",
    "\n",
    "\n",
    "_ = w.interactive_output(update_protein_list, {\"gene\": w_genes})\n",
    "    \n",
    "\n",
    "def update_protein_id_list(protein):\n",
    "    \"\"\"Update isotope list when protein is selected\"\"\"\n",
    "    mask = id_map.protein == w_protein.value\n",
    "    selected = id_map.protein.loc[mask]\n",
    "    w_proteins_ids.options = selected.index\n",
    "\n",
    "_ = w.interactive_output(update_protein_id_list, {'protein': w_protein})\n",
    "\n",
    "d_peptides_observed_prot_id = defaultdict(list)\n",
    "\n",
    "def show_sequences(prot_id):\n",
    "    _data = data_fasta[prot_id]\n",
    "    print(f\"Protein_ID on Uniport: {prot_id}\")\n",
    "    print(f\"HEADER: {_data[KEY_FASTA_HEADER]}\")\n",
    "#     print(f\"Seq  : {_data[KEY_FASTA_SEQ]}\")\n",
    "    annotate_seq = \"Peptides: \"\n",
    "    global d_peptides_observed_prot_id\n",
    "    for i, _l in enumerate(_data[KEY_PEPTIDES]):\n",
    "        annotate_seq += f\"\\nNo. of missed K or R: {i}\"\n",
    "        prot_seq_annotated = _data[KEY_FASTA_SEQ]\n",
    "        for j, _pep in enumerate(_l):\n",
    "            if _pep in set_peptides:\n",
    "                d_peptides_observed_prot_id[prot_id].append(_pep)\n",
    "                _pep_in_green = TGREEN + f\"{_pep}\" + RESET\n",
    "                prot_seq_annotated = prot_seq_annotated.replace(_pep, _pep_in_green)\n",
    "                _pep = _pep_in_green\n",
    "            if j==0:\n",
    "                annotate_seq += \"\\n\\t\" + _pep\n",
    "            else:\n",
    "                annotate_seq += \",\\n\\t\" + _pep\n",
    "        print(f\"Seq {i}: {prot_seq_annotated}\")\n",
    "    print(annotate_seq)\n",
    "    \n",
    "    \n",
    "    display(data_peptides[d_peptides_observed_prot_id[prot_id]].dropna(how='all'))\n",
    "\n",
    "w_out = w.interactive_output(show_sequences, {\"prot_id\": w_proteins_ids})\n",
    "\n",
    "label_first_letter = w.Label(value='First letter of Gene')\n",
    "label_genes = w.Label('Gene')\n",
    "label_protein = w.Label('Protein')\n",
    "label_proteins_ids = w.Label('Protein Isotopes')\n",
    "\n",
    "panel_levels = w.VBox([\n",
    "         w.HBox([\n",
    "            w.VBox([label_first_letter, w_first_letter]),\n",
    "            w.VBox([label_genes, w_genes]),\n",
    "            w.VBox([label_protein, w_protein]),\n",
    "            w.VBox([label_proteins_ids, w_proteins_ids])\n",
    "            ]),\n",
    "         w_out]\n",
    ")\n",
    "panel_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- relatively short peptides resulting from one missed cleaveage, do not appear in the upper part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `gene` `->` `Protein_ID` (contains information of `gene` `->` `protein_isotopes`\n",
    "- `protein_ID` `->` `sequences` (`FN_FASTA_DB`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from config import FN_PROTEIN_SUPPORT_MAP, FN_PROTEIN_SUPPORT_FREQ\n",
    "try:\n",
    "    df_protein_support = pd.read_pickle(FN_PROTEIN_SUPPORT_MAP)\n",
    "    with open(FN_PROTEIN_SUPPORT_FREQ, 'rb') as f:\n",
    "        d_protein_support_freq = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    from vaep.utils import sample_iterable\n",
    "    d_protein_support = {}\n",
    "    d_protein_support_freq = {}\n",
    "    for prot_id in tqdm(data_fasta.keys()):\n",
    "        _data = data_fasta[prot_id]\n",
    "        peptides_measured = []\n",
    "        for i, _l in enumerate(_data[KEY_PEPTIDES]):\n",
    "            for _pep in _l:\n",
    "                if _pep in set_peptides:\n",
    "                    peptides_measured.append(_pep)\n",
    "        _d_protein_support = {}\n",
    "        _df_support_protein = data_peptides[peptides_measured].dropna(how='all')\n",
    "\n",
    "        _n_samples = len(_df_support_protein)\n",
    "        if _n_samples > 0:\n",
    "            _d_protein_support['N_samples'] = _n_samples\n",
    "            d_protein_support_freq[prot_id] = _df_support_protein.notna().sum().to_dict()\n",
    "            d_protein_support[prot_id] = _d_protein_support\n",
    "        else:\n",
    "            d_protein_support[prot_id] = None\n",
    "        \n",
    "    df_protein_support = pd.DataFrame(d_protein_support).T.dropna()\n",
    "    df_protein_support = df_protein_support.join(id_map)\n",
    "    df_protein_support.to_pickle(FN_PROTEIN_SUPPORT_MAP)\n",
    "    \n",
    "    with open(FN_PROTEIN_SUPPORT_FREQ, 'wb') as f:\n",
    "        pickle.dump(d_protein_support_freq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_proteins_good_support = df_protein_support.sort_values(by='N_samples').tail(100).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_protein_support_freq['I3L3I0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to experimental peptide data\n",
    "\n",
    "Check if counts by `data_fasta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "counts_observed_by_missed_cleavages = {}\n",
    "for _protein_id, _data in tqdm(data_fasta.items()):\n",
    "    _peptides = _data[KEY_PEPTIDES]\n",
    "    _counts = {}\n",
    "    for i, _l in enumerate(_peptides):\n",
    "        _counts[i] = 0\n",
    "        for _pep in _l:\n",
    "            if _pep in set_peptides:\n",
    "                _counts[i] += 1\n",
    "    counts_observed_by_missed_cleavages[_protein_id] = _counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_observed_by_missed_cleavages = pd.DataFrame(\n",
    "    counts_observed_by_missed_cleavages\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import table\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, gridspec_kw={\"width_ratios\": [5, 1], \"wspace\": 0.2}, figsize=(10,4))\n",
    "\n",
    "_counts_summed = df_counts_observed_by_missed_cleavages.sum()\n",
    "_counts_summed.name = \"frequency\"\n",
    "\n",
    "ax = axes[0]\n",
    "_ = _counts_summed.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_xlabel(\"peptides from n miscleavages\")\n",
    "ax.set_ylabel(\"frequency\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(\"off\")\n",
    "_ = pd.plotting.table(ax=ax, data=_counts_summed, loc=\"best\", colWidths=[1], edges='open')\n",
    "_ = fig.suptitle('Peptides frequencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are unnormalized counts in the meaning of that _razor_ peptides are counted as often as they are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_counts_observed_by_missed_cleavages != 0\n",
    "df_prot_observed = df_counts_observed_by_missed_cleavages.replace(0, pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prot_observed = df_prot_observed.dropna(axis=0, how=\"all\")\n",
    "df_prot_observed = df_prot_observed.fillna(0)\n",
    "df_prot_observed = df_prot_observed.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.pandas import combine_value_counts\n",
    "\n",
    "combine_value_counts(df_prot_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pep_mapped_to_protID = df_prot_observed.sum(axis=1).value_counts()\n",
    "freq_pep_mapped_to_protID = freq_pep_mapped_to_protID.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pep_mapped_to_protID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes with support in data\n",
    "\n",
    "try software to identify the _most likely_ protein. OpenMS or russian alternative?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation: Train model\n",
    "\n",
    "> Select Gene or Protein\n",
    "\n",
    "As the samples are all obtained from the same biological sample (in principal), the single run should somehow be comparable.\n",
    "An description of variablity (from the Data Scientist perspective) can highlight some commenly known facts about proteomics experiments:\n",
    " - batch effects: Measurements on consecutive days are have to be normalized to each other\n",
    " - scoring: PSM are assigned to a peptide based on a score. Small variations can lead to different assignments\n",
    " \n",
    "Can a complex representation of a sample level out experimental variation on an in principle comparable data. \n",
    "\n",
    "### Strategy\n",
    "- first start using peptides from single Protein_IDs\n",
    "- then move to all models from genes\n",
    "- explore structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_peptides_observed_prot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_select_proteins_good_support = w.Dropdown(options=l_proteins_good_support)\n",
    "w_select_proteins_queried = w.Dropdown(options=list(d_peptides_observed_prot_id.keys()))\n",
    "w.HBox(\n",
    "    [\n",
    "        w.VBox(\n",
    "            [\n",
    "                w.Label(f\"Top {len(l_proteins_good_support)} covered proteins\"),\n",
    "                w_select_proteins_good_support,\n",
    "            ]\n",
    "        ),\n",
    "        w.VBox([w.Label(\"Queried proteins from above\"), w_select_proteins_queried]),\n",
    "    ]\n",
    ")\n",
    "# select from top100 or above selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_id = w_select_proteins_good_support.value\n",
    "id_map.loc[prot_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_id = 'P00338' # 'I3L3I0' # w_select_proteins_queried.value # \n",
    "_protein, _gene, _ = id_map.loc[prot_id]\n",
    "# _gene_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_first_letter.value = _gene[0]\n",
    "w_genes.value = _gene\n",
    "w_protein.value = _protein\n",
    "w_proteins_ids.value = prot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_measured = d_peptides_observed_prot_id[prot_id]\n",
    "n_peptides_in_selection = len(peptides_measured)\n",
    "print(f\"Selected a total of {n_peptides_in_selection} peptides.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides[peptides_measured].notna().sum(axis=1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_DATA_COMPLETENESS = 0.75\n",
    "mask_samples_selected = data_peptides[peptides_measured].notna().sum(axis=1) >= int(n_peptides_in_selection * 0.75)\n",
    "print(f\"Using a share of at least {PROP_DATA_COMPLETENESS}, i.e. at least {int(n_peptides_in_selection * 0.75)} out of {n_peptides_in_selection}.\",\n",
    "     f\"In total {mask_samples_selected.sum()} samples.\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides.loc[mask_samples_selected, peptides_measured]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaep\n",
    "from vaep.transform import log\n",
    "\n",
    "peptides_selected_log10 = data_peptides.loc[mask_samples_selected, peptides_measured].apply(log) # selected in widget overview above\n",
    "peptides_selected_log10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The data to be seen here should be **assigned** peptides. Razor peptides are for now not put to one or the other protein (focus only on unique peptides?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = peptides_selected_log10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.cmd import parser\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 600\n",
    "args = ['--batch-size', str(BATCH_SIZE), '--seed', '43', '--epochs', str(EPOCHS), '--log-interval', str(BATCH_SIZE)]\n",
    "args = parser.parse_args(args)\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n",
    "\n",
    "The `torch.utils.data.Dataset` can load data into memory, or just create a mapping to data somewhere to be continously loaded by the `torch.utils.data.DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_intensities = peptides_selected_log10\n",
    "detection_limit = float(int(peptide_intensities.min().min()))\n",
    "detection_limit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vaep.model import PeptideDatasetInMemory\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class PeptideDatasetInMemory(Dataset):\n",
    "    \"\"\"Peptide Dataset fully in memory.\"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, fill_na=0):\n",
    "        self.mask_obs = torch.from_numpy(data.notna().values)\n",
    "        data = data.fillna(fill_na)\n",
    "        self.peptides = torch.from_numpy(data.values)\n",
    "        self.length_ = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.peptides[idx], self.mask_obs[idx]\n",
    "\n",
    "\n",
    "dataset_in_memory = PeptideDatasetInMemory(peptide_intensities.copy(), detection_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_in_memory,\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, mask) in enumerate(train_loader):\n",
    "    print(\"Nummber of samples in mini-batch: {}\".format(len(data)),\n",
    "          \"\\tObject-Type: {}\".format(type(mask)))\n",
    "    print(data)\n",
    "    print(mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~mask] = 0\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create logged information for tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(f'runs/{format(datetime.now(), \"%y%m%d_%H%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image('16 samples heatmap', data, dataformats='HW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; importlib.reload(vaep.model)\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from torch import optim\n",
    "from vaep.model import train\n",
    "from vaep.model import VAE\n",
    "from vaep.model import loss_function\n",
    "\n",
    "model = VAE(n_features=n_features, n_neurons=30).to(device)\n",
    "model.double()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "writer.add_graph(model, data)\n",
    "\n",
    "def train(epoch, model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n_samples = len(train_loader.dataset)\n",
    "    for batch_idx, (data, mask) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mask, mu, logvar)\n",
    "        logger.debug(\"Epoch: {epoch:3}, Batch: {batch_idx:4}\")\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "#         # print(batch_idx)\n",
    "#         # if batch_idx % args.log_interval == 0:\n",
    "#         #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#         #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#         #         100. * batch_idx / len(train_loader),\n",
    "#         #         loss.item() / len(data\n",
    "    avg_loss_per_sample =  train_loss / n_samples\n",
    "    logger.info('====> Epoch: {epoch:3} Average loss: {avg_loss:10.4f}'.format(epoch=epoch, avg_loss=avg_loss_per_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, args.epochs):\n",
    "    train(epoch, model=model, train_loader=train_loader, optimizer=optimizer, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
