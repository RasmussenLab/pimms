{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3167ddaa-c624-4561-807d-9a42b389bee5",
   "metadata": {},
   "source": [
    "# `DataLoaders` for feeding data into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bd6b7-44b4-4697-be7f-b1d9333b6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fastai\n",
    "from fastai.tabular.core import Normalize\n",
    "from fastai.tabular.core import FillMissing\n",
    "from fastai.tabular.core import TabularPandas\n",
    "from fastai.tabular.core import IndexSplitter\n",
    "# make DataLoaders.test_dl work for DataFrames as test_items:\n",
    "from fastai.tabular.all import TabularDataLoaders\n",
    "\n",
    "from fastcore.transform import Pipeline\n",
    "\n",
    "from src.setup_logging import *\n",
    "\n",
    "from vaep.io.datasplits import DataSplits\n",
    "from vaep.models import ae\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"fastai version: {fastai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd936e88-b04a-4441-9644-4d52e559dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.transform import Pipeline\n",
    "\n",
    "from fastcore.basics import store_attr\n",
    "class FillMissingKeepAll(FillMissing):\n",
    "    \"\"\"Replacement for `FillMissing` including also non-missing features\n",
    "    in the training data which might be missing in the validation or test data.\n",
    "    \"\"\"\n",
    "    def setups(self, to):\n",
    "        store_attr(but='to', na_dict={n:self.fill_strategy(to[n], self.fill_vals[n])\n",
    "                            for n in to.conts.keys()})\n",
    "        self.fill_strategy = self.fill_strategy.__name__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b242d3-09ba-4ac2-8036-622409b53eaa",
   "metadata": {},
   "source": [
    "Create data\n",
    "\n",
    "- train data without missings\n",
    "- validation and test data with missings\n",
    "\n",
    "Could be adapted to have more or less missing in training, validation or test data. Choosen as in current version the validation data cannot contain features with missing values which were not missing in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304e7f6-8752-420d-a1f5-dec282aa6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = 150, 15\n",
    "\n",
    "def create_df(N:int, M:int, scaling_factor:float=30.0, prop_na:float=0.0, start_idx:int=0):   \n",
    "    X = np.random.rand(N, M)\n",
    "\n",
    "    if prop_na>0.0 and prop_na<1.0:\n",
    "        mask = ~(X < prop_na)\n",
    "        X = np.where(mask, X, np.nan)\n",
    "    \n",
    "    X *= scaling_factor\n",
    "    \n",
    "    X = pd.DataFrame(X,\n",
    "                  index=[f'sample_{i:0{len(str(N))}}' for i in range(start_idx, start_idx+N)],\n",
    "                  columns=(f'feat_{i:0{len(str(M))}}' for i in range(M)))\n",
    "    return X\n",
    "\n",
    "X = create_df(N, M)\n",
    "X = X.append(create_df(int(N*0.3), M, prop_na=.1, start_idx=len(X)))\n",
    "\n",
    "idx_val = X.index[N:] # RandomSplitter could be used, but used to show IndexSplitter usage with Tabular\n",
    "\n",
    "X_test = create_df(int(N*0.1), M, prop_na=.1, start_idx=len(X))\n",
    "\n",
    "# data = DataSplits.from_folder(folder='data/msinstrument_in_QE4', use_wide_format=True)\n",
    "data = DataSplits(train_X=X.loc[X.index.difference(idx_val)],\n",
    "                  val_X=X.loc[idx_val],\n",
    "                  test_X=X_test)\n",
    "\n",
    "data.val_X.loc[data.val_X.isna().any(axis=1), data.val_X.isna().any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ea1e3-22b6-4720-8ced-b1295220c97e",
   "metadata": {},
   "source": [
    "## Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de36c59-1201-4f71-a476-0ca9f88762a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5aab60-049b-45a7-860e-1a572c014556",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81f67a-c918-43f5-b0d1-5423d289f625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df4b18a8-30ee-4892-8c17-f14ac4ff464c",
   "metadata": {},
   "source": [
    "### DataSet `Tabular`\n",
    "\n",
    "- `fastai.tabular.core.Tabular`\n",
    "\n",
    "\n",
    "Adding procs / transforms manually\n",
    "\n",
    "```python\n",
    "cont_names = list(splits.train_X.columns)\n",
    "to = TabularPandas(splits.train_X, cont_names=cont_names, do_setup=False)\n",
    "\n",
    "tf_norm = NORMALIZER()\n",
    "tf_fillna = FillMissing(add_col=True)\n",
    "\n",
    "_ = tf_norm.setups(to)  # returns to\n",
    "_ = tf_fillna.setup(to)\n",
    "```\n",
    "\n",
    "No added in a manuel pipeline. See [opened issue](https://github.com/fastai/fastai/issues/3530) on `Tabular` behaviour.\n",
    "Setting transformation (procs) in the constructor is somehow not persistent, although very similar code is called.\n",
    "\n",
    "```\n",
    "# not entirely empty, but to.procs.fs needs to be populated\n",
    "type(to.procs), to.procs.fs # __call__, setup, decode, fs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c737514-f79a-4c7b-be1c-ec4c21d556b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c899b9a-66a1-47ce-94ee-17090b74bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.train_X.append(data.val_X)\n",
    "\n",
    "splits = X.index.get_indexer(data.val_X.index) # In Tabular iloc is used, not loc for splitting\n",
    "splits = IndexSplitter(splits)(X) # splits is are to list of integer indicies (for iloc)\n",
    "        \n",
    "procs = [Normalize, FillMissingKeepAll]\n",
    "\n",
    "to = TabularPandas(X, procs=procs, cont_names=X.columns.to_list(), splits=splits) # to = tabular object\n",
    "\n",
    "print(\"Tabular object:\", type(to))\n",
    "to.items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ebf88-e7fc-4517-8c33-30c8ee591a19",
   "metadata": {},
   "source": [
    "Test data with procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88bf3d-b535-4d23-9c8b-757fbf0e445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = to.procs\n",
    "procs.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd181c-ec64-44dd-bdca-db306846b1d6",
   "metadata": {},
   "source": [
    "Let's format this to see what it does\n",
    "\n",
    "```python\n",
    "# (#2)\n",
    "[\n",
    "FillMissingKeepAll -- \n",
    "{'fill_strategy': <function FillStrategy.median at 0x0000023845497E50>, \n",
    " 'add_col': True, \n",
    " 'fill_vals': defaultdict(<class 'int'>,  {'feat_00': 0, 'feat_01': 0, 'feat_02': 0, ..., 'feat_14': 13.972452}\n",
    "}:\n",
    "    encodes: (object,object) -> encodes\n",
    "    decodes: ,\n",
    "Normalize -- \n",
    "{'mean': None, 'std': None, 'axes': (0, 2, 3),\n",
    " 'means': {'feat_00': 14.982738, 'feat_01': 13.158741, 'feat_02': 14.800485, ..., 'feat_14': 8.372757}\n",
    "}:\n",
    "    encodes: (TensorImage,object) -> encodes\n",
    "             (Tabular,object) -> encodes\n",
    "    decodes: (TensorImage,object) -> decodes\n",
    "             (Tabular,object) -> decodes\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c13606-7ada-42f3-853e-e42a3c0555f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0d239-7761-43e4-aa14-10a4abad34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check behaviour\n",
    "procs.encodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a884155-eae8-4019-ae1b-57019c630961",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebc15d-92f2-4d34-be08-06601b2d5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=4)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71b82a-0036-479d-a970-990ff62bdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04f447-3927-4994-8c96-170a50aac1f8",
   "metadata": {},
   "source": [
    "#### transfrom test data using `DataLoaders.test_dl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f2de5-dcf7-4ec9-9fc6-7a5f08f166e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = TabularPandas(data.test_X, cont_names=data.test_X.columns.to_list())\n",
    "dl_test = dls.test_dl(data.test_X.copy())\n",
    "dl_test.xs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef888c00-61f0-423d-9630-68d0a5533675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec83746-12c1-489b-abac-01d1b184b555",
   "metadata": {},
   "source": [
    "#### Transform test data manuelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e122d-19dc-41c3-a480-8f3e8af18cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = TabularPandas(data.test_X.copy(), procs=None, cont_names=data.test_X.columns.to_list(), splits=None, do_setup=True)\n",
    "_ = procs(to_test) # inplace operation\n",
    "to_test.items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32b81a-93d7-4df2-881c-a000e64c9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aca60-0e37-4550-9755-61a28417802f",
   "metadata": {},
   "source": [
    "#### Feeding one batch to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024613e-098f-4d39-95b2-95426a611a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats, conts, ys =  dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01a34c-011d-416f-8559-17c13f3dc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.Autoencoder(n_features=M, n_neurons=int(\n",
    "    M/2), last_decoder_activation=None, dim_latent=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d13382-ea45-40c8-998e-172e63ee545d",
   "metadata": {},
   "source": [
    "The forward pass just uses the conts features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0d79e-6558-4202-aa39-1b901d844287",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(conts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de7d6b-ba79-4390-8616-072316027a72",
   "metadata": {},
   "source": [
    "#### target\n",
    "- missing puzzle piece is to have a `callable` y-block which transforms part of the input. In principle it could be the same as the continous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62851019-2731-4982-840b-d3b3795b7f82",
   "metadata": {},
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39df418-2a90-470c-b45b-f83310f10557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def to_tensor(s: pd.Series) -> torch.Tensor:\n",
    "    return torch.from_numpy(s.values)\n",
    "\n",
    "\n",
    "class DatasetWithMaskAndNoTarget(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        if not issubclass(type(df), pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f'please pass a pandas DataFrame, not: {type(df) = }')\n",
    "        self.mask_obs = df.isna()  # .astype('uint8') # in case 0,1 is preferred\n",
    "        self.data = df\n",
    "        self.length_ = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_\n",
    "\n",
    "    def __getitem__(self, idx) -> (torch.Tensor, torch.Tensor):\n",
    "        mask = self.mask_obs.iloc[idx]\n",
    "        data = self.data.iloc[idx]\n",
    "        return to_tensor(mask), to_tensor(data)\n",
    "\n",
    "\n",
    "train_ds = DatasetWithMaskAndNoTarget(df=data.train_X)\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=data.val_X)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdb287-5efa-4b7a-bdc9-285c129e8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "with pytest.raises(ValueError):\n",
    "    DatasetWithMaskAndNoTarget(df=np.random.rand(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564fcf4-5f22-4517-a447-bd9fb4a99811",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dcc4b-75f5-4b4a-99dd-bf3163f6383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds,\n",
    "                             bs=4)\n",
    "\n",
    "dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f2d7e-aadf-49de-a065-c66c8e69009b",
   "metadata": {},
   "source": [
    "#### DataLoaders with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ec37-9968-4175-8e44-691769d2847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import * \n",
    "class Normalize(Transform):\n",
    "    def setup(self, array):\n",
    "        self.mean = array.mean()  # this assumes tensor, numpy arrays and alike\n",
    "        # should be applied along axis 0 (over the samples)\n",
    "        self.std = array.std()  # ddof=0 in scikit-learn\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        x_enc = (x - self.mean) / self.std\n",
    "        return x_enc\n",
    "\n",
    "    def decodes(self, x_enc):\n",
    "        x = (self.std * x_enc) + self.mean\n",
    "        return x\n",
    "    \n",
    "o_tf_norm = Normalize()\n",
    "o_tf_norm.setup(data.train_X)\n",
    "o_tf_norm(data.val_X.head()) # apply this manueally to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b2869-8dbd-462d-bf78-5435104e33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetWithMaskAndNoTarget(df=o_tf_norm(data.train_X))\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=o_tf_norm(data.val_X))\n",
    "\n",
    "dls = DataLoaders.from_dsets(\n",
    "    train_ds,\n",
    "    valid_ds,\n",
    "    #  tfms=[o_tf_norm],\n",
    "    #  after_batch=[o_tf_norm],\n",
    "    bs=4)\n",
    "\n",
    "dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5f8ac-1792-4406-89c8-79113e7f19cd",
   "metadata": {},
   "source": [
    "### FastAi Transfrom (as Dataset)\n",
    "\n",
    "- adding `Transforms` not possible, I openend a [discussion](https://forums.fast.ai/t/correct-output-type-for-tensor-created-from-dataframe-custom-new-task-tutorial/92564)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80209748-5c04-4d19-8bae-f2f865856385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from fastai.tabular.all import *\n",
    "# from fastai.torch_core import TensorBase\n",
    "\n",
    "\n",
    "class DatasetTransform(Transform):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        if not issubclass(type(df), pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f'please pass a pandas DataFrame, not: {type(df) = }')\n",
    "        self.mask_obs = df.isna()  # .astype('uint8') # in case 0,1 is preferred\n",
    "        self.data = df\n",
    "\n",
    "    def encodes(self, idx): # -> Tuple[torch.Tensor, torch.Tensor]: # annotation is interpreted\n",
    "        mask = self.mask_obs.iloc[idx]\n",
    "        data = self.data.iloc[idx]\n",
    "        # return (self.to_tensor(mask), self.to_tensor(data))\n",
    "        # return (Tensor(mask), Tensor(data))\n",
    "        return (TensorImage(data), TensorImage(mask))\n",
    "\n",
    "    def to_tensor(self, s: pd.Series) -> torch.Tensor:\n",
    "        return torch.from_numpy(s.values)\n",
    "\n",
    "\n",
    "train_tl = TfmdLists(\n",
    "    range(len(data.train_X)),\n",
    "    DatasetTransform(data.train_X))\n",
    "valid_tl = TfmdLists(\n",
    "    range(len(data.val_X)),\n",
    "    DatasetTransform(data.val_X))\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_tl, valid_tl,\n",
    "#                              after_item=[Normalize],\n",
    "#                              after_batch=[Normalize],\n",
    "                             bs=4)\n",
    "print(f\"\\n{DatasetTransform.encodes = }\")\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49cf8c-6e0a-4b4b-8e75-3bc5ab5d3781",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973df37c-83f3-4fed-a414-4012cf90091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.transform import MinMaxScaler\n",
    "\n",
    "args_vae = {}\n",
    "args_vae['SCALER'] = MinMaxScaler\n",
    "# select initial data: transformed vs not log transformed\n",
    "scaler = args_vae['SCALER']().fit(data.train_X)\n",
    "\n",
    "_transform_fct = scaler.transform\n",
    "\n",
    "train_ds = DatasetWithMaskAndNoTarget(df=_transform_fct(data.train_X))\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=_transform_fct(data.val_X))\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds,\n",
    "                             bs=4)\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22730fc1-f2b3-4133-8504-845667bfd12e",
   "metadata": {},
   "source": [
    "## FastAi version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad20eaf-8a14-4a46-aa3b-85a070966aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
