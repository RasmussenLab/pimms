{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "188fc02b-2e9b-4b72-b906-77d35ba50dab",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5f978-a0cb-4bb6-98d1-467eda257165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_rows = 120\n",
    "pd.options.display.min_rows = 50\n",
    "\n",
    "import vaep\n",
    "import vaep.imputation\n",
    "from vaep import sampling\n",
    "import vaep.models\n",
    "from vaep.io import datasplits\n",
    "from vaep.analyzers import compare_predictions\n",
    "\n",
    "\n",
    "import vaep.nb\n",
    "matplotlib.rcParams['figure.figsize'] = [10.0, 8.0]\n",
    "\n",
    "\n",
    "logger = vaep.logging.setup_nb_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e91c6b-20d6-402c-9577-a2bfd8ba592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['collab', 'DAE', 'VAE']\n",
    "ORDER_MODELS = ['random shifted normal', 'median', 'interpolated',\n",
    "                'collab', 'DAE', 'VAE',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164eb4bd-b28a-4237-bcc7-349b8ca3fc00",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# files and folders\n",
    "folder_experiment:str = 'runs/experiment_03/df_intensities_proteinGroups_long_2017_2018_2019_2020_N05015_M04547/Q_Exactive_HF_X_Orbitrap_Exactive_Series_slot_#6070' # Datasplit folder with data for experiment\n",
    "folder_data:str = '' # specify data directory if needed\n",
    "file_format: str = 'pkl' # change default to pickled files\n",
    "fn_rawfile_metadata: str = 'data/files_selected_metadata.csv' # Machine parsed metadata from rawfile workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5952936-d55f-4e91-a396-4b6867b7b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# fn_rawfile_metadata = \"data/ALD_study/processed/raw_meta.csv\"\n",
    "# folder_experiment = \"runs/appl_ald_data/plasma/proteinGroups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1509e8-6908-43c3-8909-efbb0229c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vaep.nb.Config()\n",
    "\n",
    "args.fn_rawfile_metadata = fn_rawfile_metadata\n",
    "del fn_rawfile_metadata\n",
    "\n",
    "args.folder_experiment = Path(folder_experiment)\n",
    "del folder_experiment\n",
    "args.folder_experiment.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "args.file_format = file_format\n",
    "del file_format\n",
    "\n",
    "args = vaep.nb.add_default_paths(args, folder_data=folder_data)\n",
    "del folder_data\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba2a48-dedc-47a9-b2ea-79936dfc48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasplits.DataSplits.from_folder(args.data, file_format=args.file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f67ae1-40e9-4c2a-af0a-41e627703518",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "_ = data.val_y.unstack().notna().sum(axis=1).sort_values().plot(\n",
    "        ax=ax,\n",
    "        title='Validation data',\n",
    "        ylabel='number of feat')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "ax = axes[1]\n",
    "_ = data.test_y.unstack().notna().sum(axis=1).sort_values().plot(\n",
    "        ax=ax,\n",
    "        title='Test data')\n",
    "fig.suptitle(\"Fake NAs per sample availability.\", size=24)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(fig, name='fake_na_val_test_splits', folder=args.out_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6d140-f48e-4477-84f3-47a196e0a3d8",
   "metadata": {},
   "source": [
    "## Across data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d043b40-5c74-40cc-a5cf-8d22ac5538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_feat = sampling.frequency_by_index(data.train_X, 0)\n",
    "# freq_feat.name = 'freq'\n",
    "freq_feat = vaep.io.datasplits.load_freq(args.data, file='freq_train.json')   # needs to be pickle -> index.name needed\n",
    "\n",
    "freq_feat.head() # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8c3f4-9896-4f0e-8f93-780f90b22573",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = freq_feat / len(data.train_X.index.levels[0])\n",
    "prop.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014084f-7101-4032-9be9-1cb9a4f00d53",
   "metadata": {},
   "source": [
    "# reference methods\n",
    "\n",
    "- drawing from shifted normal distribution\n",
    "- drawing from (-) normal distribution?\n",
    "- median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94ad00-78fd-4541-be5d-68391af99bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_wide_format()\n",
    "data.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526626c0-98c7-4741-abae-b6fc8c218f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES, M_FEAT = data.train_X.shape\n",
    "print(f\"N samples: {N_SAMPLES:,d}, M features: {M_FEAT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e738bd-79e9-4714-af4d-f3d0d2893353",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data.train_X.mean()\n",
    "std = data.train_X.std()\n",
    "\n",
    "imputed_shifted_normal = vaep.imputation.impute_shifted_normal(data.train_X, mean_shift=1.8, std_shrinkage=0.3, axis=0)\n",
    "imputed_shifted_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0550159-6f4e-4744-b3cd-36fad785b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_train = data.train_X.median()\n",
    "medians_train.name = 'median'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe028c4-190d-4d50-b8a7-d109817d7b98",
   "metadata": {},
   "source": [
    "# Model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc1e12-8477-4eda-a4c2-1f132e468616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "def select_content(s:str, stub='metrics_'):\n",
    "    s = s.split(stub)[1]\n",
    "    assert isinstance(s, str), f\"More than one split: {s}\"\n",
    "    entries = s.split('_')\n",
    "    if len(entries) > 1:\n",
    "        s = '_'.join(entries[:-1])\n",
    "    return s\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "all_configs = {}\n",
    "for fname in args.out_models.iterdir():\n",
    "    fname = Path(fname)\n",
    "    if fname.suffix != '.yaml':\n",
    "        continue\n",
    "    # \"grandparent\" directory gives name beside name of file\n",
    "    key = f\"{select_content(fname.stem, 'config_')}\"\n",
    "    print(f\"{key = }\")\n",
    "    with open(fname) as f:\n",
    "        loaded = yaml.safe_load(f)   \n",
    "    if key not in all_configs:\n",
    "        all_configs[key] = loaded\n",
    "        continue\n",
    "    for k, v in loaded.items():\n",
    "        if k in all_configs[key]:\n",
    "            if not all_configs[key][k] == v:\n",
    "                print(\n",
    "                    \"Diverging values for {k}: {v1} vs {v2}\".format(\n",
    "                k=k,\n",
    "                v1=all_configs[key][k],\n",
    "                v2=v)\n",
    "                )\n",
    "        else:\n",
    "            all_configs[key][k] = v\n",
    "\n",
    "model_configs = pd.DataFrame(all_configs).T\n",
    "model_configs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edc203-3fac-4321-8193-a5cc39590665",
   "metadata": {},
   "source": [
    "# load predictions\n",
    "\n",
    "- calculate correlation -> only makes sense per feature (and than save overall correlation stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15313cc9-5f1c-4c25-a22b-6c93b2e4364f",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c112f-fb4f-4dcd-b729-9c9558715d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_feat.index.name = data.train_X.columns.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc848c6-d39e-4092-9b72-3f6a0e1949e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "pred_files = [f for f in args.out_preds.iterdir() if split in f.name]\n",
    "pred_test = compare_predictions.load_predictions(pred_files)\n",
    "# pred_test = pred_test.join(medians_train, on=prop.index.name)\n",
    "pred_test['random shifted normal'] = imputed_shifted_normal\n",
    "pred_test = pred_test.join(freq_feat, on=freq_feat.index.name)\n",
    "SAMPLE_ID, FEAT_NAME = pred_test.index.names\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42efaec-4556-45e9-a813-66da159e771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_corr = pred_test.corr()\n",
    "ax = pred_test_corr.loc['observed', ORDER_MODELS].plot.bar(\n",
    "    # title='Corr. between Fake NA and model predictions on test data',\n",
    "    ylabel='correlation coefficient overall',\n",
    "    ylim=(0.7,1)\n",
    ")\n",
    "ax = vaep.plotting.add_height_to_barplot(ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(ax.get_figure(), name='pred_corr_test_overall', folder=args.out_figures)\n",
    "pred_test_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088a91f-6aaa-4b9d-b855-332d2bbf5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_per_sample_test = pred_test.groupby('Sample ID').aggregate(lambda df: df.corr().loc['observed'])[ORDER_MODELS]\n",
    "corr_per_sample_test = corr_per_sample_test.join(pred_test.groupby('Sample ID')[\n",
    "                                       'median'].count().rename('n_obs'))\n",
    "too_few_obs = corr_per_sample_test['n_obs'] < 3\n",
    "corr_per_sample_test.loc[~too_few_obs].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee088a12-ee60-45d1-bf5a-e07b76413c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(ylim=(0.7,1), rot=90,\n",
    "              # title='Corr. betw. fake NA and model predictions per sample on test data',\n",
    "              ylabel='correlation per sample')\n",
    "ax = corr_per_sample_test.plot.box(**kwargs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(ax.get_figure(), name='pred_corr_test_per_sample', folder=args.out_figures)\n",
    "with pd.ExcelWriter(args.out_figures/'pred_corr_test_per_sample.xlsx') as writer:   \n",
    "    corr_per_sample_test.describe().to_excel(writer, sheet_name='summary')\n",
    "    corr_per_sample_test.to_excel(writer, sheet_name='correlations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ed838-c46c-431e-a3ae-a05c8285a7a7",
   "metadata": {},
   "source": [
    "identify samples which are below lower whisker for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b846e1-00b8-4f61-b5cd-cdc1692787de",
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = vaep.pandas.get_lower_whiskers(corr_per_sample_test[models]).min()\n",
    "mask = (corr_per_sample_test[models] < treshold).any(axis=1)\n",
    "corr_per_sample_test.loc[mask].style.highlight_min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff3764-5063-4399-a182-3ba795fbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pred_test.index.levels[-1]\n",
    "N_SAMPLES = pred_test.index\n",
    "M = len(feature_names)\n",
    "pred_test.loc[pd.IndexSlice[:, feature_names[random.randint(0, M)]], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6145bd0-9b59-490e-9a0e-89475c18663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = random.sample(set(freq_feat.index), 1)\n",
    "pred_test.loc[pd.IndexSlice[:, options[0]], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53038e08-e7df-4758-bff0-1e1b6e61cdd2",
   "metadata": {},
   "source": [
    "### Correlation per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee92128-4f78-45e9-a607-8e6c4163181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_per_feat_test = pred_test.groupby(FEAT_NAME).aggregate(lambda df: df.corr().loc['observed'])[ORDER_MODELS]\n",
    "corr_per_feat_test = corr_per_feat_test.join(pred_test.groupby(FEAT_NAME)[\n",
    "                                   'observed'].count().rename('n_obs'))\n",
    "\n",
    "too_few_obs = corr_per_feat_test['n_obs'] < 3\n",
    "corr_per_feat_test.loc[~too_few_obs].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45b324-eaa0-43e4-b28b-b0f839f91955",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_per_feat_test.loc[too_few_obs].dropna(thresh=3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9ecc-526a-41ac-8a4d-d3a389ea6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(rot=90,\n",
    "              # title=f'Corr. per {FEAT_NAME} on test data',\n",
    "              ylabel=f'correlation per {FEAT_NAME}')\n",
    "ax = corr_per_feat_test.loc[~too_few_obs].drop(\n",
    "    'n_obs', axis=1).plot.box(**kwargs)\n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(ax.get_figure(), name='pred_corr_test_per_feat', folder=args.out_figures)\n",
    "with pd.ExcelWriter(args.out_figures/'pred_corr_test_per_feat.xlsx') as writer:\n",
    "    corr_per_feat_test.loc[~too_few_obs].describe().to_excel(writer, sheet_name='summary')\n",
    "    corr_per_feat_test.to_excel(writer, sheet_name='correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ffdfc-b1b0-4ae0-a47d-5881c534881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_count_test = data.test_y.stack().groupby(FEAT_NAME).count()\n",
    "feat_count_test.name = 'count'\n",
    "feat_count_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993d145-8b78-4769-838a-01721900a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = vaep.pandas.get_lower_whiskers(corr_per_feat_test[models]).min()\n",
    "mask = (corr_per_feat_test[models] < treshold).any(axis=1)\n",
    "\n",
    "def highlight_min(s, color, tolerence=0.00001):\n",
    "    return np.where((s - s.min()).abs() < tolerence, f\"background-color: {color};\", None)\n",
    "corr_per_feat_test.join(feat_count_test).loc[mask].sort_values('count').style.apply(highlight_min, color='yellow', axis=1, subset=corr_per_feat_test.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ebc82-587d-47c6-8422-03c610855211",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = vaep.models.Metrics(no_na_key='NA interpolated', with_na_key='NA not interpolated')\n",
    "test_metrics = metrics.add_metrics(pred_test.drop('freq', axis=1), key='test data')\n",
    "test_metrics = pd.DataFrame(test_metrics[\"NA interpolated\"])[ORDER_MODELS]\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8269d00-9048-4e70-9f39-dab95e103c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in_comparison = int(test_metrics.loc['N'].unique()[0])\n",
    "n_in_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096083d1-bcd2-44a2-94fe-a89b7d204b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'MAE'\n",
    "_to_plot = test_metrics.loc[METRIC].to_frame().T\n",
    "_to_plot.index = [feature_names.name]\n",
    "_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a259ef-48bd-4dd0-8dfe-9e2750579383",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = model_configs[[\"latent_dim\", \"hidden_layers\"]].apply(\n",
    "    lambda s: f'LD: {s[\"latent_dim\"]:3} '\n",
    "              f'- HL: {\",\".join(str(x) for x in s[\"hidden_layers\"]) if s[\"hidden_layers\"] is not np.nan else \"-\"}',\n",
    "    axis=1)\n",
    "text = text.rename({'dae': 'DAE', 'vae': 'VAE'})\n",
    "\n",
    "_to_plot.loc[\"text\"] = text\n",
    "_to_plot = _to_plot.fillna('')\n",
    "_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd53c0-4068-4eac-a5c3-7aaa608e5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_to_use = [sns.color_palette()[5] ,*sns.color_palette()[:5]]\n",
    "# list(sns.color_palette().as_hex()) # string representation of colors\n",
    "sns.color_palette() # select colors for comparibility with grid search (where random shifted was omitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e56c35-165f-4d3c-a1e2-8deeee06c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax = _to_plot.loc[[feature_names.name]].plot.bar(rot=0,\n",
    "                                                 ylabel=f\"{METRIC} for {feature_names.name} (based on {n_in_comparison:,} log2 intensities)\",\n",
    "                                                 # title=f'performance on test data (based on {n_in_comparison:,} measurements)',\n",
    "                                                 color=colors_to_use,\n",
    "                                                 ax=ax,\n",
    "                                                 width=.8)\n",
    "ax = vaep.plotting.add_height_to_barplot(ax)\n",
    "ax = vaep.plotting.add_text_to_barplot(ax, _to_plot.loc[\"text\"], size=16)\n",
    "ax.set_xticklabels([])\n",
    "vaep.savefig(fig, \"performance_models_test\", folder=args.out_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa35b4-26f5-4172-a1ca-768434b9782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_test = vaep.pandas.calc_errors_per_feat(pred_test.drop(\"freq\", axis=1), freq_feat=freq_feat)[[*ORDER_MODELS, 'freq']]\n",
    "errors_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221dedf-43df-4b5f-b93a-4a4238d45a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_error(errors: pd.DataFrame, metric_name, window: int = 200,\n",
    "                       min_freq=None, freq_col: str = 'freq', \n",
    "                       ax=None):\n",
    "    errors_smoothed = errors.drop(freq_col, axis=1).rolling(window=window, min_periods=1).mean()\n",
    "    errors_smoothed_max = errors_smoothed.max().max()\n",
    "    errors_smoothed[freq_col] = errors[freq_col]\n",
    "    if min_freq is None:\n",
    "        min_freq=errors_smoothed[freq_col].min()\n",
    "    else:\n",
    "        errors_smoothed = errors_smoothed.loc[errors_smoothed[freq_col] > min_freq]\n",
    "    ax = errors_smoothed.plot(x=freq_col, ylabel=f'rolling average error ({metric_name})',\n",
    "                              color=colors_to_use,\n",
    "                              xlim=(min_freq, errors_smoothed[freq_col].max()),\n",
    "                              ylim=(0, min(errors_smoothed_max, 5)), \n",
    "                              ax=None)\n",
    "    return ax\n",
    "\n",
    "min_freq = None\n",
    "ax = plot_rolling_error(errors_test, metric_name=METRIC, window=int(len(errors_test)/15), min_freq=min_freq)\n",
    "vaep.savefig(ax.get_figure(), name='errors_rolling_avg_test', folder=args.out_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd507b53-a8d6-49f9-97c9-d0e0f62456bd",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce85076",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'\n",
    "pred_files = [f for f in args.out_preds.iterdir() if split in f.name]\n",
    "pred_val = compare_predictions.load_predictions(pred_files)\n",
    "# pred_val = pred_val.join(medians_train, on=freq_feat.index.name)\n",
    "pred_val['random shifted normal'] = imputed_shifted_normal\n",
    "# pred_val = pred_val.join(freq_feat, on=freq_feat.index.name)\n",
    "pred_val_corr = pred_val.corr()\n",
    "ax = pred_val_corr.loc['observed', ORDER_MODELS].plot.bar(\n",
    "    # title='Correlation between Fake NA and model predictions on validation data',\n",
    "    ylabel='correlation overall')\n",
    "ax = vaep.plotting.add_height_to_barplot(ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(ax.get_figure(), name='pred_corr_val_overall', folder=args.out_figures)\n",
    "pred_val_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7831e-ebf3-4de4-af6c-c4b2a8b00373",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_per_sample_val = pred_val.groupby('Sample ID').aggregate(lambda df: df.corr().loc['observed'])[ORDER_MODELS]\n",
    "\n",
    "kwargs = dict(ylim=(0.7,1), rot=90,\n",
    "              # title='Corr. betw. fake NA and model pred. per sample on validation data',\n",
    "              ylabel='correlation per sample')\n",
    "ax = corr_per_sample_val.plot.box(**kwargs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "vaep.savefig(ax.get_figure(), name='pred_corr_valid_per_sample', folder=args.out_figures)\n",
    "with pd.ExcelWriter(args.out_figures/'pred_corr_valid_per_sample.xlsx') as writer:   \n",
    "    corr_per_sample_test.describe().to_excel(writer, sheet_name='summary')\n",
    "    corr_per_sample_test.to_excel(writer, sheet_name='correlations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682b3e4-7841-4348-8be2-b63bfd371f65",
   "metadata": {},
   "source": [
    "identify samples which are below lower whisker for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068d91f-856e-4aa6-9c62-5f1f77a77c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = vaep.pandas.get_lower_whiskers(corr_per_sample_val[models]).min()\n",
    "mask = (corr_per_sample_val[models] < treshold).any(axis=1)\n",
    "corr_per_sample_val.loc[mask].style.highlight_min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5575e14-3b49-4821-90e2-17ad0bc2acb1",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55a16f-1f2d-4b3e-ba6d-ecd1987a67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val = pred_val.drop('observed', axis=1).sub(pred_val['observed'], axis=0)[ORDER_MODELS]\n",
    "errors_val.describe() # over all samples, and all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d11428-4f9b-4918-9ec6-d20a298c6009",
   "metadata": {},
   "source": [
    "Describe absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df94e9-2436-4cdd-9c6f-47062bac7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val.abs().describe() # over all samples, and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52298acd-73c5-4574-b7fe-8fb6544708cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_error_min = 4.5\n",
    "mask = (errors_val[models].abs() > c_error_min).any(axis=1)\n",
    "errors_val.loc[mask].sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fc505-ab27-4710-b4c2-adbe72b33898",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val = errors_val.abs().groupby(freq_feat.index.name).mean() # absolute error\n",
    "errors_val = errors_val.join(freq_feat)\n",
    "errors_val = errors_val.sort_values(by=freq_feat.name, ascending=True)\n",
    "errors_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9a8ea",
   "metadata": {},
   "source": [
    "Some interpolated features are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc98a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val.describe()  # mean of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f0e81-e9af-4763-908d-f7bdf4a4fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_avg_error = 2\n",
    "mask = (errors_val[models] >= c_avg_error).any(axis=1)\n",
    "errors_val.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a505e2-4d05-460e-a2c5-47edc5038dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val_smoothed = errors_val.copy()\n",
    "errors_val_smoothed[errors_val.columns[:-1]] = errors_val[errors_val.columns[:-1]].rolling(window=200, min_periods=1).mean()\n",
    "ax = plot_rolling_error(errors_test, metric_name=METRIC, window=int(len(errors_test)/15), min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8693e3d-37f8-4c7e-acf0-87ae7436eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_val_smoothed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422aecb-eecc-4270-8891-5010e8b1ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.savefig(\n",
    "    ax.get_figure(),\n",
    "    folder=args.out_figures,\n",
    "    name='performance_methods_by_completness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7b878-6b1d-4b2d-b861-8e0bccbf88ff",
   "metadata": {},
   "source": [
    "# Average errors per feature - example scatter for collab\n",
    "- see how smoothing is done, here `collab`\n",
    "- shows how features are distributed in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122a309-5435-44d2-a6f8-8e9d46b5afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plots to see spread\n",
    "model = models[0]\n",
    "ax = errors_val.plot.scatter(x=prop.name, y=model, c='darkblue', ylim=(0,2),\n",
    "  # title=f\"Average error per feature on validation data for {model}\",\n",
    "  ylabel=f'average error ({METRIC}) for {model} on valid. data')\n",
    "\n",
    "vaep.savefig(\n",
    "    ax.get_figure(),\n",
    "    folder=args.out_figures,\n",
    "    name='performance_methods_by_completness_scatter',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b43585-3b2d-4821-8222-982795e45b72",
   "metadata": {},
   "source": [
    "- [ ] plotly plot with number of observations the mean for each feature is based on"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "cf83e9cb890c7f96eb0ae04f39a82254555f56a1a0ed2f03b23a8b40fe6cd31c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
