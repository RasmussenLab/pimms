{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 03 - Data\n",
    "\n",
    "Create data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from typing import Union, List\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import vaep\n",
    "from vaep.io.datasplits import DataSplits\n",
    "from vaep.io import thermo_raw_files\n",
    "from vaep.sampling import feature_frequency, sample_data\n",
    "\n",
    "from vaep.analyzers import analyzers\n",
    "from vaep.analyzers.analyzers import  AnalyzePeptides\n",
    "\n",
    "logger = vaep.logging.setup_nb_logger()\n",
    "logger.info(\"Split data and make diagnostic plots\")\n",
    "\n",
    "def add_meta_data(analysis: AnalyzePeptides, df_meta: pd.DataFrame):\n",
    "    try:\n",
    "        analysis.df = analysis.df.loc[df_meta.index]\n",
    "    except KeyError as e:\n",
    "        logger.warning(e)\n",
    "        logger.warning(\"Ignore missing samples in quantified samples\")\n",
    "        analysis.df = analysis.df.loc[analysis.df.index.intersection(\n",
    "            df_meta.index)]\n",
    "\n",
    "    analysis.df_meta = df_meta\n",
    "    return analysis\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 32\n",
    "plt.rcParams['figure.figsize'] = [4, 2]\n",
    "vaep.plotting.make_large_descriptors(5)\n",
    "\n",
    "figures = {}  # collection of ax or figures\n",
    "dumps = {}  # collection of data dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch passed parameters\n",
    "args = None\n",
    "args = dict(globals()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample (rows) intensiites for features (columns)\n",
    "FN_INTENSITIES: str = 'data/dev_datasets/HeLa_6070/protein_groups_wide_N50.csv'\n",
    "# Can be either a string or position (typical 0 for first column), or a list of these.\n",
    "index_col: Union[str, int] = 0\n",
    "# wide_format: bool = False # intensities in wide format (more memory efficient of csv). Default is long_format (more precise)\n",
    "# Manuelly set column names (of Index object in columns)\n",
    "column_names: List[str] = [\"Gene Names\"]\n",
    "# Machine parsed metadata from raw file (see workflows/metadata), wide format per sample\n",
    "fn_rawfile_metadata: str = 'data/dev_datasets/HeLa_6070/files_selected_metadata_N50.csv'\n",
    "# Minimum number or fraction of feature prevalence across samples to be kept\n",
    "feat_prevalence: Union[int, float] = 0.25\n",
    "# Minimum number or fraction of total requested features per Sample\n",
    "sample_completeness: Union[int, float] = 0.5\n",
    "select_N: int = None  # only use latest N samples\n",
    "sample_N: bool = False # if select_N, sample N randomly instead of using latest?\n",
    "random_state: int = 42  # random state for reproducibility of splits\n",
    "# based on raw file meta data, only take samples with RT > min_RT_time\n",
    "min_RT_time: Union[int, float] = None\n",
    "# Log transformation of initial data (select one of the existing in numpy)\n",
    "logarithm: str = 'log2'\n",
    "folder_experiment: str = f'runs/example'\n",
    "folder_data: str = ''  # specify data directory if needed\n",
    "file_format: str = 'csv'  # file format of create splits, default pickle (pkl)\n",
    "# metadata -> defaults for metadata extracted from machine data, used for plotting\n",
    "meta_date_col: str = None  # date column in meta data\n",
    "meta_cat_col: str = None  # category column in meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vaep.nb.get_params(args, globals=globals())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "params = vaep.nb.args_from_dict(args)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(params.index_col, str) or isinstance(params.index_col, int):\n",
    "    params.overwrite_entry('index_col', [params.index_col])\n",
    "params.index_col  # make sure it is an iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"{params.FN_INTENSITIES = }\")\n",
    "\n",
    "\n",
    "FILE_FORMAT_TO_CONSTRUCTOR = {'csv': 'from_csv',\n",
    "                              'pkl': 'from_pickle',\n",
    "                              'pickle': 'from_pickle',\n",
    "                              }\n",
    "\n",
    "FILE_EXT = Path(params.FN_INTENSITIES).suffix[1:]\n",
    "logger.info(\n",
    "    f\"File format (extension): {FILE_EXT}  (!specifies data loading function!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalyzePeptides.from_csv\n",
    "constructor = getattr(AnalyzePeptides, FILE_FORMAT_TO_CONSTRUCTOR[FILE_EXT])\n",
    "analysis = constructor(fname=params.FN_INTENSITIES,\n",
    "                       index_col=params.index_col,\n",
    "                       )\n",
    "if params.column_names:\n",
    "    analysis.df.columns.names = params.column_names\n",
    "\n",
    "if not analysis.df.index.name:\n",
    "    logger.warning(\"No sample index name found, setting to 'Sample ID'\")\n",
    "    analysis.df.index.name = 'Sample ID'\n",
    "\n",
    "log_fct = getattr(np, params.logarithm)\n",
    "analysis.log_transform(log_fct)\n",
    "logger.info(f\"{analysis = }\")\n",
    "analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ax = analysis.df.notna().sum(axis=0).to_frame(\n",
    "    analysis.df.columns.name).plot.box()\n",
    "ax.set_ylabel('number of observation across samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = params.out_folder / '01_0_data_stats.xlsx'\n",
    "dumps[fname.name] = fname.as_posix()\n",
    "writer = pd.ExcelWriter(fname)\n",
    "\n",
    "notna = analysis.df.notna()\n",
    "data_stats_original = pd.concat(\n",
    "    [\n",
    "        notna.sum().describe().rename('feat_stats'),\n",
    "        notna.sum(axis=1).describe().rename('sample_stats')\n",
    "    ],\n",
    "    axis=1)\n",
    "data_stats_original.to_excel(writer, sheet_name='data_stats_original')\n",
    "data_stats_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case there are multiple features for each intensity values (currenlty: peptide sequence and charge), combine the column names to a single str index.\n",
    "\n",
    "> The Collaborative Modeling approach will need a single feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_as_str(seq):\n",
    "    ret = \"_\".join(str(x) for x in seq)\n",
    "    return ret\n",
    "\n",
    "# ToDo: join multiindex samples indices (pkl dumps)\n",
    "# if hasattr(analysis.df.columns, \"levels\"):\n",
    "if isinstance(analysis.df.columns, pd.MultiIndex):\n",
    "    logger.warning(\"combine MultiIndex columns to one feature column\")\n",
    "    print(analysis.df.columns[:10].map(join_as_str))\n",
    "    _new_name = join_as_str(analysis.df.columns.names)\n",
    "    analysis.df.columns = analysis.df.columns.map(join_as_str)\n",
    "    analysis.df.columns.name = _new_name\n",
    "    logger.warning(f\"New name: {analysis.df.columns.names = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine metadata\n",
    "\n",
    "- read from file using [ThermoRawFileParser](https://github.com/compomics/ThermoRawFileParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.fn_rawfile_metadata:\n",
    "    df_meta = pd.read_csv(params.fn_rawfile_metadata, index_col=0)\n",
    "else:\n",
    "    logger.warning(f\"No metadata for samples provided, create placeholder.\")\n",
    "    if params.meta_date_col:\n",
    "        raise ValueError(\n",
    "            f\"No metadata provided, but data column set: {params.meta_date_col}\")\n",
    "    if params.meta_cat_col:\n",
    "        raise ValueError(\n",
    "            f\"No metadata provided, but data column set: {params.meta_cat_col}\")\n",
    "    df_meta = pd.DataFrame(index=analysis.df.index)\n",
    "df_meta = df_meta.loc[analysis.df.index.to_list()]  # index is sample index\n",
    "if df_meta.index.name is None:\n",
    "    df_meta.index.name = params.index_col[0]\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.meta_date_col:\n",
    "    df_meta[params.meta_date_col] = pd.to_datetime(\n",
    "        df_meta[params.meta_date_col])\n",
    "else:\n",
    "    params.overwrite_entry('meta_date_col', 'PlaceholderTime')\n",
    "    df_meta[params.meta_date_col] = range(len(df_meta))\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_meta.columns.isin(thermo_raw_files.cols_instrument).sum() == len(thermo_raw_files.cols_instrument):\n",
    "    display(df_meta.groupby(thermo_raw_files.cols_instrument)[\n",
    "            params.meta_date_col].agg(['count', 'min', 'max']))\n",
    "else:\n",
    "    logger.info(\n",
    "        f\"Instrument column not found: {thermo_raw_files.cols_instrument}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.describe(datetime_is_numeric=True,\n",
    "                 percentiles=np.linspace(0.05, 0.95, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select samples with a minimum retention time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.min_RT_time:\n",
    "    logger.info(\n",
    "        \"Metadata should have 'MS max RT' entry from ThermoRawFileParser\")\n",
    "    msg = f\"Minimum RT time maxiumum is set to {params.min_RT_time} minutes (to exclude too short runs, which are potentially fractions).\"\n",
    "    # can be integrated into query string\n",
    "    mask_RT = df_meta['MS max RT'] >= params.min_RT_time\n",
    "    msg += f\" Total number of samples retained: {int(mask_RT.sum())}\"\n",
    "    msg += f\" ({int(len(mask_RT) - mask_RT.sum())} excluded).\"\n",
    "    logger.info(msg)\n",
    "    df_meta = df_meta.loc[mask_RT]\n",
    "else:\n",
    "    logger.warning(f\"Retention time filtering deactivated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_meta.sort_values(params.meta_date_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_stats = df_meta.describe(include='all', datetime_is_numeric=True)\n",
    "meta_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset with variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(meta_stats.loc[:, (meta_stats.loc['unique']\n",
    "            > 1) | (meta_stats.loc['std'] > 0.1)])\n",
    "except KeyError:\n",
    "    if 'std' in meta_stats.index:\n",
    "        display(meta_stats.loc[:, (meta_stats.loc['std'] > 0.1)])\n",
    "    if 'unique' in meta_stats.index:\n",
    "        display(meta_stats.loc[:, (meta_stats.loc['std'] > 0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional, if using ThermoRawFileParser: check some columns describing settings\n",
    "  - software can be updated: `Software Version`\n",
    "  - `mass resolution` setting for instrument\n",
    "  - colision type for MS2: `beam-type collision-induced dissocation`\n",
    "  - missing `dilution factor`\n",
    "  - omit (uncomment if needed):\n",
    "    - quite some variation due to `MS max charge`: omit\n",
    "    - variation by `injection volume setting` and instrument over time\n",
    "        - 500ng of peptides should be injected, based on concentration of peptides this setting is adjusted to get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "meta_raw_settings = [\n",
    "    'Thermo Scientific instrument model',\n",
    "    'instrument serial number',\n",
    "    'Software Version',\n",
    "    # 'MS max charge',\n",
    "    'mass resolution',\n",
    "    'beam-type collision-induced dissociation',\n",
    "    # 'injection volume setting',\n",
    "    'dilution factor',\n",
    "]\n",
    "\n",
    "if df_meta.columns.isin(meta_raw_settings).sum() == len(meta_raw_settings):\n",
    "    display(\n",
    "        # index gives first example with this combination\n",
    "        df_meta[meta_raw_settings].drop_duplicates()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check for variation in `software Version` and `injection volume setting`\n",
    "\n",
    "\n",
    "Update selection of samples based on metadata (e.g. minimal retention time)\n",
    "- sort data the same as sorted meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = add_meta_data(analysis, df_meta=df_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure unique indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df.index.is_unique, \"Duplicates in index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of samples if specified (reduce the number of samples)\n",
    "\n",
    "- select features if `select_N` is specifed (for now)\n",
    "- for interpolation to make sense, it is best to select a consecutive number of samples:\n",
    "  - take N most recent samples (-> check that this makes sense for your case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.select_N is not None:\n",
    "    params.select_N = min(params.select_N, len(analysis.df_meta))\n",
    "    if params.sample_N:\n",
    "        analysis.df_meta = analysis.df_meta.sample(params.select_N)\n",
    "    else:\n",
    "        analysis.df_meta = analysis.df_meta.iloc[-params.select_N:]\n",
    "\n",
    "    analysis.df = analysis.df.loc[analysis.df_meta.index].dropna(\n",
    "        how='all', axis=1)\n",
    "    ax = analysis.df.T.describe().loc['count'].hist()\n",
    "    _ = ax.set_title('histogram of features for all eligable samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Select features by prevalence\n",
    "- `feat_prevalence` across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_per_feature = analysis.df.notna().sum()  # on wide format\n",
    "if isinstance(params.feat_prevalence, float):\n",
    "    N_samples = len(analysis.df_meta)\n",
    "    logger.info(f\"Current number of samples: {N_samples}\")\n",
    "    logger.info(\n",
    "        f\"Feature has to be present in at least {params.feat_prevalence:.2%} of samples\")\n",
    "    params.overwrite_entry('feat_prevalence', int(\n",
    "        N_samples * params.feat_prevalence))\n",
    "assert isinstance(params.feat_prevalence, int)\n",
    "! check that feature prevalence is greater equal to 3 (otherwise train, val, test split is not possible)\n",
    "logger.info(\n",
    "    f\"Feature has to be present in at least {params.feat_prevalence} of samples\")\n",
    "# select features\n",
    "mask = freq_per_feature >= params.feat_prevalence\n",
    "logger.info(f\"Drop {(~mask).sum()} features\")\n",
    "freq_per_feature = freq_per_feature.loc[mask]\n",
    "analysis.df = analysis.df.loc[:, mask]\n",
    "analysis.N, analysis.M = analysis.df.shape\n",
    "\n",
    "# # potentially create freq based on DataFrame\n",
    "analysis.df\n",
    "\n",
    "notna = analysis.df.notna()\n",
    "data_stats_filtered = pd.concat(\n",
    "    [\n",
    "        notna.sum().describe().rename('feat_stats'),\n",
    "        notna.sum(axis=1).describe().rename('sample_stats')\n",
    "    ],\n",
    "    axis=1)\n",
    "data_stats_filtered.to_excel(writer, sheet_name='data_stats_filtered')\n",
    "data_stats_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step - Sample selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select samples based on completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(params.sample_completeness, float):\n",
    "    msg = f'Fraction of minimum sample completeness over all features specified with: {params.sample_completeness}\\n'\n",
    "    # assumes df in wide format\n",
    "    params.overwrite_entry('sample_completeness', int(\n",
    "        analysis.df.shape[1] * params.sample_completeness))\n",
    "    msg += f'This translates to a minimum number of features per sample (to be included): {params.sample_completeness}'\n",
    "    logger.info(msg)\n",
    "\n",
    "sample_counts = analysis.df.notna().sum(axis=1)  # if DataFrame\n",
    "sample_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sample_counts > params.sample_completeness\n",
    "msg = f'Drop {len(mask) - mask.sum()} of {len(mask)} initial samples.'\n",
    "print(msg)\n",
    "analysis.df = analysis.df.loc[mask]\n",
    "analysis.df = analysis.df.dropna(\n",
    "    axis=1, how='all')  # drop now missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.N, params.M = analysis.df.shape  # save data dimensions\n",
    "params.used_samples = analysis.df.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of features per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = analysis.df.notna().sum(axis=1).hist()\n",
    "ax.set_xlabel('features per eligable sample')\n",
    "ax.set_ylabel('observations')\n",
    "fname = params.out_figures / 'hist_features_per_sample'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ax = analysis.df.notna().sum(axis=0).sort_values().plot()\n",
    "_new_labels = [l.get_text().split(';')[0] for l in ax.get_xticklabels()]\n",
    "_ = ax.set_xticklabels(_new_labels, rotation=45,\n",
    "                       horizontalalignment='right')\n",
    "ax.set_xlabel('feature prevalence')\n",
    "ax.set_ylabel('observations')\n",
    "fname = params.out_figures / 'feature_prevalence'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number off observations accross feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = vaep.plotting.data.min_max(analysis.df.stack())\n",
    "ax, bins = vaep.plotting.data.plot_histogram_intensites(\n",
    "    analysis.df.stack(), min_max=min_max)\n",
    "\n",
    "fname = params.out_figures / 'intensity_distribution_overall'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = vaep.plotting.data.plot_feat_median_over_prop_missing(\n",
    "    data=analysis.df, type='scatter')\n",
    "fname = params.out_figures / 'intensity_median_vs_prop_missing_scatter'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = vaep.plotting.data.plot_feat_median_over_prop_missing(\n",
    "    data=analysis.df, type='boxplot')\n",
    "fname = params.out_figures / 'intensity_median_vs_prop_missing_boxplot'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive and Single plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots need to become interactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counts.name = 'identified features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "analysis.df = analysis.df.astype(float)\n",
    "pcs = analysis.get_PCA(n_components=K)  # should be renamed to get_PCs\n",
    "pcs = pcs.iloc[:, :K].join(analysis.df_meta).join(sample_counts)\n",
    "\n",
    "pcs_name = pcs.columns[:2]\n",
    "pcs_index_name = pcs.index.name\n",
    "pcs = pcs.reset_index()\n",
    "pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.describe(include='all', datetime_is_numeric=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.meta_cat_col:\n",
    "    fig, ax = plt.subplots(figsize=(2,2))\n",
    "    analyzers.seaborn_scatter(\n",
    "        pcs[pcs_name], ax, meta=pcs[params.meta_cat_col], title=f\"by {params.meta_cat_col}\")\n",
    "    fname = (params.out_figures\n",
    "              / f'pca_sample_by_{\"_\".join(params.meta_cat_col.split())}')\n",
    "    figures[fname.stem] = fname\n",
    "    vaep.savefig(fig, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.meta_date_col != 'PlaceholderTime':\n",
    "    fig, ax = plt.subplots()\n",
    "    analyzers.plot_date_map(\n",
    "        df=pcs[pcs_name], ax=ax, dates=pcs[params.meta_date_col], title=f'by {params.meta_date_col}')\n",
    "    fname = params.out_figures / 'pca_sample_by_date'\n",
    "    figures[fname.stem] = fname\n",
    "    vaep.savefig(fig, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- software version: Does it make a difference?\n",
    "- size: number of features in a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "col_identified_feat = 'identified features'\n",
    "analyzers.plot_scatter(\n",
    "    pcs[pcs_name],\n",
    "    ax,\n",
    "    pcs[col_identified_feat],\n",
    "    title=f'by {col_identified_feat}',\n",
    "    size=5,\n",
    ")\n",
    "fname = (params.out_figures\n",
    "         / f'pca_sample_by_{\"_\".join(col_identified_feat.split())}.pdf')\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(fig, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pcs, x=pcs_name[0], y=pcs_name[1],\n",
    "    hover_name=pcs_index_name,\n",
    "    # hover_data=analysis.df_meta,\n",
    "    title=f'First two Principal Components of {analysis.M} features for {pcs.shape[0]} samples',\n",
    "    # color=pcs['Software Version'],\n",
    "    color=col_identified_feat,\n",
    "    template='none',\n",
    "    width=1200, # 4 inches x 300 dpi\n",
    "    height=600 # 2 inches x 300 dpi\n",
    ")\n",
    "fname = (params.out_figures\n",
    "         / f'pca_sample_by_{\"_\".join(col_identified_feat.split())}_plotly.pdf')\n",
    "figures[fname.stem] = fname\n",
    "fig.write_image(fname)\n",
    "fig  # stays interactive in html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Medians and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.df\n",
    "df = df.join(df_meta[params.meta_date_col])\n",
    "df = df.set_index(params.meta_date_col).sort_index()\n",
    "if not params.meta_date_col == 'PlaceholderTime':\n",
    "    df.to_period('min')\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.boxplot(rot=80, figsize=(8, 3), fontsize=5,\n",
    "                showfliers=False, showcaps=False)\n",
    "_ = vaep.plotting.select_xticks(ax)\n",
    "fig = ax.get_figure()\n",
    "fname = params.out_figures / 'median_boxplot'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(fig, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles of intensities in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack().describe(percentiles=np.linspace(0.05, 0.95, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample median over time\n",
    "  - check if points are equally spaced (probably QC samples are run in close proximity)\n",
    "  - the machine will be not use for intermediate periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not params.meta_date_col == 'PlaceholderTime':\n",
    "    dates = df_meta[params.meta_date_col].sort_values()\n",
    "    # dates.name = 'date'\n",
    "    median_sample_intensity = (analysis.df\n",
    "                               .median(axis=1)\n",
    "                               .to_frame('median intensity'))\n",
    "    median_sample_intensity = median_sample_intensity.join(dates)\n",
    "\n",
    "    ax = median_sample_intensity.plot.scatter(x=dates.name, y='median intensity',\n",
    "                                              rot=90,\n",
    "                                              fontsize='large',\n",
    "                                              figsize=(8, 2),\n",
    "                                              s=5,\n",
    "                                              xticks=vaep.plotting.select_dates(\n",
    "                                                  median_sample_intensity[dates.name])\n",
    "                                              )\n",
    "    fig = ax.get_figure()\n",
    "    figures['median_scatter'] = params.out_figures / 'median_scatter'\n",
    "    vaep.savefig(fig, figures['median_scatter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the closer the labels are there denser the samples are measured around that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature frequency  in data\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data\n",
    "\n",
    "Based on unmodified training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Total number of samples in training data split: {}\"\n",
    "print(msg.format(len(analysis.df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # analysis.splits.to_wide_format()\n",
    "# assert analysis.splits is splits, \"Sanity check failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate feature frequency after selecting some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_per_feature = feature_frequency(analysis.df)\n",
    "freq_per_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_per_feature.name = 'Gene names freq' # name it differently?\n",
    "# index.name is lost when data is stored\n",
    "fname = params.data / 'freq_features.json'\n",
    "dumps[fname.name] = fname\n",
    "freq_per_feature.to_json(fname)\n",
    "fname = fname.with_suffix('.pkl')\n",
    "dumps[fname.name] = fname\n",
    "freq_per_feature.to_pickle(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conserning sampling with frequency weights:\n",
    "  - larger weight -> higher probablility of being sampled\n",
    "  - weights need to be alignable to index of original DataFrame before grouping (same index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split: Train, validation and test data\n",
    "\n",
    "- test data is in clinical language often denoted as independent validation cohort\n",
    "- validation data (for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.splits = DataSplits(is_wide_format=False)\n",
    "splits = analysis.splits\n",
    "print(f\"{analysis.splits = }\")\n",
    "analysis.splits.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample targets (Fake NAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add goldstandard targets for valiation and test data\n",
    "- based on same day\n",
    "- same instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some target values by sampling 5% of the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.to_long_format(inplace=True)\n",
    "analysis.df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_na, splits.train_X = sample_data(analysis.df_long.squeeze(),\n",
    "                                      sample_index_to_drop=0,\n",
    "                                      weights=freq_per_feature,\n",
    "                                      frac=0.1,\n",
    "                                      random_state=params.random_state,)\n",
    "assert len(splits.train_X) > len(fake_na)\n",
    "splits.val_y = fake_na.sample(frac=0.5, random_state=params.random_state).sort_index()\n",
    "splits.test_y = fake_na.loc[fake_na.index.difference(splits.val_y.index)]\n",
    "# splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo check that feature indices and sample indicies overlap\n",
    "# -> a single feature cannot be only in the validation or test split\n",
    "# -> single features should be put into the training data\n",
    "# -> or raise error as feature completness treshold is so low that less than 3 samples\n",
    "# per feature are allowd.\n",
    "\n",
    "diff = (splits\n",
    "    .val_y\n",
    "    .index\n",
    "    .levels[-1]\n",
    "    .difference(splits\n",
    "                .train_X\n",
    "                .index\n",
    "                .levels[-1]\n",
    "    ).to_list())\n",
    "if diff:\n",
    "    to_remove = splits.val_y.loc[pd.IndexSlice[:, diff]]\n",
    "    display(to_remove)\n",
    "    splits.train_X = pd.concat([splits.train_X, to_remove])\n",
    "    splits.val_y = splits.val_y.drop(to_remove.index)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc31ea0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "diff = (splits\n",
    "    .test_y\n",
    "    .index\n",
    "    .levels[-1]\n",
    "    .difference(splits\n",
    "                .train_X\n",
    "                .index\n",
    "                .levels[-1]\n",
    "    ).to_list())\n",
    "if diff:\n",
    "    to_remove = splits.test_y.loc[pd.IndexSlice[:, diff]]\n",
    "    display(to_remove)\n",
    "    splits.train_X = pd.concat([splits.train_X, to_remove])\n",
    "    splits.test_y = splits.test_y.drop(to_remove.index)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumps data in long-format\n",
    "splits_dumped = splits.dump(folder=params.data, file_format=params.file_format)\n",
    "dumps.update(splits_dumped)\n",
    "splits_dumped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DataSplits.from_folder(params.data, file_format=params.file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot distribution of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_df = pd.DataFrame(index=analysis.df_long.index)\n",
    "splits_df['train'] = splits.train_X\n",
    "splits_df['val'] = splits.val_y\n",
    "splits_df['test'] = splits.test_y\n",
    "stats_splits = splits_df.describe()\n",
    "stats_splits.to_excel(writer, 'stats_splits', float_format='%.2f')\n",
    "stats_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whitespaces in legends are not displayed correctly...\n",
    "# max_int_len   = len(str(int(stats_splits.loc['count'].max()))) +1\n",
    "# _legend = [\n",
    "#     f'{s:<5} (N={int(stats_splits.loc[\"count\", s]):>{max_int_len},d})'.replace(\n",
    "#         ' ', '\\u00A0')\n",
    "#     for s in ('train', 'val', 'test')]\n",
    "_legend = [\n",
    "    f'{s:<5} (N={int(stats_splits.loc[\"count\", s]):,d})'\n",
    "    for s in ('train', 'val', 'test')]\n",
    "print(_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (splits\n",
    "      .train_X\n",
    "      .plot\n",
    "      .hist(\n",
    "          bins=bins,\n",
    "          ax=None,\n",
    "          color='C0',\n",
    "))\n",
    "_ = (splits\n",
    "     .val_y\n",
    "     .plot\n",
    "     .hist(bins=bins,\n",
    "           xticks=list(bins),\n",
    "           ax=ax,\n",
    "           color='C2',\n",
    "           legend=True)\n",
    "     )\n",
    "ax.legend(_legend[:-1])\n",
    "fname = params.out_figures / 'test_over_train_split.pdf'\n",
    "figures[fname.name] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = vaep.plotting.data.min_max(splits.val_y)\n",
    "bins = range(int(min_bin), int(max_bin), 1)\n",
    "ax = splits_df.plot.hist(bins=bins,\n",
    "                         xticks=list(bins),\n",
    "                         legend=False,\n",
    "                         stacked=True,\n",
    "                         color=['C0', 'C1', 'C2'],\n",
    "    )\n",
    "ax.legend(_legend)\n",
    "ax.set_xlabel('Intensity bins')\n",
    "ax.yaxis.set_major_formatter(\"{x:,.0f}\")\n",
    "fname = params.out_figures / 'splits_freq_stacked.pdf'\n",
    "figures[fname.name] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = splits_df.drop('train', axis=1).plot.hist(bins=bins,\n",
    "                                               xticks=list(bins),\n",
    "                                               color=['C1', 'C2'],\n",
    "                                               legend=False,\n",
    "                                               stacked=True,\n",
    "                        )\n",
    "ax.legend(_legend[1:])\n",
    "ax.set_xlabel('Intensity bins')\n",
    "ax.yaxis.set_major_formatter(\"{x:,.0f}\")\n",
    "fname = params.out_figures / 'val_test_split_freq_stacked_.pdf'\n",
    "figures[fname.name] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3a66e",
   "metadata": {},
   "source": [
    "plot training data missing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61154b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.to_wide_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = vaep.plotting.data.plot_feat_median_over_prop_missing(\n",
    "    data=splits.train_X, type='scatter')\n",
    "fname = params.out_figures / 'intensity_median_vs_prop_missing_scatter_train'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = vaep.plotting.data.plot_feat_median_over_prop_missing(\n",
    "    data=splits.train_X, type='boxplot')\n",
    "fname = params.out_figures / 'intensity_median_vs_prop_missing_boxplot_train'\n",
    "figures[fname.stem] = fname\n",
    "vaep.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = params.folder_experiment / 'data_config.yaml'\n",
    "params.dump(fname)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved figures\n",
    "figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "writer.close()\n",
    "dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
