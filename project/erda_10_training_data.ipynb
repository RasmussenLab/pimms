{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a set of training data\n",
    "\n",
    "Use a set of (most) common peptides to create inital data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import random  # shuffle, seed\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import src.config as config\n",
    "from src.config import FOLDER_PROCESSED\n",
    "import vaep.io\n",
    "from vaep.io import data_objects\n",
    "\n",
    "from src.config import FNAME_C_PEPTIDES, FNAME_C_EVIDENCE, FNAME_C_PG, FNAME_C_GENES\n",
    "\n",
    "FNAME_C_PEPTIDES, FNAME_C_EVIDENCE, FNAME_C_PG, FNAME_C_GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def select_files_by_parent_folder(fpaths:List, years:List):\n",
    "    selected = []\n",
    "    for year_folder in years:\n",
    "        # several passes, but not a bottle neck\n",
    "        selected += [dump for dump in fpaths if year_folder in dump.parent.stem]\n",
    "    return selected\n",
    "\n",
    "def load_evidence_dump(fpath, index_col=['Sequence', 'Charge']):\n",
    "    df = pd.read_csv(fpath, index_col=index_col)\n",
    "    return df\n",
    "\n",
    "def load_agg_peptide_dump(fpath):\n",
    "    fpath = Path(fpath)\n",
    "    peptides = pd.read_csv(fpath, index_col=0, dtype=d_dtypes_training_sample)\n",
    "    return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED: int = 42  # Random seed for reproducibility\n",
    "\n",
    "FEAT_COMPLETNESS_CUTOFF = 0.25 # Minimal proportion of samples which have to share a feature\n",
    "\n",
    "YEARS = ['2017','2018', '2019', '2020']\n",
    "\n",
    "\n",
    "NAME = 'evidence'\n",
    "BASE_NAME = f\"df_intensities_{NAME}_long\"\n",
    "\n",
    "TYPES_DUMP = {'Sample ID': 'category',\n",
    "              'Sequence': 'category',\n",
    "              'Charge': 'category',}\n",
    "\n",
    "TYPES_COUNT = {'Charge': int}\n",
    "\n",
    "IDX_COLS_LONG = ['Sample ID', 'Sequence', 'Charge'] # in order \n",
    "\n",
    "LOAD_DUMP = load_evidence_dump\n",
    "\n",
    "CounterClass = data_objects.EvidenceCounter\n",
    "FNAME_COUNTER = FNAME_C_EVIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'peptides'\n",
    "BASE_NAME = f\"df_intensities_{NAME}_long\"\n",
    "\n",
    "TYPES_DUMP = {'Sample ID': 'category',\n",
    "                  'Sequence': 'category',\n",
    "                  }\n",
    "\n",
    "TYPES_COUNT = {}\n",
    "\n",
    "IDX_COLS_LONG = ['Sample ID', 'Sequence'] # in order \n",
    "\n",
    "LOAD_DUMP = data_objects.load_agg_peptide_dump\n",
    "\n",
    "CounterClass = data_objects.PeptideCounter\n",
    "FNAME_COUNTER = FNAME_C_PEPTIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'proteinGroups'\n",
    "BASE_NAME = f\"df_intensities_{NAME}_long\"\n",
    "\n",
    "TYPES_DUMP = {'Sample ID': 'category',\n",
    "              'Gene names': 'category',\n",
    "                  }\n",
    "\n",
    "TYPES_COUNT = {}\n",
    "\n",
    "IDX_COLS_LONG = ['Sample ID', 'Gene names'] # in order \n",
    "\n",
    "\n",
    "def load_pg_dump(folder):\n",
    "    logger.debug(f\"Load: {folder}\")\n",
    "    df = pd.read_csv(folder, index_col=pg_cols.Gene_names, usecols=use_cols)\n",
    "    return df\n",
    "\n",
    "LOAD_DUMP = data_objects.pg_idx_gene_fct\n",
    "\n",
    "\n",
    "\n",
    "CounterClass = data_objects.GeneCounter\n",
    "FNAME_COUNTER = FNAME_C_GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charged Peptides\n",
    "\n",
    "counter = CounterClass(FNAME_COUNTER)\n",
    "counts = counter.get_df_counts()\n",
    "\n",
    "if TYPES_COUNT:\n",
    "    counts = counts.convert_dtypes().astype({'Charge': int}) #\n",
    "mask = counts['proportion'] >= FEAT_COMPLETNESS_CUTOFF\n",
    "counts.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = counts.loc[mask].set_index(counter.idx_names).sort_index().index\n",
    "# selected_features.name = 'Gene names' # needs to be fixed\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dumps = select_files_by_parent_folder(list(counter.dumps.values()), years=YEARS)\n",
    "print(\"Total number of files:\", len(selected_dumps))\n",
    "selected_dumps[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_DUMP(selected_dumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from pandas.errors import EmptyDataError\n",
    "def process_folders(fpaths: List[Path],\n",
    "                    selected_features: pd.Index,\n",
    "                    load_folder: Callable,\n",
    "                    id_col='Sample ID',\n",
    "                    dtypes: dict = {\n",
    "                        'Sample ID': 'category',\n",
    "                        'Sequence': 'category'}) -> tuple:\n",
    "    print(f\"started new process with {len(fpaths)} files.\")\n",
    "    data_intensity = []\n",
    "    for i, fpath in enumerate(fpaths):\n",
    "        if not i % 10: print(f\"File ({i}): {fpath}\")\n",
    "        sample_name = fpath.stem\n",
    "        try:\n",
    "            dump = load_folder(fpath)\n",
    "        except EmptyDataError:\n",
    "            logging.warning(f'Empty dump: {fpath}')\n",
    "            continue\n",
    "        except FileNotFoundError:\n",
    "            logging.warning(f'Missing dump: {fpath}')\n",
    "            continue\n",
    "        sequences_available = dump.index.intersection(selected_features)\n",
    "        dump = dump.loc[sequences_available, 'Intensity'].reset_index()\n",
    "        dump[id_col] = sample_name\n",
    "        dump = dump.astype(dtypes)\n",
    "        data_intensity.append(dump)\n",
    "    \n",
    "    data_intensity = pd.concat(data_intensity, copy=False, ignore_index=True)\n",
    "    data_intensity = data_intensity.astype(dtypes)\n",
    "    return data_intensity\n",
    "\n",
    "# # experiment\n",
    "# process_folders(selected_dumps[:2],\n",
    "#                 selected_features=selected_features,\n",
    "#                 load_folder=LOAD_DUMP,\n",
    "#                 dtypes=TYPES_DUMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "process_folders_peptides = functools.partial(process_folders,\n",
    "                                             selected_features=selected_features,\n",
    "                                             load_folder=LOAD_DUMP,\n",
    "                                             dtypes=TYPES_DUMP)\n",
    "collected_dfs = data_objects.collect_in_chuncks(paths=selected_dumps,\n",
    "                                                process_chunk_fct=process_folders_peptides,\n",
    "                                                chunks=200,\n",
    "                                                n_workers=1 # to debug, don't multiprocess\n",
    "                                               )\n",
    "\n",
    "# one would need to aggregate categories first to keep them during aggregation?\n",
    "collected_dfs = pd.concat(collected_dfs, copy=False, ignore_index=True)\n",
    "collected_dfs = collected_dfs.astype(TYPES_DUMP)\n",
    "df_intensities = collected_dfs\n",
    "df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities = df_intensities.set_index(IDX_COLS_LONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(selected_features)\n",
    "N = len(selected_dumps)\n",
    "N,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = f'{BASE_NAME}_' + '_'.join(YEARS)\n",
    "fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.pkl', shape=(N,M))\n",
    "print(f\"{fname = }\")\n",
    "df_intensities.to_pickle(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_intensities = df_intensities.unstack(['Sample ID'])\n",
    "# df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_intensities.sort_index(inplace=True)\n",
    "# base_name = \"df_intensities_evidence_long\" + '_'.join(YEARS)\n",
    "# fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.csv', shape=(N,M))\n",
    "# print(f\"{fname = }\")\n",
    "# df_intensities.to_csv(fname)\n",
    "# df_intensities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
