{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a set of training data\n",
    "\n",
    "Use a set of (most) common peptides to create inital data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import random  # shuffle, seed\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import src.config as config\n",
    "from src.config import FOLDER_PROCESSED\n",
    "import vaep.io\n",
    "from vaep.io import data_objects\n",
    "\n",
    "from src.config import FNAME_C_PEPTIDES, FNAME_C_EVIDENCE, FNAME_C_PG, FNAME_C_GENES\n",
    "\n",
    "FNAME_C_PEPTIDES, FNAME_C_EVIDENCE, FNAME_C_PG, FNAME_C_GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N: int = 10_000  # Number of max samples\n",
    "RANDOM_SEED: int = 42  # Random seed for reproducibility\n",
    "\n",
    "FEAT_COMPLETNESS_CUTOFF = 0.25 # Minimal proportion of samples which have to share a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charged Peptides\n",
    "\n",
    "counter = data_objects.EvidenceCounter(FNAME_C_EVIDENCE)\n",
    "counts = counter.get_df_counts()\n",
    "counts = counts.convert_dtypes().astype({'Charge': int})\n",
    "mask = counts['proportion'] >= FEAT_COMPLETNESS_CUTOFF\n",
    "counts.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_evidence = counts.loc[mask].set_index(counter.idx_names).sort_index().index\n",
    "selected_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = list(counter.dumps.values())\n",
    "\n",
    "\n",
    "def load_evidence_dump(fpath, index_col=counter.idx_names):\n",
    "    df = pd.read_csv(fpath, index_col=index_col)\n",
    "    return df\n",
    "\n",
    "load_evidence_dump(dumps[0])\n",
    "\n",
    "# counter.load_dump(dumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dumps = []\n",
    "years = ['2018', '2019']\n",
    "for year_folder in years:\n",
    "    selected_dumps += [dump for dump in dumps if year_folder in dump.parent.stem]\n",
    "print(\"Total number of files:\", len(selected_dumps))\n",
    "selected_dumps[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # current limit ~4000 files on erda (16GB of memory)\n",
    "# N = min(len(selected_dumps), N)\n",
    "\n",
    "# data_intensity = {}\n",
    "# # data_genes = {}\n",
    "# support = {}\n",
    "\n",
    "# load_dump = load_evidence_dump\n",
    "# selected_features = selected_evidence\n",
    "\n",
    "# for fpath in tqdm(selected_dumps[:N]):\n",
    "#     sample_name = fpath.stem\n",
    "#     dump = load_dump(fpath)\n",
    "#     sequences_available = dump.index.intersection(selected_features)\n",
    "#     support[sample_name] = len(sequences_available)\n",
    "#     data_intensity[sample_name] = dump.loc[sequences_available,\n",
    "#                                                'Intensity'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# N = 100\n",
    "N = min(len(selected_dumps), N)\n",
    "\n",
    "data_intensity = {}\n",
    "\n",
    "load_dump = load_evidence_dump\n",
    "selected_features = selected_evidence\n",
    "\n",
    "import functools\n",
    "from typing import List, Callable\n",
    "\n",
    "def process_folders(fpaths: List[Path],\n",
    "                    selected_features: pd.Index,\n",
    "                    load_folder: Callable)-> tuple:\n",
    "\n",
    "    data_intensity = {}\n",
    "    print(\"started new process.\")\n",
    "    for fpath in fpaths:\n",
    "        print(fpath)\n",
    "        sample_name = fpath.stem\n",
    "        dump = load_dump(fpath)\n",
    "        sequences_available = dump.index.intersection(selected_features)\n",
    "        data_intensity[sample_name] = dump.loc[sequences_available,\n",
    "                                               'Intensity'].to_dict()\n",
    "    return pd.DataFrame.from_dict(data_intensity).T\n",
    "\n",
    "\n",
    "process_folders_peptides = functools.partial(selected_dumps,\n",
    "                                             selected_features=selected_evidence,\n",
    "                                             load_folder=load_evidence_dump)\n",
    "collected_data_intensities = data_objects.collect_in_chuncks(paths=dumps,\n",
    "                                                             process_chunk_fct=process_folders_peptides,\n",
    "                                                             chunks=200)\n",
    "\n",
    "\n",
    "collected_dfs = pd.concat(collected_dfs)\n",
    "df_intensities = collected_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities.columns.names = counter.idx_names\n",
    "df_intensities.index.name = 'Sample ID'\n",
    "df_intensities.sort_index(inplace=True)\n",
    "base_name = \"df_intensities_evidence_\" + '_'.join(years)\n",
    "fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.csv')\n",
    "print(f\"{fname = }\")\n",
    "df_intensities.to_csv(fname)\n",
    "df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"df_intensities_evidence_long\" + '_'.join(years)\n",
    "fname = config.FOLDER_DATA / config.insert_shape(df_intensities, base_name + '{}.csv')\n",
    "print(f\"{fname = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities = df_intensities.stack([0,1])\n",
    "df_intensities.index = df_intensities.index.astype(pd.CategoricalDtype)\n",
    "df_intensities.name = 'Intensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities.to_csv(fname)\n",
    "df_intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_counter = data_objects.PeptideCounter(FNAME_C_PEPTIDES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_counts = peptide_counter.get_df_counts()\n",
    "mask = peptide_counts['proportion'] >= FEAT_COMPLETNESS_CUTOFF\n",
    "peptide_counts.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_peptides = peptide_counts.loc[mask].set_index('Sequence').index\n",
    "selected_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = list(peptide_counter.dumps.values())\n",
    "\n",
    "peptides = data_objects.load_agg_peptide_dump(dumps[0])\n",
    "peptides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N = min(len(dumps), N)\n",
    "\n",
    "data_intensity = {}\n",
    "support = {}\n",
    "# again with multiprocessing? await functions?\n",
    "for fp_training_sample in tqdm(dumps[:N]):\n",
    "    sample_name = fp_training_sample.stem\n",
    "    peptides = data_objects.load_agg_peptide_dump(fp_training_sample)\n",
    "    sequences_available = peptides.index.intersection(selected_peptides)\n",
    "    support[sample_name] = len(sequences_available)\n",
    "    data_intensity[sample_name] = peptides.loc[sequences_available,\n",
    "                                               'Intensity'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensities = pd.DataFrame.from_dict(data_intensity).T\n",
    "df_intensities.index.name = 'Sample ID'\n",
    "df_intensities.sort_index(inplace=True)\n",
    "df_intensities.to_csv(config.FOLDER_DATA /\n",
    "                      config.insert_shape(df_intensities, 'df_intensities{}.csv'))\n",
    "df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.FOLDER_DATA /\n",
    "          config.insert_shape(df_intensities, 'support_agg_peptides{}.json'), 'w') as f:\n",
    "    json.dump(support, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
