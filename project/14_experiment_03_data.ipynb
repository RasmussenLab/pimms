{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 03 - Data\n",
    "\n",
    "Create data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import logging\n",
    "import typing\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from src.nb_imports import *\n",
    "\n",
    "import vaep.io_images\n",
    "from vaep.pandas import interpolate\n",
    "from vaep.io.datasplits import DataSplits\n",
    "from vaep.sampling import feature_frequency, frequency_by_index, sample_data\n",
    "\n",
    "import src\n",
    "from src.logging import setup_logger\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 03 - data\")\n",
    "\n",
    "figures = {}  # collection of ax or figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "FN_PEPTIDE_INTENSITIES: str = 'data/df_intensities_N07285_M01000'  # Samples\n",
    "index_col: typing.Union[str,int] = 'Sample ID' # Can be either a string or position (typical 0 for first column)\n",
    "# query expression for subsetting\n",
    "query_subset_meta: str = 'ms_instrument in [\"QE4\", ]'\n",
    "experiment_folder: str = 'data'\n",
    "columns_name: str = 'peptide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"Documentation. Copy pasted arguments to a dataclass.\"\"\"\n",
    "    FN_PEPTIDE_INTENSITIES: str = \"data/df_intensities_N07285_M01000\"  # Samples\n",
    "    index_col: typing.Union[\n",
    "        str, int\n",
    "    ] = \"Sample ID\"  # Can be either a string or position (typical 0 for first column)\n",
    "    # query expression for subsetting\n",
    "    query_subset_meta: str = 'ms_instrument in [\"QE4\", ]'\n",
    "    experiment_folder: str = \"data\"\n",
    "    columns_name: str = \"peptide\"\n",
    "\n",
    "\n",
    "params = DataConfig(\n",
    "    FN_PEPTIDE_INTENSITIES=FN_PEPTIDE_INTENSITIES,\n",
    "    index_col=index_col,\n",
    "    query_subset_meta=query_subset_meta,\n",
    "    experiment_folder=experiment_folder,\n",
    "    columns_name=columns_name\n",
    ")\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "# OmegaConf.create(cfg)\n",
    "params = OmegaConf.create(params.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"{FN_PEPTIDE_INTENSITIES = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printable = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ '\n",
    "\n",
    "\n",
    "def parse_query_expression(s, printable=printable):\n",
    "    return ''.join(filter(lambda x: x in printable, s))\n",
    "\n",
    "\n",
    "if not experiment_folder:\n",
    "    experiment_folder = query_subset_meta.replace('_', ' ')\n",
    "    experiment_folder = parse_query_expression(experiment_folder)\n",
    "    experiment_folder = experiment_folder.strip()\n",
    "    experiment_folder = experiment_folder.replace(' ', '_')\n",
    "    params.experiment_folder\n",
    "experiment_folder = Path(experiment_folder)\n",
    "logger.info(f'Folder for output = {experiment_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = AnalyzePeptides.from_file(fname=FN_PEPTIDE_INTENSITIES, nrows=None, index_col=index_col)\n",
    "analysis.df.columns.name = columns_name\n",
    "analysis.log_transform(np.log2)\n",
    "logger.info(f\"{analysis = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename some samples\n",
    "- [ ] needs to be moved into the data extraction pipeline from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date are not possible in the indices\n",
    "rename_indices_w_wrong_dates = {'20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_03': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_03',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_12': '20180330_QE10_nLC0_MR_QC_MNT_Hela_12',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_01': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_01',\n",
    "                                '20180230_QE10_nLC0_MR_QC_MNT_Hela_11': '20180330_QE10_nLC0_MR_QC_MNT_Hela_11',\n",
    "                                '20161131_LUMOS1_nLC13_AH_MNT_HeLa_long_02': '20161130_LUMOS1_nLC13_AH_MNT_HeLa_long_02'}\n",
    "analysis.df.rename(index=rename_indices_w_wrong_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N consecutive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert analysis.df.index.is_unique, \"Duplicates in index\"\n",
    "analysis.df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.add_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta['datetime'] = pd.to_datetime(\n",
    "    analysis.df_meta.date, format=\"%Y/%m/%d\")  # persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_meta = analysis.df_meta.query(query_subset_meta)\n",
    "analysis.df_meta.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select proteomics data based on meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df = analysis.df.loc[analysis.df_meta.index]\n",
    "analysis.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot of raw data\n",
    "- biological stock differences in PCA plot. Show differences in models. Only see biological variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis.plot_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.io_images._savefig(\n",
    "    fig, f'pca_plot_raw_data_{analysis.fname_stub}', folder=experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots need to become interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split: Train, validation and test data\n",
    "\n",
    "- test data is in clinical language often denoted as independent validation cohort\n",
    "- validation data (for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.splits = DataSplits(is_wide_format=True)\n",
    "splits = analysis.splits\n",
    "print(f\"{analysis.splits = }\")\n",
    "analysis.splits.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = (0.8, 0.9)  # change here\n",
    "\n",
    "percent_str = [f'{int(x*100)}%' for x in percentiles]\n",
    "split_at_date = analysis.df_meta['datetime'].describe(\n",
    "    datetime_is_numeric=True, percentiles=(0.8, 0.9)).loc[percent_str]\n",
    "split_at_date = tuple(pd.Timestamp(t.date()) for t in split_at_date)\n",
    "\n",
    "print(f\"{split_at_date[0] = }\", f\"{split_at_date[1] = }\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = analysis.df_meta['datetime'] < split_at_date[0]\n",
    "analysis.splits.train_X = analysis.df.loc[idx_train]\n",
    "analysis.splits.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_validation = ((analysis.df_meta['datetime'] >= split_at_date[0]) & (\n",
    "    analysis.df_meta['datetime'] < split_at_date[1]))\n",
    "analysis.splits.val_X = analysis.df.loc[idx_validation]\n",
    "analysis.splits.val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = (analysis.df_meta['datetime'] >= split_at_date[1])\n",
    "# analysis.df_test =\n",
    "analysis.splits.test_X = analysis.df.loc[idx_test]\n",
    "analysis.splits.test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test_na = analysis.splits.test_X.stack(\n",
    "    dropna=False).loc[splits.test_X.isna().stack()].index\n",
    "print(f\"number of missing values in test data: {len(idx_test_na)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add goldstandard targets for valiation and test data\n",
    "- based on same day\n",
    "- same instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.val_y = interpolate(splits.val_X)\n",
    "splits.test_y = interpolate(splits.test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA values not imputed using other data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_still_na = idx_test_na.difference(splits.test_y.index)\n",
    "if not idx_still_na.empty:\n",
    "    logger.info(idx_still_na.to_list())\n",
    "else:\n",
    "    logger.info(\"all missing values imputed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save in long format\n",
    "\n",
    "- Data in long format: (peptide, sample_id, intensity)\n",
    "- no missing values kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = experiment_folder / 'data'# possibly avoid duplication?\n",
    "\n",
    "# currently val_y and test_y are in long format, while all *_X are in wide format\n",
    "# dump transforms all into long-format\n",
    "\n",
    "splits.dump(folder=folder)  # dumps data in long-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling peptides by their frequency (important for later)\n",
    "\n",
    "- higher count, higher probability to be sampled into training data\n",
    "- missing peptides are sampled both into training as well as into validation dataset\n",
    "- everything not in training data is validation data\n",
    "\n",
    "Based on unmodified training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section does work with data loaded from dumps in long-format\n",
    "# start with single view of all data (i.e. in long-format)\n",
    "analysis.splits = DataSplits.from_folder(folder=folder)\n",
    "analysis.splits.to_wide_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_per_peptide = feature_frequency(analysis.splits.train_X)\n",
    "\n",
    "analysis.splits.to_long_format()\n",
    "assert all(frequency_by_index(df_long=analysis.splits.train_X,\n",
    "           sample_index_to_drop=0) == freq_per_peptide)\n",
    "\n",
    "freq_per_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Total number of samples in training data split: {}\"\n",
    "print(msg.format(len(analysis.splits.train_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_per_peptide.to_csv(folder / 'freq_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_sampled, series_not_sampled = sample_data(analysis.splits.test_X, 0)\n",
    "# in test_sampling:\n",
    "# assert len(analysis.splits.test_X) == len(\n",
    "#     series_sampled) + len(series_not_sampled)\n",
    "# assert analysis.splits.test_X.index.difference(\n",
    "#     series_sampled.index.append(series_not_sampled.index)).empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conserning sampling with frequency weights:\n",
    "  - larger weight -> higher probablility of being sampled\n",
    "  - weights need to be alignable to index of original DataFrame before grouping (same index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_selected = 'YYVTIIDAPGHR'\n",
    "freq_per_peptide.loc[peptide_selected] = 0  # non should be sampled\n",
    "freq_per_peptide.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# set one peptide weights to 0 and affirm that they are only in the not sample series\n",
    "series_sampled, series_not_sampled = sample_data(\n",
    "    analysis.splits.test_X, 0, weights=freq_per_peptide)\n",
    "\n",
    "series_not_sampled.loc[pd.IndexSlice[:, [peptide_selected]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex Hints\n",
    "\n",
    "- use mulitindex for obtaining validation split\n",
    "\n",
    "[[stackoverflow](https://stackoverflow.com/questions/53927460/select-rows-in-pandas-multiindex-dataframe), [guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html)]\n",
    "\n",
    "- [`xs` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.xs.html) or [`pd.IndexSlice`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IndexSlice.html?highlight=indexslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name_1, sample_name_2 = analysis.df_long.sample(2).index.get_level_values(-1).to_list()\n",
    "sample_name_1, sample_name_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long.loc[pd.IndexSlice[:, sample_name_1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.df_long.loc[(slice(None), sample_name_2), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a series the syntax changes slightly (no column) and the indexing behaviour different if a string or a list is passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = analysis.df_long.squeeze()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[pd.IndexSlice[:, sample_name_2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[pd.IndexSlice[:, [sample_name_2]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(experiment_folder/'data_config.yaml', 'w') as f:\n",
    "    OmegaConf.save(params, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca718f398b3a596c3df6787ca2afa269ec54c58eb9478d66aeb41db8e6cb8262"
  },
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
