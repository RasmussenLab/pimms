{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e1208b-9b36-4294-b3fd-910e05a82f2e",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5d571-2956-4112-b22c-43d6c2146b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from fastai.collab import *\n",
    "\n",
    "# overwriting Recorder callback with custom plot_loss\n",
    "from vaep.models import plot_loss, RecorderDump, calc_net_weight_count\n",
    "from fastai import learner\n",
    "learner.Recorder.plot_loss = plot_loss\n",
    "# import fastai.callback.hook # Learner.summary\n",
    "\n",
    "\n",
    "import vaep\n",
    "import vaep.model\n",
    "import vaep.models as models\n",
    "from vaep.io import datasplits\n",
    "from vaep import sampling\n",
    "\n",
    "\n",
    "import vaep.nb\n",
    "from vaep.logging import setup_logger\n",
    "logger = setup_logger(logger=logging.getLogger('vaep'))\n",
    "logger.info(\"Experiment 03 - Analysis of latent spaces and performance comparisions\")\n",
    "\n",
    "figures = {}  # collection of ax or figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f062bb-8d2c-4afa-8a81-9e2a328050fe",
   "metadata": {},
   "source": [
    "Papermill script parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch passed parameters\n",
    "args = None\n",
    "args = dict(globals()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f14bc-3c37-43fa-8217-f790f0593d78",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# files and folders\n",
    "folder_experiment:str = 'runs/example' # Datasplit folder with data for experiment\n",
    "folder_data:str = '' # specify data directory if needed\n",
    "file_format: str = 'pkl' # change default to pickled files\n",
    "fn_rawfile_metadata: str = 'data/dev_datasets/HeLa_6070/files_selected_metadata_N50.csv' # Machine parsed metadata from rawfile workflow\n",
    "# training\n",
    "epochs_max:int = 20  # Maximum number of epochs\n",
    "# early_stopping:bool = True # Wheather to use early stopping or not\n",
    "batch_size:int = 32_768 # Batch size for training (and evaluation)\n",
    "cuda:bool=True # Use the GPU for training?\n",
    "# model\n",
    "latent_dim:int = 10 # Dimensionality of encoding dimension (latent space of model)\n",
    "# hidden_layers:str = '128_64' # A space separated string of layers, '50 20' for the encoder, reverse will be use for decoder\n",
    "sample_idx_position: int = 0 # position of index which is sample ID\n",
    "model: str = 'CF' # model name\n",
    "model_key: str = 'CF' # potentially alternative key for model (grid search)\n",
    "save_pred_real_na:bool=True # Save all predictions for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b284f5-55cc-4a2c-bb72-31828888bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_experiment = \"runs/experiment_03/df_intensities_peptides_long_2017_2018_2019_2020_N05011_M42725/Q_Exactive_HF_X_Orbitrap_Exactive_Series_slot_#6070\"\n",
    "# folder_experiment = \"runs/experiment_03/df_intensities_evidence_long_2017_2018_2019_2020_N05015_M49321/Q_Exactive_HF_X_Orbitrap_Exactive_Series_slot_#6070\"\n",
    "# epochs_max = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8e04b-2eb2-4ecb-b1d1-2de871cd0a56",
   "metadata": {},
   "source": [
    "Some argument transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746e70f-0259-48d5-90ef-25fe4b59f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vaep.nb.get_params(args, globals=globals())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bbf80",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "args = vaep.nb.args_from_dict(args)\n",
    "\n",
    "# # Currently not needed -> DotProduct used, not a FNN\n",
    "# if isinstance(args.hidden_layers, str):\n",
    "#     args.overwrite_entry(\"hidden_layers\", [int(x) for x in args.hidden_layers.split('_')])\n",
    "# else:\n",
    "#     raise ValueError(f\"hidden_layers is of unknown type {type(args.hidden_layers)}\")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59f6d8-9cb1-461a-8d62-2ab4458cab60",
   "metadata": {},
   "source": [
    "Some naming conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19fe098-a029-4f71-b7fb-e652a9c16ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_MODEL_PARAMS = 'model_params_{}.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cc005-0c5f-4e88-9656-c549e613ca68",
   "metadata": {},
   "source": [
    "## Load data in long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cc7bd-6b6f-40b9-8db7-c8228e4b03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasplits.DataSplits.from_folder(args.data, file_format=args.file_format) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca12fc2-bf34-42ac-99b2-a78ff9fe7722",
   "metadata": {},
   "source": [
    "data is loaded in long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb6bf5-0eb1-4c73-9723-414b14eaf7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_X.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045414b",
   "metadata": {},
   "source": [
    "Infer index names from long format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44958473",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_columns = list(data.train_X.index.names)\n",
    "sample_id = index_columns.pop(args.sample_idx_position)\n",
    "if len(index_columns) == 1: \n",
    "    index_column = index_columns.pop()\n",
    "    index_columns = None\n",
    "    logger.info(f\"{sample_id = }, single feature: {index_column = }\")\n",
    "else:\n",
    "    logger.info(f\"{sample_id = }, multiple features: {index_columns = }\")\n",
    "\n",
    "if not index_columns:\n",
    "    index_columns = [sample_id, index_column]\n",
    "else:\n",
    "    raise NotImplementedError(\"More than one feature: Needs to be implemented. see above logging output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ae06d-64dd-4f4f-abde-8485a8c8458e",
   "metadata": {},
   "source": [
    "load meta data for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b945aa-9b4e-4487-8b09-dca289e64d9d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(args.fn_rawfile_metadata, index_col=0)\n",
    "df_meta.loc[data.train_X.index.levels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef773a-5588-4b11-9bd7-840b628eeaff",
   "metadata": {},
   "source": [
    "## Initialize Comparison\n",
    "\n",
    "- replicates idea for truely missing values: Define truth as by using n=3 replicates to impute\n",
    "  each sample\n",
    "- real test data:\n",
    "    - Not used for predictions or early stopping.\n",
    "    - [x] add some additional NAs based on distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f675b6-e619-45b6-8f04-b75237d212a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_peptides = sampling.frequency_by_index(data.train_X, 0)\n",
    "freq_peptides.head() # training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02afb4e-ee91-4753-a118-7fa20fe621c9",
   "metadata": {},
   "source": [
    "### Produce some addional fake samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5763b-00fe-44ce-9dfa-b6e506045762",
   "metadata": {},
   "source": [
    "The validation fake NA is used to by all models to evaluate training performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eebaff-0e1e-4e44-ae40-12d2f0e75c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_fake_na = data.val_y.to_frame(name='observed')\n",
    "val_pred_fake_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797a539-84d9-430a-8d16-7cc0eebfe9f5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_pred_fake_na = data.test_y.to_frame(name='observed')\n",
    "test_pred_fake_na.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ea8e9-7f48-4f72-b013-7010666aa1a2",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "- save custom collab batch size (increase AE batch size by a factor), could be setup separately.\n",
    "- the test data is used to evaluate the performance after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee54305-266a-479a-b677-f151ddde250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger mini-batches speed up training\n",
    "ana_collab = models.collab.CollabAnalysis(\n",
    "    datasplits=data,\n",
    "    sample_column=sample_id,\n",
    "    item_column=index_column, # not generic\n",
    "    target_column='intensity',\n",
    "    model_kwargs=dict(n_factors=args.latent_dim,\n",
    "                    y_range=(int(data.train_X.min()),\n",
    "                                int(data.train_X.max())+1)\n",
    "                    ),\n",
    "    batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffa243-151e-4220-a1d5-247f8aba3429",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Args:\")\n",
    "pprint(ana_collab.model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02e061-6789-4f3d-8031-a40879c496c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_collab.model = EmbeddingDotBias.from_classes(\n",
    "    classes=ana_collab.dls.classes,\n",
    "    **ana_collab.model_kwargs)\n",
    "\n",
    "args.n_params = models.calc_net_weight_count(ana_collab.model)\n",
    "ana_collab.params['n_parameters'] = args.n_params\n",
    "ana_collab.learn = Learner(dls=ana_collab.dls, model=ana_collab.model, loss_func=MSELossFlat(),\n",
    "                           cbs=EarlyStoppingCallback(patience=1),\n",
    "                           model_dir=args.out_models)\n",
    "if args.cuda:\n",
    "    ana_collab.learn.model = ana_collab.learn.model.cuda()\n",
    "# learn.summary() # see comment at DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a7346-0b44-44a4-b995-d655e05656f8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317c9e1-d128-4ab4-8d60-775cb85ef535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# papermill_description=train_collab\n",
    "suggested_lr = ana_collab.learn.lr_find()\n",
    "print(f\"{suggested_lr.valley = :.5f}\")\n",
    "ana_collab.learn.fit_one_cycle(args.epochs_max, lr_max=suggested_lr.valley)\n",
    "args.epoch_trained = ana_collab.learn.epoch + 1\n",
    "# ana_collab.learn.fit_one_cycle(args.epochs_max, lr_max=1e-3)\n",
    "ana_collab.model_kwargs['suggested_inital_lr'] = suggested_lr.valley\n",
    "ana_collab.learn.save('collab_model')\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.set_title('CF loss: Reconstruction loss')\n",
    "ana_collab.learn.recorder.plot_loss(skip_start=5, ax=ax)\n",
    "recorder_dump = RecorderDump(\n",
    "    recorder=ana_collab.learn.recorder, name='CF')\n",
    "recorder_dump.save(args.out_figures)\n",
    "del recorder_dump\n",
    "vaep.savefig(fig, name='collab_training',\n",
    "                folder=args.out_figures)\n",
    "ana_collab.model_kwargs['batch_size'] = ana_collab.batch_size\n",
    "vaep.io.dump_json(ana_collab.model_kwargs, args.out_models /\n",
    "                    TEMPLATE_MODEL_PARAMS.format('CF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979b7f0-a673-4d3d-9d53-6ac02618eaed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee5b225-d50a-4189-9995-ad99c4d47a45",
   "metadata": {},
   "source": [
    "Compare fake_na data predictions to original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76e6c5-e135-41c4-95e8-a56c3764c731",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# this could be done using the validation data laoder now\n",
    "ana_collab.test_dl = ana_collab.dls.test_dl(data.val_y.reset_index())  # test_dl is here validation data\n",
    "val_pred_fake_na['CF'], _ = ana_collab.learn.get_preds(\n",
    "    dl=ana_collab.test_dl)\n",
    "val_pred_fake_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22f63f-be3f-4f25-ad60-bafd6b028bd7",
   "metadata": {},
   "source": [
    "select test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0c597-d3c7-42d0-a6ef-3bc4c13121b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_collab.test_dl = ana_collab.dls.test_dl(data.test_y.reset_index())\n",
    "test_pred_fake_na['CF'], _ = ana_collab.learn.get_preds(dl=ana_collab.test_dl)\n",
    "test_pred_fake_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd76df6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if args.save_pred_real_na:\n",
    "    pred_real_na = models.collab.get_missing_values(\n",
    "        df_train_long=data.train_X,\n",
    "        val_idx=data.val_y.index,\n",
    "        test_idx=data.test_y.index, \n",
    "        analysis_collab=ana_collab)\n",
    "    pred_real_na.to_csv(args.out_preds / f\"pred_real_na_{args.model_key}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eced7a-6cd7-414e-b974-4bd1dbe3a787",
   "metadata": {},
   "source": [
    "## Data in wide format\n",
    "\n",
    "- Autoencoder need data in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8caf4-ccc9-4a36-a992-2cc596abe51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_wide_format()\n",
    "args.M = data.train_X.shape[-1]\n",
    "data.train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc46767-49c9-487e-bf2d-19aacc9114c3",
   "metadata": {},
   "source": [
    "### Add interpolation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e63726-f163-4007-81f9-ee12b1e35fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated = vaep.pandas.interpolate(wide_df = data.train_X) \n",
    "val_pred_fake_na['interpolated'] = interpolated\n",
    "test_pred_fake_na['interpolated'] = interpolated\n",
    "del interpolated\n",
    "test_pred_fake_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f16d62-f1c8-4447-bdd3-2d3161b6346f",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "> Note: The interpolated values have less predictions for comparisons than the ones based on models (CF, DAE, VAE)  \n",
    "> The comparison is therefore not 100% fair as the interpolated samples will have more common ones (especailly the sparser the data)  \n",
    "> Could be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b9b3c-11d0-4cda-98c9-fadea16e47c4",
   "metadata": {},
   "source": [
    "### Validation data\n",
    "\n",
    "- all measured (identified, observed) peptides in validation data\n",
    "\n",
    "> Does not make to much sense to compare collab and AEs,  \n",
    "> as the setup differs of training and validation data differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825e38e-f3d6-4bca-b621-150267e7b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# papermill_description=metrics\n",
    "d_metrics = models.Metrics(no_na_key='NA interpolated', with_na_key='NA not interpolated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9b887-a644-4086-8399-e27b533bd22a",
   "metadata": {},
   "source": [
    "The fake NA for the validation step are real test data (not used for training nor early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a7a6f-93fd-4612-9d8d-96541a2441be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "added_metrics = d_metrics.add_metrics(val_pred_fake_na, 'valid_fake_na')\n",
    "added_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fda7f1-3024-46bc-a3c1-17f509016bd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test Datasplit\n",
    "\n",
    "Fake NAs : Artificially created NAs. Some data was sampled and set explicitly to misssing before it was fed to the model for reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ac8d4-bb5d-45db-bba8-59817e476304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "added_metrics = d_metrics.add_metrics(test_pred_fake_na, 'test_fake_na')\n",
    "added_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388de9d-0387-486a-9481-d673e0fec88b",
   "metadata": {},
   "source": [
    "Save all metrics as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87910434-7d07-4e8e-8380-c92fc515bd16",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaep.io.dump_json(d_metrics.metrics, args.out_metrics / f'metrics_{args.model_key}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99deb9-9aad-4ba9-b79d-e4b3c6c7f023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = models.get_df_from_nested_dict(d_metrics.metrics).T\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2c775-22b2-4169-9345-852d25564169",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414171e0-83d5-407c-98c0-8ab544e6b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_view = metrics_df.stack().unstack(-2).set_index('N', append=True)\n",
    "plotly_view.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144d54a-fc7b-4967-bfdb-e32ae46ca788",
   "metadata": {},
   "source": [
    "#### Fake NA which could be interpolated\n",
    "\n",
    "- bulk of validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ffdac-5131-42e6-951f-6db4f7016e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_view.loc[pd.IndexSlice[:, :, 'NA interpolated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9af56-6a0d-4cf9-9a0f-a7ec4142ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'NA interpolated'\n",
    "fig = px.scatter(plotly_view.loc[pd.IndexSlice[:, :, subset]].stack().to_frame('metric_value').reset_index(),\n",
    "                 x=\"data_split\",\n",
    "                 y='metric_value',\n",
    "                 color=\"model\",\n",
    "                 facet_row=\"metric_name\",\n",
    "                 # facet_col=\"subset\",\n",
    "                 hover_data='N',\n",
    "                 title=f'Performance for {subset}',\n",
    "                 labels={\"data_split\": \"data\",\n",
    "                         \"metric_value\": '', 'metric_name': 'metric'},\n",
    "                 height=500,\n",
    "                 width=300,\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcbcb2-5094-4d78-8a07-0e039e8d493f",
   "metadata": {},
   "source": [
    "#### Fake NA which could not be interpolated\n",
    "\n",
    "- small fraction of total validation and test data\n",
    "\n",
    "> not interpolated fake NA values are harder to predict for models  \n",
    "> Note however: fewer predicitons might mean more variability of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554dff6-9e36-4444-9b82-dec2e2219da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_view.loc[pd.IndexSlice[:, :, 'NA not interpolated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04efd95-4b02-43ec-9efb-4150f07ef430",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'NA not interpolated'\n",
    "fig = px.scatter(plotly_view.loc[pd.IndexSlice[:, :, subset]].stack().to_frame('metric_value').reset_index(),\n",
    "                 x=\"data_split\",\n",
    "                 y='metric_value',\n",
    "                 color=\"model\",\n",
    "                 facet_row=\"metric_name\",\n",
    "                 # facet_col=\"subset\",\n",
    "                 hover_data='N',\n",
    "                 title=f'Performance for {subset}',\n",
    "                 labels={\"data_split\": \"data\",\n",
    "                         \"metric_value\": '', 'metric_name': 'metric'},\n",
    "                 height=500,\n",
    "                 width=300,\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d6b3e-1316-4795-bc3d-4bdf270b890e",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782636ac-c979-4f8b-9fc0-66fd0c7a3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save simulated missing values for both splits\n",
    "val_pred_fake_na.to_csv(args.out_preds / f\"pred_val_{args.model_key}.csv\")\n",
    "test_pred_fake_na.to_csv(args.out_preds / f\"pred_test_{args.model_key}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2c184-e9ef-42be-ae87-7cbf52a0c0b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13cb38-abf0-4b56-9399-3d11d32f7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dump(fname=args.out_models/ f\"model_config_{args.model_key}.yaml\")\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b261a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "cf83e9cb890c7f96eb0ae04f39a82254555f56a1a0ed2f03b23a8b40fe6cd31c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
