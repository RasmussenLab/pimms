{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse peptides\n",
    "\n",
    "## Specification\n",
    "- access different levels of peptides easily\n",
    "- select training data per gene easily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "logging.basicConfig(level=logging.INFO) # configures root logger\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src/config import FN_FASTA_DB, FN_ID_MAP, FN_PEPTIDE_INTENSITIES, FN_PEPTIDE_STUMP, FOLDER_DATA\n",
    "\n",
    "pd.options.display.float_format = '{:,.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = pd.read_json(FN_ID_MAP, orient=\"split\")\n",
    "\n",
    "mask_no_gene = id_map.gene.isna()\n",
    "id_map.loc[mask_no_gene, \"gene\"] = \"-\"\n",
    "\n",
    "with open(FN_FASTA_DB) as f:\n",
    "    data_fasta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "l_peptides_files = list(Path(FOLDER_DATA).glob(f\"{FN_PEPTIDE_STUMP}*.pkl\"))\n",
    "assert l_peptides_files, 'No matches found'\n",
    "l_peptides_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides = []\n",
    "for i, file_path in enumerate(l_peptides_files):\n",
    "    _peptides = pd.read_pickle(file_path)\n",
    "    loaded_dtypes =  _peptides.dtypes.unique()\n",
    "    print(f\"Current dtypes: {''.join(str(x) for x in loaded_dtypes)}\\tFile:{file_path}\")\n",
    "    if not isinstance(loaded_dtypes[0], pd.Int64Dtype):\n",
    "        print(f\"try converting data: {file_path}.\")\n",
    "        # # use less specific integer check?\n",
    "        # loaded_dtypes[0].is_signed_integer or loaded_dtypes[0].is_unsigned_integer    \n",
    "        _peptides = _peptides.convert_dtypes()\n",
    "        _peptides.to_pickle(file_path)\n",
    "    data_peptides.append(_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = sum([len(_data) for _data in data_peptides])\n",
    "\n",
    "peptides_intensities = data_peptides.pop(0)\n",
    "\n",
    "while len(data_peptides) > 0:\n",
    "    _data = data_peptides.pop(0)\n",
    "    peptides_intensities = peptides_intensities.append(_data)\n",
    "    del _data\n",
    "\n",
    "assert len(peptides_intensities) == N_total\n",
    "logging.info(\"Loaded {0} samples having a total of {1:,d} peptides.\".format(*peptides_intensities.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid reassambly of data?\n",
    "# data_peptides.to_pickle(FN_PEPTIDE_INTENSITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides = peptides_intensities\n",
    "set(data_peptides.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_peptides = set(data_peptides.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- switch between list of proteins with any support and non\n",
    "    - set threshold of number of peptides per protein over all samples (some peptides uniquely matched to one protein in on sample is just noise -> check razor peptides)\n",
    "- show support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_2 = ('TTGIVMDSGDGVTHTVPIYEGYALPHAILRLDLAGR',\n",
    "                                          'LDLAGRDLTDYLMK')\n",
    "\n",
    "peptides_4 = (   \"ILTERGYSFTTTAEREIVR\",\n",
    "                    \"GYSFTTTAEREIVRDIK\",\n",
    "                              \"EIVRDIKEK\",\n",
    "                                  \"DIKEKLCYVALDFEQEMATAASSSSLEK\")\n",
    "peptides_4[:0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.setLevel(logging.DEBUG)\n",
    "COLORS= [\"\\033[32;2m\", \"\\033[32;1m\", \"0;34;47m\"]\n",
    "def annotate_overlap(peptides):\n",
    "    i = len(peptides)\n",
    "    if i > 3:\n",
    "        raise ValueError(\"Two many peptides provided.\")\n",
    "    logging.debug(f\"First peptide: {peptides[0]} \")\n",
    "    base_peptide = peptides[0][::-1]\n",
    "    logging.debug(f\"Reversed pep:  {base_peptide}\")\n",
    "    colored_part = \"\"\n",
    "    overlaps = []\n",
    "    logging.debug(peptides[:0:-1])\n",
    "    for pep in peptides[:0:-1]:\n",
    "        \n",
    "        logger.debug(f\"Find overlap for: {pep}\")        \n",
    "        overlap = \"\"\n",
    "        overlap_in_last_step = False\n",
    "        for j, amino_acid in enumerate(pep):\n",
    "            overlap += amino_acid\n",
    "            if overlap[::-1] != base_peptide[:len(overlap)]:\n",
    "                overlap_now = False\n",
    "            else:\n",
    "                overlap_in_last_step = True\n",
    "                logger.debug(f\"Found overlap: {overlap}\")\n",
    "            if overlap_in_last_step and not overlap_now:\n",
    "                overlaps.append(overlap)\n",
    "                break\n",
    "        logger.debug(f\"Search remaining peptide: {base_peptide[len(overlap)::]}\")\n",
    "        base_peptide = base_peptide[len(overlap)::]\n",
    "    overlaps.append(base_peptide[::-1])\n",
    "    return overlaps[::-1]\n",
    "\n",
    "assert ''.join(annotate_overlap(peptides_2)) == \"TTGIVMDSGDGVTHTVPIYEGYALPHAILRLDLAGR\" \n",
    "# annotate_overlap(peptides_4) # should raise ValueError\n",
    "assert ''.join(annotate_overlap(peptides_4[0:3])) == 'ILTERGYSFTTTAEREIVR'\n",
    "assert ''.join(annotate_overlap(peptides_4[1:])) == 'GYSFTTTAEREIVRDIK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_0missed =      \"GYSFTTTAER\"\n",
    "pep_1missed = [\"ILTERGYSFTTTAER\",\n",
    "                   \"GYSFTTTAEREIVR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ipywidgets as w\n",
    "from src/config import KEY_FASTA_HEADER, KEY_FASTA_SEQ, KEY_PEPTIDES, KEY_GENE_NAME_FASTA\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "\n",
    "TGREEN = \"\\033[32;2m\"  # Green Text\n",
    "TGREEN_2 = \"\\033[32;1m\"  # Green Text\n",
    "RESET = \"\\033[0;0m\"\n",
    "\n",
    "w_first_letter = w.Dropdown(\n",
    "    options=id_map[KEY_GENE_NAME_FASTA].str[0].unique())\n",
    "\n",
    "w_genes = w.Dropdown(\n",
    "    options=id_map.gene.loc[id_map[KEY_GENE_NAME_FASTA].str[0] == w_first_letter.value].unique(),\n",
    "    value='ACTB'\n",
    ")\n",
    "\n",
    "mask = id_map.gene == w_genes.value\n",
    "selected = id_map.loc[mask, \"protein\"]\n",
    "\n",
    "\n",
    "w_proteins_ids = w.Dropdown(options=selected.index)\n",
    "w_protein = w.Dropdown(options=selected.unique())\n",
    "\n",
    "\n",
    "def update_gene_list(first_letter):\n",
    "    \"\"\"Update proteins when new gene is selected\"\"\"\n",
    "    mask_selected_genes = id_map[KEY_GENE_NAME_FASTA].str[0] == w_first_letter.value\n",
    "    w_genes.options = id_map[KEY_GENE_NAME_FASTA].loc[mask_selected_genes].unique()\n",
    "\n",
    "\n",
    "_ = w.interactive_output(update_gene_list, {\"first_letter\": w_first_letter})\n",
    "\n",
    "\n",
    "def update_protein_list(gene):\n",
    "    mask = id_map[KEY_GENE_NAME_FASTA] == gene\n",
    "    selected = id_map.loc[mask, \"protein\"]\n",
    "    w_protein.options = selected.unique()\n",
    "#     w_proteins_ids.options = selected.loc[selected == w_protein.value].index\n",
    "\n",
    "\n",
    "_ = w.interactive_output(update_protein_list, {\"gene\": w_genes})\n",
    "    \n",
    "\n",
    "def update_protein_id_list(protein):\n",
    "    \"\"\"Update isotope list when protein is selected\"\"\"\n",
    "    mask = id_map.protein == w_protein.value\n",
    "    selected = id_map.protein.loc[mask]\n",
    "    w_proteins_ids.options = selected.index\n",
    "\n",
    "_ = w.interactive_output(update_protein_id_list, {'protein': w_protein})\n",
    "\n",
    "d_peptides_observed_prot_id = defaultdict(list)\n",
    "\n",
    "def show_sequences(prot_id):\n",
    "    _data = data_fasta[prot_id]\n",
    "    print(f\"Protein_ID on Uniport: {prot_id}\")\n",
    "    print(f\"HEADER: {_data[KEY_FASTA_HEADER]}\")\n",
    "#     print(f\"Seq  : {_data[KEY_FASTA_SEQ]}\")\n",
    "    annotate_seq = \"Peptides: \"\n",
    "    global d_peptides_observed_prot_id\n",
    "    for i, _l in enumerate(_data[KEY_PEPTIDES]):\n",
    "        annotate_seq += f\"\\nNo. of missed K or R: {i}\"\n",
    "        prot_seq_annotated = _data[KEY_FASTA_SEQ]     \n",
    "        _change_color = False\n",
    "        for j, _pep in enumerate(_l):\n",
    "            if _pep in set_peptides:\n",
    "                d_peptides_observed_prot_id[prot_id].append(_pep)\n",
    "                if _change_color is False:\n",
    "                    _pep_in_green = TGREEN + f\"{_pep}\" + RESET\n",
    "                    _change_color = True\n",
    "                else:\n",
    "                    _pep_in_green = TGREEN_2 + f\"{_pep}\" + RESET\n",
    "                    _change_color = False\n",
    "                prot_seq_annotated = prot_seq_annotated.replace(_pep, _pep_in_green)\n",
    "                _pep = _pep_in_green\n",
    "            else:\n",
    "                _change_color = False\n",
    "            if j==0:\n",
    "                annotate_seq += \"\\n\\t\"\n",
    "            else:\n",
    "                annotate_seq += \",\\n\\t\"\n",
    "            annotate_seq += _pep\n",
    "                \n",
    "        print(f\"Seq {i}: {prot_seq_annotated}\")\n",
    "    print(annotate_seq)\n",
    "    \n",
    "    \n",
    "    _ = data_peptides[d_peptides_observed_prot_id[prot_id]].dropna(how='all')\n",
    "    if _.columns.size > 2:\n",
    "        display(_)\n",
    "        display(_.describe())\n",
    "    else:\n",
    "        print(\"\\nNo empirical evidence for protein\")\n",
    "\n",
    "w_out = w.interactive_output(show_sequences, {\"prot_id\": w_proteins_ids})\n",
    "\n",
    "label_first_letter = w.Label(value='First letter of Gene')\n",
    "label_genes = w.Label('Gene')\n",
    "label_protein = w.Label('Protein')\n",
    "label_proteins_ids = w.Label('Protein Isotopes')\n",
    "\n",
    "panel_levels = w.VBox([\n",
    "         w.HBox([\n",
    "            w.VBox([label_first_letter, w_first_letter]),\n",
    "            w.VBox([label_genes, w_genes]),\n",
    "            w.VBox([label_protein, w_protein]),\n",
    "            w.VBox([label_proteins_ids, w_proteins_ids])\n",
    "            ]),\n",
    "         w_out]\n",
    ")\n",
    "panel_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> create styler object?\n",
    "\n",
    "- [ ] replace zeros with NaN\n",
    "- [ ] display summary statistics on log-scale (but do not compute summary based on log-scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"https://www.uniprot.org/uniprot/?query=accession:{prot_id}&format=txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- relatively short peptides resulting from one missed cleaveage, do not appear in the upper part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `gene` `->` `Protein_ID` (contains information of `gene` `->` `protein_isotopes`\n",
    "- `protein_ID` `->` `sequences` (`FN_FASTA_DB`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from src/config import FN_PROTEIN_SUPPORT_MAP, FN_PROTEIN_SUPPORT_FREQ\n",
    "# from vaep.utils import sample_iterable\n",
    "\n",
    "try:\n",
    "    if (time.time() - os.path.getmtime(FN_PROTEIN_SUPPORT_MAP)) / 3600 / 24 > 7:\n",
    "        # recompute file every week\n",
    "        raise FileNotFoundError\n",
    "    df_protein_support = pd.read_pickle(FN_PROTEIN_SUPPORT_MAP)\n",
    "    with open(FN_PROTEIN_SUPPORT_FREQ, 'rb') as f:\n",
    "        d_protein_support_freq = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    d_protein_support = {}\n",
    "    d_protein_support_freq = {}\n",
    "    for prot_id in tqdm(data_fasta.keys()):\n",
    "        _data = data_fasta[prot_id]\n",
    "        peptides_measured = []\n",
    "        for i, _l in enumerate(_data[KEY_PEPTIDES]):\n",
    "            for _pep in _l:\n",
    "                if _pep in set_peptides:\n",
    "                    peptides_measured.append(_pep)\n",
    "        _d_protein_support = {}\n",
    "        _df_support_protein = data_peptides[peptides_measured].dropna(how='all')\n",
    "\n",
    "        _n_samples = len(_df_support_protein)\n",
    "        if _n_samples > 0:\n",
    "            _d_protein_support['N_samples'] = _n_samples\n",
    "            d_protein_support_freq[prot_id] = _df_support_protein.notna().sum().to_dict()\n",
    "            d_protein_support[prot_id] = _d_protein_support\n",
    "        else:\n",
    "            d_protein_support[prot_id] = None\n",
    "        \n",
    "    df_protein_support = pd.DataFrame(d_protein_support).T.dropna()\n",
    "    df_protein_support = df_protein_support.join(id_map)\n",
    "    df_protein_support.to_pickle(FN_PROTEIN_SUPPORT_MAP)\n",
    "    \n",
    "    with open(FN_PROTEIN_SUPPORT_FREQ, 'wb') as f:\n",
    "        pickle.dump(d_protein_support_freq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_proteins_good_support = df_protein_support.sort_values(by='N_samples').tail(100).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_protein_support_freq['I3L3I0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to experimental peptide data\n",
    "\n",
    "Check if counts by `data_fasta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "counts_observed_by_missed_cleavages = {}\n",
    "for _protein_id, _data in tqdm(data_fasta.items()):\n",
    "    _peptides = _data[KEY_PEPTIDES]\n",
    "    _counts = {}\n",
    "    for i, _l in enumerate(_peptides):\n",
    "        _counts[i] = 0\n",
    "        for _pep in _l:\n",
    "            if _pep in set_peptides:\n",
    "                _counts[i] += 1\n",
    "    counts_observed_by_missed_cleavages[_protein_id] = _counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_observed_by_missed_cleavages = pd.DataFrame(\n",
    "    counts_observed_by_missed_cleavages\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import table\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, gridspec_kw={\"width_ratios\": [5, 1], \"wspace\": 0.2}, figsize=(10,4))\n",
    "\n",
    "_counts_summed = df_counts_observed_by_missed_cleavages.sum()\n",
    "_counts_summed.name = \"frequency\"\n",
    "\n",
    "ax = axes[0]\n",
    "_ = _counts_summed.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_xlabel(\"peptides from n miscleavages\")\n",
    "ax.set_ylabel(\"frequency\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(\"off\")\n",
    "_ = pd.plotting.table(ax=ax, data=_counts_summed, loc=\"best\", colWidths=[1], edges='open')\n",
    "_ = fig.suptitle('Peptides frequencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are unnormalized counts in the meaning of that _razor_ peptides are counted as often as they are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_counts_observed_by_missed_cleavages != 0\n",
    "df_prot_observed = df_counts_observed_by_missed_cleavages.replace(0, pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prot_observed = df_prot_observed.dropna(axis=0, how=\"all\")\n",
    "df_prot_observed = df_prot_observed.fillna(0)\n",
    "df_prot_observed = df_prot_observed.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.pandas import combine_value_counts\n",
    "\n",
    "combine_value_counts(df_prot_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pep_mapped_to_protID = df_prot_observed.sum(axis=1).value_counts()\n",
    "freq_pep_mapped_to_protID = freq_pep_mapped_to_protID.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pep_mapped_to_protID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes with support in data\n",
    "\n",
    "try software to identify the _most likely_ protein. [PyOpenMS](https://pyopenms.readthedocs.io/en/latest/) or [Pyteomics](https://pyteomics.readthedocs.io/en/latest/)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation: Train model\n",
    "\n",
    "> Select Gene or Protein\n",
    "\n",
    "As the samples are all obtained from the same biological sample (in principal), the single run should somehow be comparable.\n",
    "An description of variablity (from the Data Scientist perspective) can highlight some commenly known facts about proteomics experiments:\n",
    " - batch effects: Measurements on consecutive days are have to be normalized to each other\n",
    " - scoring: PSM are assigned to a peptide based on a score. Small variations can lead to different assignments\n",
    " \n",
    "Can a complex representation of a sample level out experimental variation on an in principle comparable data. \n",
    "\n",
    "### Strategy\n",
    "- first start using peptides from single Protein_IDs\n",
    "- then move to all models from genes\n",
    "- explore structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_peptides_observed_prot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peptides.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_select_proteins_good_support = w.Dropdown(options=l_proteins_good_support)\n",
    "w_select_proteins_queried = w.Dropdown(options=list(d_peptides_observed_prot_id.keys()))\n",
    "\n",
    "# select from top100 or above \n",
    "\n",
    "import vaep\n",
    "from vaep.transform import log\n",
    "from src/config import PROTEIN_DUMPS\n",
    "\n",
    "def main_trigger(prot_id):\n",
    "    \"\"\"Explore protein data\n",
    "    \n",
    "    Global Variables used\n",
    "    ---------------------\n",
    "    data_peptides : pandas.DataFrame\n",
    "    id_map : pandas.DataFrame\n",
    "    d_peptides_observed_prot_id: dict\n",
    "    \n",
    "    \n",
    "    Global variables set\n",
    "    --------------------\n",
    "    peptides_selected_log10: pandas.DataFrame\n",
    "        Current selection of data for protein_id. All possible features are returned. log10 transformed\n",
    "    prod_id : str\n",
    "        Passed prot_id to function exposed globally\n",
    "    \"\"\"\n",
    "    print(f'Protein Identifier: {prot_id}')\n",
    "    _gene_name = id_map.loc[prot_id, KEY_GENE_NAME_FASTA] # Select gene name, based on selected FASTA-File\n",
    "    _protein = id_map.protein.loc[prot_id] # Protein Name summarized several UNIPROT isotopes (PROT, PROT_2, PROT_3, etc)\n",
    "    print(f'Gene Identifier {_gene_name}')\n",
    "    # configure viewer above\n",
    "    w_first_letter.value = _gene_name[0]\n",
    "    w_genes.value = _gene_name\n",
    "    w_protein.value = _protein\n",
    "    w_proteins_ids.value = prot_id\n",
    "    \n",
    "    peptides_measured = d_peptides_observed_prot_id[prot_id] # get observed peptides according to pre-computed dictionary\n",
    "    n_peptides_in_selection = len(peptides_measured)\n",
    "    print(f\"Found {n_peptides_in_selection} peptides measured of this protein.\\n\\n\") \n",
    "    \n",
    "    peptides_selected = data_peptides[peptides_measured] # select subsample (as view) of peptides\n",
    "    mask_selected_notna = data_peptides[peptides_measured].notna()\n",
    "    selected_notna_summed_ax1 = mask_selected_notna.sum(axis=1)\n",
    "    print(\"How many samples have how many peptides quantified?\")\n",
    "    for n_peptides, n_samples in selected_notna_summed_ax1.value_counts().sort_index().tail(10).items():\n",
    "        print(f\"In {n_samples:5} samples are {n_peptides:5} peptides measured.\")\n",
    "    \n",
    "    PROP_DATA_COMPLETENESS = 0.5\n",
    "    mask_samples_selected = selected_notna_summed_ax1 >= int(n_peptides_in_selection * PROP_DATA_COMPLETENESS)\n",
    "    print(f\"\\nUsing a share of at least {PROP_DATA_COMPLETENESS}, \"\n",
    "          f\"i.e. at least {int(n_peptides_in_selection * PROP_DATA_COMPLETENESS)} out of {n_peptides_in_selection}.\",\n",
    "          f\"In total {mask_samples_selected.sum()} samples are selected for further analysis.\", sep=\"\\n\")\n",
    "    # from IPython.core.debugger import set_trace; set_trace()\n",
    "    _ = peptides_selected.loc[mask_samples_selected, peptides_measured]\n",
    "    _.index.name = f\"protein_id {prot_id}\"\n",
    "    # _.to_json(PROTEIN_DUMPS / f\"{prot_id}.json\")\n",
    "    \n",
    "    display(_)\n",
    "    # display(_.describe())\n",
    "    global peptides_selected_log10\n",
    "    peptides_selected_log10 = _.apply(log) # selected in widget overview above\n",
    "    display(peptides_selected_log10)\n",
    "    display(peptides_selected_log10.describe())\n",
    "    global prot_last\n",
    "    prot_last = prot_id\n",
    "    \n",
    "w.VBox([\n",
    "    w.HBox(\n",
    "        [\n",
    "            w.VBox(\n",
    "                [\n",
    "                    w.Label(f\"Top {len(l_proteins_good_support)} covered proteins\"),\n",
    "                    w_select_proteins_good_support,\n",
    "                ]\n",
    "            ),\n",
    "            w.VBox([w.Label(\"Queried proteins from above\"), w_select_proteins_queried]),\n",
    "        ]\n",
    "    ),\n",
    "    w.interactive_output(main_trigger, {\"prot_id\": w_select_proteins_good_support})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import importlib; importlib.reload(vaep.model)\n",
    "from vaep.model import train\n",
    "from vaep.model import VAE\n",
    "from vaep.model import loss_function\n",
    "from vaep.cmd import get_args\n",
    "\n",
    "# from vaep.model import PeptideDatasetInMemory\n",
    "# import importlib; importlib.reload(vaep.io.datasets)\n",
    "from vaep.io.datasets import PeptideDatasetInMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://pytorch.org/docs/stable/data.html#memory-pinning\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# class SimpleCustomBatch:\n",
    "#     def __init__(self, data):\n",
    "#         transposed_data = list(zip(*data))\n",
    "#         self.inp = torch.stack(transposed_data[0], 0)\n",
    "#         self.tgt = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "#     # custom memory pinning method on custom type\n",
    "#     def pin_memory(self):\n",
    "#         self.inp = self.inp.pin_memory()\n",
    "#         self.tgt = self.tgt.pin_memory()\n",
    "#         return self\n",
    "\n",
    "# def collate_wrapper(batch):\n",
    "#     return SimpleCustomBatch(batch)\n",
    "\n",
    "# inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "# tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "# dataset = TensorDataset(inps, tgts)\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
    "#                     pin_memory=True)\n",
    "\n",
    "# for batch_ndx, sample in enumerate(loader):\n",
    "#     print(sample.inp.is_pinned())\n",
    "#     print(sample.tgt.is_pinned())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(no_cuda=True)\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_start_training = w.Button(description='Train on new selection')\n",
    "\n",
    "def main_train():\n",
    "    n_samples, n_features = peptides_selected_log10.shape\n",
    "    detection_limit = float(int(peptides_selected_log10.min().min()))\n",
    "    detection_limit # replace by mean of sample/ features?\n",
    "\n",
    "    dataset_in_memory = PeptideDatasetInMemory(data=peptides_selected_log10, fill_na=detection_limit, device=device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset_in_memory,\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    #ToDo: Send data to correct device set above manually. Check docs..\n",
    "\n",
    "    data, mask = next(iter(train_loader))\n",
    "\n",
    "    writer = SummaryWriter(f'runs/{prot_last}_{format(datetime.now(), \"%y%m%d_%H%M\")}')\n",
    "    writer.add_image(f'{len(data)} batch of sampled data (as heatmap)', data, dataformats='HW')\n",
    "    writer.add_image(f'{len(mask)} mask for this batch of samples', mask, dataformats='HW')\n",
    "\n",
    "    global model\n",
    "    model = VAE(n_features=n_features, n_neurons=30).double()\n",
    "    model = model.to(device, non_blocking=True)\n",
    "    writer.add_graph(model, input_to_model=data)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(1, args.epochs):\n",
    "        train(epoch, model=model, train_loader=train_loader, optimizer=optimizer, device=device, writer=writer)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "# w_out_training = w.interactive_output(w_start_training, w_start_training)\n",
    "\n",
    "w_out_training = w.Output()\n",
    "display(w_start_training, w_out_training)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with w_out_training:\n",
    "        main_train()\n",
    "\n",
    "w_start_training.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Select a protein which leads to training. Each selection will create a dump of the selected data, which can be used in the `XZY.ipynb` for model fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
