{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3167ddaa-c624-4561-807d-9a42b389bee5",
   "metadata": {},
   "source": [
    "# `DataLoaders` for feeding data into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bd6b7-44b4-4697-be7f-b1d9333b6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fastai\n",
    "from fastai.tabular.core import Normalize\n",
    "from fastai.tabular.core import FillMissing\n",
    "from fastai.tabular.core import TabularPandas\n",
    "from fastai.tabular.core import IndexSplitter\n",
    "# make DataLoaders.test_dl work for DataFrames as test_items:\n",
    "\n",
    "# from fastai.tabular.all import *\n",
    "from fastai.tabular.all import TabularDataLoaders\n",
    "from fastcore.transform import Pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "from vaep.logging import setup_nb_logger\n",
    "setup_nb_logger()\n",
    "\n",
    "from vaep.io.datasplits import DataSplits\n",
    "from vaep.io.datasets import DatasetWithMaskAndNoTarget, to_tensor\n",
    "from vaep.transform import VaepPipeline\n",
    "from vaep.models import ae\n",
    "from vaep.utils import create_random_df\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"fastai version: {fastai.__version__}\")\n",
    "print(f\"torch  version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd936e88-b04a-4441-9644-4d52e559dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.transform import Pipeline\n",
    "\n",
    "from fastcore.basics import store_attr\n",
    "class FillMissingKeepAll(FillMissing):\n",
    "    \"\"\"Replacement for `FillMissing` including also non-missing features\n",
    "    in the training data which might be missing in the validation or test data.\n",
    "    \"\"\"\n",
    "    def setups(self, to):\n",
    "        store_attr(but='to', na_dict={n:self.fill_strategy(to[n], self.fill_vals[n])\n",
    "                            for n in to.conts.keys()})\n",
    "        self.fill_strategy = self.fill_strategy.__name__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b242d3-09ba-4ac2-8036-622409b53eaa",
   "metadata": {},
   "source": [
    "Create data\n",
    "\n",
    "- train data without missings\n",
    "- validation and test data with missings\n",
    "\n",
    "Could be adapted to have more or less missing in training, validation or test data. Choosen as in current version the validation data cannot contain features with missing values which were not missing in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304e7f6-8752-420d-a1f5-dec282aa6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = 150, 15\n",
    "\n",
    "create_df = create_random_df\n",
    "\n",
    "X = create_df(N, M)\n",
    "X = X.append(create_df(int(N*0.3), M, prop_na=.1, start_idx=len(X)))\n",
    "\n",
    "idx_val = X.index[N:] # RandomSplitter could be used, but used to show IndexSplitter usage with Tabular\n",
    "\n",
    "X_test = create_df(int(N*0.1), M, prop_na=.1, start_idx=len(X))\n",
    "\n",
    "data = DataSplits(train_X=X.loc[X.index.difference(idx_val)],\n",
    "                  val_y=X.loc[idx_val],\n",
    "                  test_y=X_test,\n",
    "                  is_wide_format=True)\n",
    "\n",
    "data.val_y.loc[data.val_y.isna().any(axis=1), data.val_y.isna().any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ea1e3-22b6-4720-8ced-b1295220c97e",
   "metadata": {},
   "source": [
    "## Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de36c59-1201-4f71-a476-0ca9f88762a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5aab60-049b-45a7-860e-1a572c014556",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b18a8-30ee-4892-8c17-f14ac4ff464c",
   "metadata": {},
   "source": [
    "### DataSet `Tabular`\n",
    "\n",
    "- `fastai.tabular.core.Tabular`\n",
    "\n",
    "\n",
    "Adding procs / transforms manually\n",
    "\n",
    "```python\n",
    "cont_names = list(splits.train_X.columns)\n",
    "to = TabularPandas(splits.train_X, cont_names=cont_names, do_setup=False)\n",
    "\n",
    "tf_norm = NORMALIZER()\n",
    "tf_fillna = FillMissing(add_col=True)\n",
    "\n",
    "_ = tf_norm.setups(to)  # returns to\n",
    "_ = tf_fillna.setup(to)\n",
    "```\n",
    "\n",
    "No added in a manuel pipeline. See [opened issue](https://github.com/fastai/fastai/issues/3530) on `Tabular` behaviour.\n",
    "Setting transformation (procs) in the constructor is somehow not persistent, although very similar code is called.\n",
    "\n",
    "```\n",
    "# not entirely empty, but to.procs.fs needs to be populated\n",
    "type(to.procs), to.procs.fs # __call__, setup, decode, fs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c899b9a-66a1-47ce-94ee-17090b74bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.train_X.append(data.val_y)\n",
    "\n",
    "splits = X.index.get_indexer(data.val_y.index) # In Tabular iloc is used, not loc for splitting\n",
    "splits = IndexSplitter(splits)(X) # splits is are to list of integer indicies (for iloc)\n",
    "        \n",
    "procs = [Normalize, FillMissingKeepAll]\n",
    "\n",
    "to = TabularPandas(X, procs=procs, cont_names=X.columns.to_list(), splits=splits) # to = tabular object\n",
    "\n",
    "print(\"Tabular object:\", type(to))\n",
    "to.items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ebf88-e7fc-4517-8c33-30c8ee591a19",
   "metadata": {},
   "source": [
    "Test data with procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88bf3d-b535-4d23-9c8b-757fbf0e445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = to.procs\n",
    "procs.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd181c-ec64-44dd-bdca-db306846b1d6",
   "metadata": {},
   "source": [
    "Let's format this to see what it does\n",
    "\n",
    "```python\n",
    "# (#2)\n",
    "[\n",
    "FillMissingKeepAll -- \n",
    "{'fill_strategy': <function FillStrategy.median at 0x0000023845497E50>, \n",
    " 'add_col': True, \n",
    " 'fill_vals': defaultdict(<class 'int'>,  {'feat_00': 0, 'feat_01': 0, 'feat_02': 0, ..., 'feat_14': 13.972452}\n",
    "}:\n",
    "    encodes: (object,object) -> encodes\n",
    "    decodes: ,\n",
    "Normalize -- \n",
    "{'mean': None, 'std': None, 'axes': (0, 2, 3),\n",
    " 'means': {'feat_00': 14.982738, 'feat_01': 13.158741, 'feat_02': 14.800485, ..., 'feat_14': 8.372757}\n",
    "}:\n",
    "    encodes: (TensorImage,object) -> encodes\n",
    "             (Tabular,object) -> encodes\n",
    "    decodes: (TensorImage,object) -> decodes\n",
    "             (Tabular,object) -> decodes\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c13606-7ada-42f3-853e-e42a3c0555f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0d239-7761-43e4-aa14-10a4abad34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check behaviour\n",
    "procs.encodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a884155-eae8-4019-ae1b-57019c630961",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebc15d-92f2-4d34-be08-06601b2d5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=4)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71b82a-0036-479d-a970-990ff62bdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24fcfc-db60-4b08-8ba6-183832b945dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.dtype for x in dls.one_batch()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04f447-3927-4994-8c96-170a50aac1f8",
   "metadata": {},
   "source": [
    "#### transfrom test data using `DataLoaders.test_dl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f2de5-dcf7-4ec9-9fc6-7a5f08f166e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = TabularPandas(data.test_y, cont_names=data.test_y.columns.to_list())\n",
    "dl_test = dls.test_dl(data.test_y.copy())\n",
    "dl_test.xs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef888c00-61f0-423d-9630-68d0a5533675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec83746-12c1-489b-abac-01d1b184b555",
   "metadata": {},
   "source": [
    "#### Transform test data manuelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e122d-19dc-41c3-a480-8f3e8af18cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = TabularPandas(data.test_y.copy(), procs=None, cont_names=data.test_y.columns.to_list(), splits=None, do_setup=True)\n",
    "_ = procs(to_test) # inplace operation\n",
    "to_test.items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32b81a-93d7-4df2-881c-a000e64c9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aca60-0e37-4550-9755-61a28417802f",
   "metadata": {},
   "source": [
    "#### Feeding one batch to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024613e-098f-4d39-95b2-95426a611a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats, conts, ys =  dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01a34c-011d-416f-8559-17c13f3dc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.Autoencoder(n_features=M, n_neurons=int(\n",
    "    M/2), last_decoder_activation=None, dim_latent=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d13382-ea45-40c8-998e-172e63ee545d",
   "metadata": {},
   "source": [
    "The forward pass just uses the conts features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0d79e-6558-4202-aa39-1b901d844287",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(conts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de7d6b-ba79-4390-8616-072316027a72",
   "metadata": {},
   "source": [
    "#### target\n",
    "- missing puzzle piece is to have a `callable` y-block which transforms part of the input. In principle it could be the same as the continous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62851019-2731-4982-840b-d3b3795b7f82",
   "metadata": {},
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39df418-2a90-470c-b45b-f83310f10557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetWithMaskAndNoTarget(df=data.train_X)\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=data.val_y)\n",
    "train_ds[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564fcf4-5f22-4517-a447-bd9fb4a99811",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dcc4b-75f5-4b4a-99dd-bf3163f6383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds,\n",
    "                             bs=4)\n",
    "\n",
    "dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f2d7e-aadf-49de-a065-c66c8e69009b",
   "metadata": {},
   "source": [
    "#### DataLoaders with Normalization fastai Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ec37-9968-4175-8e44-691769d2847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import * \n",
    "class Normalize(Transform):\n",
    "    def setup(self, array):\n",
    "        self.mean = array.mean()  # this assumes tensor, numpy arrays and alike\n",
    "        # should be applied along axis 0 (over the samples)\n",
    "        self.std = array.std()  # ddof=0 in scikit-learn\n",
    "    \n",
    "    def encodes(self, x): # -> torch.Tensor: # with type annotation this throws an error\n",
    "        x_enc = (x - self.mean) / self.std\n",
    "        return x_enc\n",
    "\n",
    "    def decodes(self, x_enc:torch.tensor) -> torch.Tensor:\n",
    "        x = (self.std * x_enc) + self.mean\n",
    "        return x\n",
    "    \n",
    "o_tf_norm = Normalize()\n",
    "o_tf_norm.setup(data.train_X)\n",
    "o_tf_norm(data.val_y.head()) # apply this manueally to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423273cc-b39d-4bb7-8ecc-679524e74445",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_tf_norm.encodes # object= everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b2869-8dbd-462d-bf78-5435104e33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetWithMaskAndNoTarget(df=o_tf_norm(data.train_X))\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=o_tf_norm(data.val_y))\n",
    "\n",
    "dls = DataLoaders.from_dsets(\n",
    "    train_ds,\n",
    "    valid_ds,\n",
    "    #  tfms=[o_tf_norm],\n",
    "    #  after_batch=[o_tf_norm],\n",
    "    bs=4)\n",
    "\n",
    "dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c3d5e-dd73-4757-85b1-ef32455c3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from numpy.testing import assert_array_almost_equal, assert_array_less\n",
    "\n",
    "assert (dls.valid.one_batch()[1] < 0.0).any(), \"Normalization did not work.\"\n",
    "with pytest.raises(AttributeError):\n",
    "    DatasetWithMaskAndNoTarget(df=data.val_y, transformer=o_tf_norm)\n",
    "    \n",
    "# assert_array_almost_equal(DatasetWithMaskAndNoTarget(df=data.val_y, transformer=o_tf_norm)[0][1], DatasetWithMaskAndNoTarget(df=o_tf_norm(data.val_y))[0][1])\n",
    "# with pytest.raises(AttributeError):\n",
    "#        valid_ds.inverse_transform(dls.valid.one_batch()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbe725-1baa-4801-8313-251fd629494b",
   "metadata": {},
   "source": [
    "#### DataLoaders with Normalization sklearn transform\n",
    "\n",
    "- solve transformation problem by composition\n",
    "- inverse transform only used for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a835a-7b77-4f1e-94a7-a216a0839a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import vaep\n",
    "# import importlib; importlib.reload(vaep); importlib.reload(vaep.transform)\n",
    "\n",
    "dae_default_pipeline = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        ('normalize', StandardScaler()),\n",
    "        ('impute', SimpleImputer(add_indicator=False))\n",
    "    ])\n",
    "# new procs, transform equal encode, inverse_transform equals decode\n",
    "dae_transforms = VaepPipeline(\n",
    "    df_train=data.train_X, encode=dae_default_pipeline, decode=['normalize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d211c3-5ea1-4f97-84f7-5066336dafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = DatasetWithMaskAndNoTarget(data.val_y, dae_transforms)\n",
    "valid_ds[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7bed34-df4f-4374-90fc-3fee51cb9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.io.dataloaders import get_dls\n",
    "dls = get_dls(data.train_X, data.val_y, dae_transforms, bs=4)    \n",
    "dls.valid.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25bd6c-8a14-4d82-8e21-6da6dd41b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(\n",
    "    dataset=DatasetWithMaskAndNoTarget(data.test_y, dae_transforms),\n",
    "    shuffle=False,\n",
    "    bs=4)\n",
    "test_dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19562f-bb04-41df-a0e8-e07f2af59fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dae_transforms.inverse_transform(test_dl.one_batch()[1]) # here the missings are not replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5608989-58ff-4692-8666-1db060845594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_y.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5f8ac-1792-4406-89c8-79113e7f19cd",
   "metadata": {},
   "source": [
    "### FastAi Transfrom (as Dataset)\n",
    "\n",
    "- adding `Transforms` not possible, I openend a [discussion](https://forums.fast.ai/t/correct-output-type-for-tensor-created-from-dataframe-custom-new-task-tutorial/92564)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80209748-5c04-4d19-8bae-f2f865856385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from fastai.tabular.all import *\n",
    "# from fastai.torch_core import TensorBase\n",
    "\n",
    "\n",
    "class DatasetTransform(Transform):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        if not issubclass(type(df), pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f'please pass a pandas DataFrame, not: {type(df) = }')\n",
    "        self.mask_obs = df.isna()  # .astype('uint8') # in case 0,1 is preferred\n",
    "        self.data = df\n",
    "\n",
    "    def encodes(self, idx): # -> Tuple[torch.Tensor, torch.Tensor]: # annotation is interpreted\n",
    "        mask = self.mask_obs.iloc[idx]\n",
    "        data = self.data.iloc[idx]\n",
    "        # return (self.to_tensor(mask), self.to_tensor(data))\n",
    "        # return (Tensor(mask), Tensor(data))\n",
    "        return (tensor(data), tensor(mask)) #TabData, TabMask\n",
    "\n",
    "    def to_tensor(self, s: pd.Series) -> torch.Tensor:\n",
    "        return torch.from_numpy(s.values)\n",
    "\n",
    "\n",
    "train_tl = TfmdLists(\n",
    "    range(len(data.train_X)),\n",
    "    DatasetTransform(data.train_X))\n",
    "valid_tl = TfmdLists(\n",
    "    range(len(data.val_y)),\n",
    "    DatasetTransform(data.val_y))\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_tl, valid_tl,\n",
    "#                              after_item=[Normalize],\n",
    "#                              after_batch=[Normalize],\n",
    "                             bs=4)\n",
    "print(f\"\\n{DatasetTransform.encodes = }\")\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49cf8c-6e0a-4b4b-8e75-3bc5ab5d3781",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973df37c-83f3-4fed-a414-4012cf90091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaep.transform import MinMaxScaler\n",
    "\n",
    "args_vae = {}\n",
    "args_vae['SCALER'] = MinMaxScaler\n",
    "# select initial data: transformed vs not log transformed\n",
    "scaler = args_vae['SCALER']().fit(data.train_X)\n",
    "\n",
    "_transform_fct = scaler.transform\n",
    "\n",
    "train_ds = DatasetWithMaskAndNoTarget(df=_transform_fct(data.train_X))\n",
    "valid_ds = DatasetWithMaskAndNoTarget(df=_transform_fct(data.val_y))\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds,\n",
    "                             bs=4)\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22730fc1-f2b3-4133-8504-845667bfd12e",
   "metadata": {},
   "source": [
    "## FastAi version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad20eaf-8a14-4a46-aa3b-85a070966aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
