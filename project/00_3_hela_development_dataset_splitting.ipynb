{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up data into single datasets\n",
    "\n",
    "- create datasets per (set of) instruments for a specific experiments\n",
    "- drop some samples based on quality criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates\n",
    "import seaborn as sns\n",
    "\n",
    "import umap\n",
    "\n",
    "from vaep.io import thermo_raw_files\n",
    "from vaep.analyzers import analyzers\n",
    "\n",
    "from config import erda_dumps\n",
    "from config import defaults\n",
    "\n",
    "import vaep\n",
    "import vaep.io.filenames\n",
    "from vaep.logging import setup_nb_logger\n",
    "\n",
    "logger = setup_nb_logger()\n",
    "\n",
    "FOLDER_DATA = defaults.FOLDER_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep.plotting.make_large_descriptors()\n",
    "FIGSIZE = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "N_MIN_INSTRUMENT = 300\n",
    "META_DATA: str = 'data/files_selected_metadata.csv'\n",
    "FILE_EXT = 'pkl'\n",
    "SAMPLE_ID = 'Sample ID'\n",
    "\n",
    "DUMP: str = erda_dumps.FN_PROTEIN_GROUPS\n",
    "OUT_NAME = 'protein group'  # for legends labels\n",
    "# DUMP: str = erda_dumps.FN_PEPTIDES\n",
    "# OUT_NAME = 'aggregated peptide' # for legends labels\n",
    "# DUMP: str = erda_dumps.FN_EVIDENCE\n",
    "# OUT_NAME = 'charged peptide' # for legends labels\n",
    "\n",
    "FOLDER_DATASETS: str = f'single_datasets/{DUMP.stem}'\n",
    "\n",
    "INSTRUMENT_LEGEND_TITLE = 'Q Exactive HF-X Orbitrap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure output folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP = Path(DUMP)  # set parameter from cli or yaml to Path\n",
    "FOLDER_DATASETS = defaults.FOLDER_DATA / FOLDER_DATASETS\n",
    "FOLDER_DATASETS.mkdir(exist_ok=True, parents=True)\n",
    "logger.info(f\"Folder for datasets to be created: {FOLDER_DATASETS.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load dumps\n",
    "- load file to machine mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(DUMP)\n",
    "data = data.squeeze()  # In case it is a DataFrame, not a series (-> leads to MultiIndex)\n",
    "name_data = data.name\n",
    "logger.info(\n",
    "    f\"Number of rows (row = sample, feature, intensity): {len(data):,d}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make categorical index a normal string index (this lead to problems when selecting data using `loc` and grouping data as level of data could not easily be removed from MultiIndex)\n",
    "\n",
    "- see [blog](https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_columns = data.index.names\n",
    "data = data.reset_index()\n",
    "print(data.memory_usage(deep=True))\n",
    "cat_columns = data.columns[data.dtypes == 'category']\n",
    "if not cat_columns.empty:\n",
    "    data[cat_columns] = data[cat_columns].astype('object')\n",
    "    print(\"non categorical: \\n\", data.memory_usage(deep=True))\n",
    "    logger.warning(\n",
    "        \"if time allows, this should be investigate -> use of loc with data which is not categorical\")\n",
    "data = data.set_index(index_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_non_sample = list(data.index.names)\n",
    "idx_non_sample.remove(SAMPLE_ID)\n",
    "idx_non_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = data.index.droplevel(SAMPLE_ID).nunique() # very slow alternative, but 100% correct\n",
    "M = vaep.io.filenames.read_M_features(DUMP.stem)\n",
    "logger.info(f\"Number of unqiue features: {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "counts = data.groupby(SAMPLE_ID).count().squeeze()\n",
    "N = len(counts)\n",
    "counts.to_json(FOLDER_DATASETS / 'support_all.json', indent=4)\n",
    "ax = (counts\n",
    "      .sort_values()  # will raise an error with a DataFrame\n",
    "      .reset_index(drop=True)\n",
    "      .plot(rot=45,\n",
    "            figsize=FIGSIZE,\n",
    "            grid=True,\n",
    "            ylabel='number of features in sample',\n",
    "            xlabel='Sample rank ordered by number of features',\n",
    "            title=f'Support of {N:,d} samples features over {M} features ({\", \".join(idx_non_sample)})',\n",
    "            ))\n",
    "vaep.plotting.add_prop_as_second_yaxis(ax, M)\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "vaep.plotting.savefig(fig, name='support_all',\n",
    "                      folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.groupby(idx_non_sample).count().squeeze()\n",
    "counts.to_json(FOLDER_DATASETS / 'feat_completeness_all.json', indent=4)\n",
    "ax = (counts\n",
    "      .sort_values()  # will raise an error with a DataFrame\n",
    "      .reset_index(drop=True)\n",
    "      .plot(rot=45,\n",
    "            figsize=FIGSIZE,\n",
    "            grid=True,\n",
    "            ylabel='number of samples per feature',\n",
    "            xlabel='Feature rank ordered by number of samples',\n",
    "            title=f'Support of {len(counts):,d} features over {N} samples ({\", \".join(idx_non_sample)})',\n",
    "            ))\n",
    "vaep.plotting.add_prop_as_second_yaxis(ax, N)\n",
    "fig = ax.get_figure()\n",
    "vaep.plotting.savefig(fig, name='feat_per_sample_all',\n",
    "                      folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for odd samples\n",
    "\n",
    "- fractionated samples\n",
    "- GPF - Gas phase fractionation # Faims? DIA? \n",
    "- DIA\n",
    "- CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see misc_data_exploration_peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data\n",
    "\n",
    "- based on ThermoRawFileParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_ids = data.index.levels[0] # assume first index position is Sample ID?\n",
    "sample_ids = data.index.get_level_values(SAMPLE_ID).unique()  # more explict\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(META_DATA, index_col=SAMPLE_ID)\n",
    "date_col = 'Content Creation Date'\n",
    "df_meta[date_col] = pd.to_datetime(df_meta[date_col])\n",
    "df_meta = df_meta.loc[sample_ids]\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_instrument = df_meta.groupby(thermo_raw_files.cols_instrument)[date_col].agg(\n",
    "    ['count', 'min', 'max']).sort_values(by=thermo_raw_files.cols_instrument[:2] + ['count'], ascending=False)\n",
    "counts_instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts_instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_instruments = counts_instrument.query(f\"count >= {N_MIN_INSTRUMENT}\")\n",
    "fname = FOLDER_DATASETS / 'dataset_info'\n",
    "selected_instruments.to_latex(f\"{fname}.tex\")\n",
    "selected_instruments.to_excel(f\"{fname}.xlsx\")\n",
    "logger.info(f\"Save Information to: {fname} (as json, tex)\")\n",
    "selected_instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = pd.Series(False, index=df_meta.index)\n",
    "# for v in selected_instruments.index:\n",
    "#     mask = mask | (df_meta[selected_instruments.index.names] == v).all(axis=1)\n",
    "# mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta = df_meta.loc[mask]\n",
    "# data = data.loc[df_meta.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary plot - UMAP\n",
    "\n",
    "- embedding based on all samples\n",
    "- visualization of top 5 instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "data = data.unstack(idx_non_sample)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(data.fillna(data.median()))\n",
    "embedding = pd.DataFrame(embedding, index=data.index,\n",
    "                         columns=['UMAP 1', 'UMAP 2'])\n",
    "embedding = embedding.join(\n",
    "    df_meta[[\"Content Creation Date\", \"instrument serial number\"]])\n",
    "d_instrument_counts = counts_instrument['count'].reset_index(\n",
    "    level=[0, 1], drop=True).to_dict()\n",
    "embedding[\"count\"] = embedding[\"instrument serial number\"].replace(\n",
    "    d_instrument_counts)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = int(np.ceil(np.log10(embedding[\"count\"].max())))\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[\"instrument with N\"] = embedding[[\"instrument serial number\",\n",
    "                                            \"count\"]].apply(lambda s: f\"{s[0]} (N={s[1]:{digits}d})\", axis=1)\n",
    "embedding[\"instrument with N\"] = embedding[\"instrument with N\"].str.replace(\n",
    "    'Exactive Series slot', 'Instrument')\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define top five instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = counts_instrument[\"count\"].nlargest(5)\n",
    "top_5 = top_5.index.levels[-1]\n",
    "embedding[\"instrument\"] = embedding[\"instrument serial number\"].apply(\n",
    "    lambda x: x if x in top_5 else 'other')\n",
    "mask_top_5 = embedding[\"instrument\"] != 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[\"Date (90 days intervals)\"] = embedding[\"Content Creation Date\"].dt.round(\n",
    "    \"90D\").astype(str)\n",
    "to_plot = embedding.loc[mask_top_5]\n",
    "print(f\"N samples in plot: {len(to_plot):,d}\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax = sns.scatterplot(data=to_plot, x='UMAP 1', y='UMAP 2', style=\"instrument with N\",\n",
    "                     hue=\"Date (90 days intervals)\", ax=ax)  # =\"Content Creation Date\")\n",
    "vaep.savefig(fig, name='umap_interval90days_top5_instruments',\n",
    "             folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['o', 'x', 's', 'P', 'D', '.']\n",
    "alpha = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "groups = list()\n",
    "\n",
    "vaep.plotting.make_large_descriptors()\n",
    "embedding[\"Content Creation Date\"] = embedding[\"Content Creation Date\"].dt.round(\n",
    "    \"D\")\n",
    "embedding[\"mdate\"] = embedding[\"Content Creation Date\"].apply(\n",
    "    matplotlib.dates.date2num)\n",
    "\n",
    "to_plot = embedding.loc[mask_top_5]\n",
    "\n",
    "norm = matplotlib.colors.Normalize(\n",
    "    embedding[\"mdate\"].quantile(0.05), embedding[\"mdate\"].quantile(0.95))\n",
    "cmap = sns.color_palette(\"cubehelix\", as_cmap=True)\n",
    "\n",
    "\n",
    "for k, _to_plot in to_plot.groupby('instrument with N'):\n",
    "    if markers:\n",
    "        marker = markers.pop(0)\n",
    "    _ = ax.scatter(\n",
    "        x=_to_plot[\"UMAP 1\"],\n",
    "        y=_to_plot[\"UMAP 2\"],\n",
    "        c=_to_plot[\"mdate\"],\n",
    "        alpha=alpha,\n",
    "        marker=marker,\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "    groups.append(k)\n",
    "\n",
    "cbar = vaep.analyzers.analyzers.add_date_colorbar(\n",
    "    ax.collections[0], ax=ax, fig=fig)\n",
    "cbar.ax.set_ylabel(\"date of measurement\", labelpad=-115, loc='center')\n",
    "ax.legend(ax.collections, groups,\n",
    "          title=INSTRUMENT_LEGEND_TITLE, fontsize='xx-large')\n",
    "ax.set_xlabel('UMAP 1')  # , fontdict={'size': 16})\n",
    "ax.set_ylabel('UMAP 2')\n",
    "vaep.savefig(fig, name='umap_date_top5_instruments', folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics for top 5 instruments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# boxplot: number of available sample for included features\n",
    "to_plot = data.loc[mask_top_5].notna().sum(axis=0).reset_index(\n",
    "    drop=True).to_frame(f'{OUT_NAME.capitalize()} prevalence')\n",
    "# boxplot: number of features per sample\n",
    "to_plot = to_plot.join(data.loc[mask_top_5].notna().sum(axis=1).reset_index(\n",
    "    drop=True).to_frame(f'{OUT_NAME.capitalize()}s per sample'))\n",
    "to_plot = to_plot.join(counts_instrument.reset_index([0, 1], drop=True).loc[top_5, 'count'].reset_index(\n",
    "    drop=True).rename('Samples per instrument', axis='index'))\n",
    "ax = to_plot.plot(kind='box', ax=ax, fontsize=16, )\n",
    "ax.set_ylabel('number of observations',\n",
    "              fontdict={'fontsize': 14})\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "to_plot.to_csv(FOLDER_DATASETS / 'summary_statistics_dump_data.csv')\n",
    "vaep.savefig(fig, name='summary_statistics_dump',\n",
    "             folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_meta = df_meta.loc[mask_top_5] \n",
    "top_5_meta[['injection volume setting', 'dilution factor']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data stats for top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _instrument, _df_meta_instrument in top_5_meta.groupby(by=thermo_raw_files.cols_instrument):\n",
    "    print('#'* 80, ' - '.join(_instrument), sep='\\n')\n",
    "    display(_df_meta_instrument.describe())\n",
    "    display(_df_meta_instrument['injection volume setting'].value_counts())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump single experiments\n",
    "\n",
    "from long-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.stack(idx_non_sample)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = selected_instruments.index.names\n",
    "\n",
    "file_formats = {'pkl': 'to_pickle',\n",
    "                'pickle': 'to_pickle',\n",
    "                'csv': 'to_csv'}\n",
    "\n",
    "\n",
    "for values in selected_instruments.index:\n",
    "    mask = df_meta[cols] == values\n",
    "    logger.info(f\"Samples: {mask.all(axis=1).sum()}\")\n",
    "    sample_ids = df_meta.loc[mask.all(axis=1)]\n",
    "    display(sample_ids.sort_index())\n",
    "    sample_ids = sample_ids.index\n",
    "    # which categorical this might need to be a categorical Index as well?\n",
    "    dataset = data.loc[sample_ids]\n",
    "    dataset.index = dataset.index.remove_unused_levels()\n",
    "\n",
    "    display(dataset\n",
    "            .unstack(dataset.index.names[1:])\n",
    "            .sort_index()\n",
    "            )\n",
    "\n",
    "    fname_dataset = vaep.io.get_fname_from_keys(values,\n",
    "                                                folder=FOLDER_DATASETS,\n",
    "                                                file_ext=f\".{FILE_EXT}\")\n",
    "\n",
    "    logger.info(f'Dump dataset with N = {len(dataset)} to {fname_dataset}')\n",
    "    _to_file_format = getattr(dataset, file_formats[FILE_EXT])\n",
    "    _to_file_format(fname_dataset)\n",
    "\n",
    "    fname_support = vaep.io.get_fname_from_keys(values,\n",
    "                                                folder='.',\n",
    "                                                file_ext=\"\")\n",
    "    fname_support = fname_support.stem + '_support'\n",
    "    logger.info(f\"Dump support to: {fname_support}\")\n",
    "    counts = dataset.groupby(SAMPLE_ID).count().squeeze()\n",
    "    counts.to_json(FOLDER_DATASETS / f\"{fname_support}.json\", indent=4)\n",
    "\n",
    "    # very slow alternative, but 100% correct\n",
    "    M = dataset.index.droplevel(SAMPLE_ID).nunique()\n",
    "\n",
    "    # plot:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = (counts\n",
    "          .sort_values()  # will raise an error with a DataFrame\n",
    "          .reset_index(drop=True)\n",
    "          .plot(rot=45,\n",
    "                ax=ax,\n",
    "                figsize=FIGSIZE,\n",
    "                grid=True,\n",
    "                xlabel='Count of samples ordered by number of features',\n",
    "                title=f'Support of {len(counts):,d} samples features over {M} features ({\", \".join(idx_non_sample)})',\n",
    "                ))\n",
    "    vaep.plotting.add_prop_as_second_yaxis(ax, M)\n",
    "    fig.tight_layout()\n",
    "    vaep.plotting.savefig(fig, name=fname_support,\n",
    "                          folder=FOLDER_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last example dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add json dump as target file for script for workflows\n",
    "selected_instruments.to_json(f\"{fname}.json\", indent=4)\n",
    "logger.info(f\"Saved: {fname}.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf83e9cb890c7f96eb0ae04f39a82254555f56a1a0ed2f03b23a8b40fe6cd31c"
  },
  "kernelspec": {
   "display_name": "vaep",
   "language": "python",
   "name": "vaep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
